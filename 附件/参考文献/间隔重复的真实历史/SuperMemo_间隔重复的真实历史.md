---
created: 2024-12-23T10:03:41 (UTC +08:00)
tags: 
source: https://www.supermemo.com/en/blog/the-true-history-of-spaced-repetition
author: Piotr Wozniak
---
# SuperMemo_The true history of spaced repetition

> ## Excerpt
> The popular history of spaced repetition is full of myths and falsehoods. This text is to tell you the true story.
> 
> ## 摘要
> 关于间隔重复的流行历史充满了谣传和谎言。这段文字是为了告诉你真实的故事。

---
![[pexels-engin-akyurt-2952871-1-500x334.jpg]]

Dr Piotr Wozniak, June 2018

彼得·沃兹尼亚克教授，2018年6月

## 目录（Contents）

-   简介（Introduction）
-   1985年：SuperMemo的诞生（1985: Birth of SuperMemo）
-   1986年：SuperMemo 初试身手（1986: First steps of SuperMemo）
-   1987年：DOS 上的 SuperMemo 1.0（1987: SuperMemo 1.0 for DOS）
-   1988年：记忆的两个组成部分（1988: Two component of memory）
-   1989年：SuperMemo 适应用户记忆（1989: SuperMemo adapts to user memory）
-   1990年：记忆的普适公式（1990: Universal formula for memory）（1990: Universal formula for memory）
-   1991年：运用遗忘曲线（1991: Employing forgetting curves）（1991: Employing forgetting curves）
-   1994年：遗忘的指数性质（1994: Exponential nature of forgetting）
-   1995年：超媒体 SuperMemo（1995: Hypermedia SuperMemo）
-   1997年：应用神经网络（1997: Employing neural networks）
-   1999年：选定名称：“间隔重复”（1999: Choosing the name: “spaced repetition”）
-   2005年：稳定性增长函数（2005: Stability increase function）
-   2014年：SM-17算法（2014: Algorithm SM-17）
-   间隔重复的指数级传播（Exponential adoption of spaced repetition）
-   记忆研究史摘要（Summary of memory research）
-   失败与成功的剖析（The anatomy of failure and success）

## 简介（Introduction）

### 真正的历史（True history）

The popular history of spaced repetition is full of myths and falsehoods. This text is to tell you the true story. The problem with spaced repetition is that it became too popular for its own effective replication. Like a fast mutating virus it keeps jumping from application to application, and tells its own story while accumulating errors on the way.

关于间隔重复的流行历史充满了神话和谎言。这段文字是为了告诉你真实的故事。间隔重复的问题在于，它变得过于流行，以至于难以在复制过程中保留原本信息。就像一个快速变异的病毒，它不断地从一种应用方法跳到另一种应用方法，并在传播的过程中积累错误。

### 谁发明了间隔重复？ （Who invented spaced repetition?）

This is the story of how I solved the problem of forgetting. I figured out how to learn efficiently. Modesty is a waste of time, therefore I will add that I think I actually know how to significantly amplify human intelligence. In short: memory underlies knowledge which underlies intelligence. If we can control what we store in memory and what we forget, we can control our problem solving capacity. In a very similar way, we can also amplify artificial intelligence. Its a great relief to be able to type in those proud words after many years of a gag order imposed by commercial considerations.

这是一个关于我如何解决“遗忘”的故事。我解明了如何高效学习。谦虚是对时间的浪费，因此我就直说吧，我认为我实际上知道如何显著提高人类智力。简而言之：记忆是知识的基础，知识是智力的基础。如果我们能控制我们在记忆中存储以及遗忘的事务，我们就能控制我们解决问题的能力。以非常类似的方式，我们也可以增强人工智能。在被基于商业考虑所施加的禁言令限制多年之后，能够打出这些自豪的词语对我是一种极大的解脱。

Back in the early 1990s, I thought I knew how to turn education systems around the world upside down and make them work for all students. However, any major change requires a cultural paradigm shift. It is not enough for a poor student from a poor communist country to announce the potential for a change. I did that, in my Link opens in a new tabLink opens in a new tabMaster’s Thesis, but I found little interest in my ideas. Even my own family was dismissive. Luckily, I met a few smart friends at my university who declared they would use my ideas to set up a business. Like Microsoft changed the world of personal computing, we would change the way people learn. We owned a powerful learning tool: Link opens in a new tabLink opens in a new tabSuperMemo. However, for Link opens in a new tabLink opens in a new tabSuperMemo to conquer the world it had to ditch its roots for a while. To convince others, Link opens in a new tabLink opens in a new tabSuperMemo had to be a product of pure science. It could not have just been an idea conceived by a humble student.

在20世纪90年代初，我自以为知道如何颠覆全球的教育体系，使它们为所有学生服务。然而，任何重大变革都需要文化范式的转变。一个来自贫穷共产主义国家的贫困学生，即使他宣传变革中蕴含的潜力，也难以让人信服。我在我的硕士论文中做了这件事，但发现自己的观点鲜有人关注。甚至我的家人也不屑一顾。幸运的是，我在大学遇到了一些聪明的朋友，他们宣称会用我的想法来建立一个企业。就像微软改变了个人计算的世界一样，我们将改变人们的学习方式。我们拥有一个强大的学习工具：SuperMemo。然而，为了让 SuperMemo 征服世界，它不得不暂时抛弃它的根基。为了说服他人，SuperMemo 必须是一个纯粹科学的产物。而不能仅仅是一个谦逊学生提出的想法。

To root SuperMemo in science, we made a major effort to publish our ideas in a peer-review journal, adopted a little known scientific term of ” *spaced repetition* ” and set our learning technology in a context of learning theory and the history of research in psychology. I am very skeptical of schools, certificates, and titles. However, I still went as far as to earn a PhD in economics of learning, to add respectability to my words.

为了将 SuperMemo 植根于科学，我们做出了重大努力，在同行评审期刊上发表我们的想法，采用了鲜为人知的科学术语“间隔重复”，并将我们的学习技术置于学习理论和心理学研究历史的背景中。我对学校、证书和头衔的可靠性非常怀疑。然而，我还是努力获得了学习经济学的博士学位，以增加我话语的可信度。

Today, when spaced repetition is finally showing up in hundreds of respectable learning tools, applications, and services, we can finally stake the claim and plant the flag at the summit. Usership is going into hundreds of millions.

今天，当间隔重复终于出现在数百个受人尊敬的学习工具、应用程序和服务中时，我们终于可以为自己的主张摇旗呐喊。而我们的用户数量也即将进入数亿的规模。

If you read SuperMemopedia here you may conclude that *“Nobody should ever take credit for discovering spaced repetition”*. I beg to disagree. In this text I will claim the full credit for the discovery, and some solid credit for the dissemination of the idea. My contribution to the latter is waning thanks to the power of the idea itself and a growing circle of people involved in the concept (well beyond our company).

如果你阅读 SuperMemopedia，你可能会得出结论：“没有人能独占发现间隔重复的荣誉”。我不敢苟同。在这段文字中，我将宣称自己占有发现这一想法的全部荣誉，以及为这一想法的传播做出坚实贡献的荣誉。由于这一想法本身的力量以及越来越多的人在传播中的参与（远远超出了我们公司），我对后者的贡献占比正在减少。

### 一直以来的误解

It is Krzysztof Biedalak (CEO), who got least patience with fake news in reference to spaced repetition. I will then credit this particular text and the effort in mythbusting to his resolution to keep the history straight. SuperMemo for DOS was born 30 years ago (1987). Let’s pay some tribute.

对关于间隔重复的假消息最不能忍的要属 Krzysztof Biedalak（CEO）。我将把这篇文章的诞生和破除误解的努力归功于他，并感谢他为保持历史的准确性所做的贡献。SuperMemo for DOS 诞生于30年前（1987年）。让我们对此表示敬意。

If you believe that Ebbinghaus invented spaced repetition in 1885, I apologize. When compiling the history of SuperMemo, we put the name of the venerable German psychologist at the top of the chronological list and the myth was born. Ebbinghaus never worked over spaced repetition.

如果你认为 Ebbinghaus 在1885年发明了间隔重复，我为此道歉。在编写 SuperMemo 的历史时，我们将这位受人尊敬的德国心理学家的名字放在了时间线的最顶端，于是误解诞生了。实际上 Ebbinghaus 从未研究过间隔重复。

Writing about history of spaced repetition is not easy. Each time we do it, we generate more myths through distortions and misunderstandings. Let’s then make it clear and emphatic. There has been a great deal of memory research before SuperMemo. However, each time I give prolific credit, keep in mind the words of Biedalak:

书写间隔重复的历史并不容易。每次我们这样做，都会因歪曲和误解产生更多的误会。那就让我们明确并强调这一点。在 SuperMemo 之前有很多关于记忆的研究。然而，在我给予他们大量的赞誉的同时，也请记住 Biedalak 的话：

> If SuperMemo is a space shuttle, we need to acknowledge prior work done on bicycles. In the meantime, our competition is busy trying to replicate our shuttle, but the efforts are reminiscent of the Soviet Buran program. Buran has at least made one space flight. It was unmanned
> 
> 如果 SuperMemo 是一艘航天飞机，我们确实需要承认前人为发明自行车所做的贡献。但与此同时，我们的竞争对手复制的是我们的航天飞机本身，这种做法让人想起了苏联的 Buran 计划。Buran 至少还进行了一次太空飞行，而且是无人驾驶的。

This texts is to put the facts straight, and openly disclose the early steps of spaced repetition. This is a fun foray into the past that brings me a particular delight with the sense of “mission accomplished”. Now that we can call our effort a global success, there is no need to make it more respectable than it really is. No need to make it more scientific, more historic, or more certified.

这段文字是为了澄清事实，公开披露间隔重复的早期研究过程。这是一次有趣的过去之旅，给我带来了一种“任务完成”的特别喜悦。现在我们可以称我们的努力为全球性的成功，没有必要再夸大它的受尊敬程度。不需要使其显得更具科学性、更具历史性或更受认可。

Spaced repetition is here and it here to stay. We did it!

间隔重复就在这里，它将一直存在。我们做到了！

### Credits 致谢

The list of contributors to the idea of spaced repetition is too long to include in this short article. Some names do not show up because I simply run out of allocated time to describe their efforts. Dr Phil Pavlik got probably most fresh ideas in the field. An array of memory researchers investigate the impact of spacing on memory. Duolingo and Quizlet are leading competitors with a powerful impact on the good promotion of the idea. I failed to list many of my fantastic teachers who inspired my thinking. The whole host of hard-working and talented people at SuperMemo World would also deserve a mention. Users of SuperMemo constantly contribute incredible suggestions that drive further progress. The reward for most impactful explanation of spaced repetition should go to Gary Wolf of Wired, but there were many more. Perhaps some other day, I will have more time to write about all those great people in detail.

对间隔重复理念做出贡献的人名单太长，无法全部包含在这篇短文中。有些名字没有出现，仅仅是因为我没有足够的时间来描述他们的努力。Phil Pavlik 博士拥有在这个领域可能是最新鲜的想法。许多记忆研究者正在调查间隔对记忆的影响。Duolingo 和 Quizlet 是领先的竞争对手，对这一理念的良好推广有着强大的影响。我没法逐一列出那些激发我思考的出色老师。在 SuperMemo World 工作的众多勤奋和有才华的人也值得一提。SuperMemo 的用户不断提出好到令人难以置信的建议，推动进一步的进展。《连线》杂志的 Gary Wolf 应当享有对间隔重复做出最具影响力的解释的功劳。做出贡献的人还有太多……也许有一天，我会有更多的时间来细数所有这些伟大的人以及他们的贡献。

## 1985年：SuperMemo的诞生（1985: Birth of SuperMemo）

### 追求更有效的学习（The drive for better learning）

I spent 22 long years in the education system. Old truths about schooling match my case perfectly. I never liked school, but I always liked to learn. I never let school interfere with my learning. At entry to university, after 12 years in the public school system, I still loved learning. Schooling did not destroy that love for two main reasons: (1) the system was lenient for me, and, (2) I had full freedom to learn what I like at home. In Communist Poland, I never truly experienced the toxic whip of heavy schooling. The system was negligent and I loved the ensuing freedoms.

我在教育体系中度过了漫长的22年。关于学校的老生常谈与我的经历完全吻合。我从来不喜欢学校，但我总是喜欢学习。我从未让学校干扰我的学习。在进入大学后，经过12年的公立学校系统教育，我仍然热爱学习。学校教育没有摧毁这种热爱，主要有两个原因：（1）这个系统对我比较宽容，以及（2）我在家中有完全的自由去学习我喜欢的东西。在共产主义波兰，我从未真正体验过沉重学校教育的毒害。这个系统疏忽大意，我喜欢随之而来的自由。

We all know that best learning comes from passion. It is powered by the learn drive. My learn drive was strong and it was mixed with a bit of frustration. The more I learned, there more I could see the power of forgetting. I could not remedy forgetting by more learning. My memory was not bad in comparison with other students, but it was clearly a leaky vessel.

我们都知道最好的学习来自于激情。它是由内在的学习驱动力所驱动的。我的学习驱动力很强，并且混合着一些挫败感。我学的越多，就越能看到遗忘的力量。我无法通过更多的学习来弥补遗忘。我的记忆与其它学生相比并不算差，但显然也还是一个有漏洞的容器。

In 1982, I paid more attention to what most students discover sooner or later: testing effect. I started formulating my knowledge for active recall. I would write questions on the left side of a page and answers in a separate column to the right:

1982年，我开始更加关注大多数学生迟早会发现的事情：测试效应。我开始为我的知识制定主动回忆的方案。我会在一页纸的左侧写上问题，在右侧的单独一栏写上答案：

![[500px-Woz_Pol-Eng_word_pairs.jpg]]

This way, I could cover the answers with a sheet of paper, and employ active recall to get a better memory effect from review. This was a slow process but the efficiency of learning increased dramatically. My notebooks from the time are described as *“fast assimilation material”*, which referred to the way my knowledge was written down.

通过这种方式，我可以用一张纸覆盖答案，运用主动回忆来获得更好的记忆效果。这是一个缓慢的过程，但学习效率显著提高。我那个时期的笔记本被描述为“快速吸收材料”，这指的是我记录知识的方式。

In the years 1982-1983, I kept expanding my “fast assimilation” knowledge in the areas of biochemistry and English. I would review my pages of information from time to time to reduce forgetting. My retention improved but it was only a matter of time when I would hit the wall again. The more pages I had, the less frequent the review, the more obvious the problem of leaking memory. Here is an example of a repetition history from that time:

在1982-1983年间，我在生物化学和英语领域不断扩大我的“快速吸收”知识。我会不时回顾我的信息页面，以减少遗忘。我的记忆保持能力有所提高，但壁垒始终存在，再次遇到记忆泄漏只是时间问题。我拥有的页面越多，回顾的频率就越低，记忆泄漏的问题就越明显。以下是那个时期重复历史的一个例子：

![[300px-Woz_review_table.jpg]]

Between June 1982 and December 1984, my English-Polish word-pairs notebook included 79 pages looking like this:

在1982年6月至1984年12月之间，我的英语-波兰语单词对笔记本包含了79页，看起来像这样：

![[English-Polish_word_pairs_Wozniak_1982.jpg]]

> ***Figure:** A typical page from my English-Polish words notebook started in June 1982. Word pairs would be listed on the left. Review history would be recorded on the right. Recall errors would be marked as dots in the middle*
> 
> ***图**：这是我从1982年6月开始的英语-波兰语单词笔记本的一个典型页面。单词对会列在左边，复习历史记录在右边。回忆错误会在中间用点标记*。

Those 79 pages would encompass a mere 2794 words. This is just a fraction of what I needed, and already quite a headache to review. Interestingly, I started learning English in an active way, i.e. using Polish-English word pairs only in 1984, i.e. with two years delay. I was simply late to discover that passive knowledge of vocabulary is ok in reading, but it is not enough to speak a language. This kind of ignorance after 6 years of schooling is a norm. Schools do a lot of drilling, but shed very little light on what makes efficient learning.

这79页仅包含2794个单词。这只是我需要的一小部分，而且已经相当难以复习。有趣的是，在1984年，也就是两年后，我开始通过一种积极主动的方式学习英语，即只使用波兰语-英语单词对。我只是花了些时间才发现，被动词汇知识足以应付阅读，但不足以让你开口说一门语言。在6年的学校教育后还有这种无知是常态。学校做了很多练习，但对什么使学习更有效却鲜有启发。

In late 1984, I decided to improve the review process and carry out an experiment that has changed my life. In the end, three decades later, I am super-proud to notice that it actually affected millions. It has opened the floodgates. We have an era of faster and better learning.

1984年底，我决定改进复习过程，并进行一个改变了我生活的实验。最终，三十年后，我非常自豪地注意到它实际上影响了数百万人。它开启了变革之门。为我们带来了一个学习更快更好的时代。

This is how this initial period was described in my Master’s Thesis in 1990:

这是我在1990年的硕士论文中对最初时期的描述：

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

It was 1982 when I made my first observations concerning the mechanism of memory that were later used in the formulation of the SuperMemo method. As a then student of molecular biology I was overwhelmed by the amount of knowledge that was required to pass exams in mathematics, physics, chemistry, biology, etc. The problem was not in being unable to master the knowledge. Usually 2-3 days of intensive studying were enough to pack the head with data necessary to pass an exam. The frustrating point was that only an infinitesimal fraction of newly acquired wisdom could remain in memory after few months following the exam.

在1982年，我首次对记忆的机制进行了观察，相关发现后来被用于构建 SuperMemo 方法。当时作为分子生物学的学生，我被数学、物理、化学、生物等科目的考试所需要的知识量压倒。问题不在于无法掌握知识。通常2-3天的密集学习就足以在考试前将必要的数据填满头脑。令人沮丧的是，考试后几个月，新获得的智慧中只有极小一部分能留在记忆中。

My first observation, obvious for every attentive student, was that one of the key elements of learning was active recall. This observation implies that passive reading of books is not sufficient if it is not followed by an attempt to recall learned facts from memory. The principle of basing the process of learning on recall will be later referred to as the **active recall principle**. The process of recalling is much faster and not less effective if the questions asked by the student are specific rather than general. It is because answers to general questions contain redundant information necessary to describe relations between answer subcomponents.

我的第一个发现，也是对每个细心的学生都显而易见的事实，那就是学习的一个关键要素是主动回忆。这一发现意味着，仅仅被动阅读书籍是不够的，我们必须在阅读之后主动回忆学到的知识。将学习过程建立在回忆上的原则，后来被称为主动回忆原则。如果学生提出的问题是具体的（而非宽泛的），回忆过程会快得多，效果却并不会变差。这是因为宽泛问题的答案往往包含描述答案子集之间关系所必需的冗余信息。

To illustrate the problem let us imagine an extreme situation in which a student wants to master knowledge contained in a certain textbook, and who uses only one question in the process of recall: What did you learn from the textbook? Obviously, information describing the sequence of chapters of the book would be helpful in answering the question, but it is certainly redundant for what the student really wants to know. The principle of basing the process of recall on specific questions will be later referred to as the **minimum information principle** . This principle appears to be justified not only because of the elimination of redundancy.

为了说明问题，让我们想象一个极端情况，一个学生想要掌握某本教科书中包含的知识，并且在回忆过程中只使用一个问题：你从教科书中学到了什么？显然，描述书籍章节顺序的信息在回答问题时会有帮助，但相比于学生真正想知道的来说，这当然是冗余的。将回忆过程建立在具体问题上的原则，后来被称为最小信息原则。随后人们发现，这一原则的合理似乎还不只是因为它能消除冗余。

Having the principles of active recall and minimum information in mind, I created my first databases (i.e. collections of questions and answers) used in an attempt to retain the acquired knowledge in memory. At that time the databases were stored in a written form on paper. My first database was started on June 6, 1982, and was composed of pages that contained about 40 pairs of words each. The first word in a pair (interpreted as a question) was an English term, the second (interpreted as an answer) was its Polish equivalent. I will refer to these pairs as **items**. I repeated particular pages in the database in irregular intervals (dependent mostly on the availability of time) always recording the date of the repetition, items that were not remembered and their number. This way of keeping the acquired knowledge in memory proved sufficient for a moderate-size database on condition that the repetitions were performed frequently enough.

考虑到主动回忆和最小信息的原则，我创建了我的第一个数据库（即问题和答案的集合），用于尝试将获得的知识保留在记忆中。当时，数据库以书面形式存储在纸上。我的第一个数据库始于1982年6月6日，由每页包含大约40对单词的页面组成。一对单词中的第一个词（视作问题）是英语术语，第二个词（视作答案）是它的波兰语对应词。我将把这些对称为项目。我按照不规则的间隔（主要取决于可用的时间）重复数据库中的特定页面，总是记录重复的日期、没有记住的项目及其数量。并证实了只要复习足够频繁，这种记忆知识的方法对于中等大小的数据库来说是足够了。

### 间隔重复的生日：1985年7月31日（The birthday of spaced repetition: July 31, 1985）

#### 直觉（Intuitions）

In 1984, my reasoning about memory was based on two simple intuitions that probably all students have:

在1984年，我对记忆的理解基于两个简单的直觉，这些直觉可能是所有学生都有的：

-   if we review something twice, we remember it better. That’s pretty obvious, isn’t it? If we review it 3 times, we probably remember it even better
-   if we remember a set of notes, they will gradually disappear from memory, i.e. not all at once. This is easy to observe in life. Memories have different lifetimes

- 如果我们复习某件事两次，我们会记得更好。这很明显，不是吗？如果我们复习三次，我们可能会记得再好一些。
- 如果我们记住了一组笔记，它们会逐渐从记忆中消失，而不是一次性全部消失。这在生活中很容易观察到。记忆有不同的寿命。

These two intuitions should make everyone wonder: how fast and how many notes we lose and when we should review next?

这两个直觉应该让每个人都想知道：我们遗忘笔记的速度有多快？特定时间后被遗忘的笔记占总量多少？我们下次应该何时复习？

To this day, I am amazed that very few people ever bothered to measure that ” optimum interval“. When I measured it myself, I was sure I would find more accurate results in books on psychology. I did not.

直到今天，我仍然惊讶于很少有人去测量那个“最优间隔”。当我自己测量时，我曾确信我会在心理学书籍中找到更准确的结果。但我从未找到。

#### 实验（Experiment）

The following simple experiment led to the birth of spaced repetition. It was conducted in 1985 and first described in my Master’s Thesis in 1990. It was used to establish optimum intervals for the first 5 repetitions of pages of knowledge. Each page contained around 40 word-pairs and the optimum interval was to approximate the moment in time when roughly 5-10% of that knowledge was forgotten. Naturally, the intervals would be highly suited for that particular type of learning material and for a specific person, in this case, me. In addition, to speed things up, the measurement samples were small. Note that this was not a research project. It was not intended for publication. The goal was to just speed up my own learning. I was convinced someone else must have measured the intervals much better, but 13 years before the birth of Google, I thought measuring the intervals would be faster than digging into libraries to find better data. The experiment ended on Aug 24, 1985, which I originally named the birthday of spaced repetition. However, while writing this text in 2018, I found the original learning materials, and it seems my eagerness to learn made me formulate an outline of an algorithm and start learning human biology on Jul 31, 1985.

以下简单的实验导致了间隔重复的诞生。它在1985年进行，并于1990年首次在我的硕士论文中被描述。它被用来确定知识页面前5次复习的最优间隔。每一页包含大约40个词对，最优复习间隔是大约5-10%的知识被遗忘的时间。自然地，这样的间隔将非常适合那些特定类型的学习材料和特定的人，在这个案例中，就是我自己。此外，为了加快速度，测量样本很小。请注意，这不是一个研究项目。它不打算发表。目标只是为了加快我自己的学习。我相信一定有人更好地测量了这些间隔，但在谷歌诞生的13年前，我认为自行测量间隔会比在图书馆查找更好的数据来的更快。实验在1985年8月24日结束，我最初将其命名为间隔重复的生日。然而，当我在2018年写这篇文章时，我发现了原始的学习材料，似乎我对学习的渴望让我在1985年7月31日制定了一个算法的大纲，并开始学习人类生物学。

For that reason, I can say that the most accurate birthday of SuperMemo and computational spaced repetition was Jul 31, 1985.

因此，我可以说，SuperMemo 和计算间隔重复最准确的诞生日是1985年7月31日。

By July 31, before the end of the experiment, the results seemed predictable enough. In later years, the findings of this particular experiment appeared pretty universal and could be extended to more areas of knowledge and to the whole healthy adult population. Even in 2018, the default settings of Algorithm SM-17 do not depart far from those rudimentary findings.

到了实验结束前的7月31日，结果似乎已经可以预见。在后来的几年里，这个特定实验的结论看起来适用范围相当广泛，可以应用于更多的知识领域和所有健康的成年人口。即使在2018年，算法 SM-17 的默认设置也并未偏离那些基本的发现。

Spaced repetition was born on Jul 31, 1985.

间隔重复诞生于1985年7月31日。

Here is the original description of the experiment from my Master’s Thesis with minor corrections to grammar and style. Emphasis in the text was added in 2018 to highlight important parts. If it seems boring and unreadable, compare Ebbinghaus 1885. This is the same style of writing in the area of memory. Only goals differed. Ebbinghaus tried to understand memory. 100 years later, I just wanted to learn faster:

以下是我硕士论文中对实验的原始描述，对语法和风格进行了轻微的更正。2018年在文本中添加了强调以突出重要部分。如果它看起来无聊且难以阅读，可以和 Ebbinghaus 1885比较。记忆研究领域的写作风格基本都是如此。唯一的区别在于目标。Ebbinghaus 试图理解记忆。100年后，我只想更快地学习：

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

**Experiment intended to approximate the length of optimum inter-repetition intervals** (Feb 25, 1985 – Aug 24, 1985):

**旨在寻找最优重复间隔（的时长）的实验**（1985年2月25日至8月24日）：

1.  The experiment consisted of stages A, B, C, … etc. Each of these stages was intended to calculate the second, third, fourth and further quasi-optimal inter-repetition intervals (the first interval was set to one day as it seemed the most suitable interval judging from the data collected earlier). The criterion for establishing quasi-optimal intervals was that they should be as long as possible and allow for not more than 5% loss of remembered knowledge.
2.  The memorized knowledge in each of the stages A, B, C, consisted of 5 pages containing about 40 items in the following form:*Question*: English word,*Answer*: its Polish equivalent.
3.  Each of the pages used in a given stage was memorized in a single session and repeated next day. To avoid confusion note, that in order to simplify further considerations I use the term first repetition to refer to memorization of an item or a group of items. After all, both processes, memorization and relearning, have the same form – answering questions as long as it takes for the number of errors to reach zero.
4.  In the stage A (Feb 25 – Mar 16), the third repetition was made in intervals 2, 4, 6, 8 and 10 days for each of the five pages respectively. The observed loss of knowledge after these repetitions was 0, 0, 0, 1, 17 percent respectively. The seven-day interval was chosen to approximate the second quasi-optimal inter-repetition interval separating the second and third repetitions.
5.  In the stage B (Mar 20 – Apr 13), the third repetition was made after seven-day intervals whereas the fourth repetitions followed in 6, 8, 11, 13, 16 days for each of the five pages respectively. The observed loss of knowledge amounted to 3, 0, 0, 0, 1 percent. The 16-day interval was chosen to approximate the third quasi-optimal interval. NB: it would be scientifically more valid to repeat the stage B with longer variants of the third interval because the loss of knowledge was little even after the longest of the intervals chosen; however, I was then too eager to see the results of further steps to spend time on repeating the stage B that appeared sufficiently successful (i.e. resulted in good retention)
6.  In the stage C (Apr 20 – Jun 21), the third repetitions were made after seven-day intervals, the fourth repetitions after 16-day intervals and the fifth repetitions after intervals of 20, 24, 28, 33 and 38 days. The observed loss of knowledge was 0, 3, 5, 3, 0 percent. The stage C was repeated for longer intervals preceding the fifth repetition (May 31 – Aug 24). The intervals and memory losses were as follows: 32-8%, 35-8%, 39-17%, 44-20%, 51-5% and 60-20%. The 35-day interval was chosen to approximate the fourth quasi-optimal interval.

1. 实验包括 A、B、C 等阶段。每个阶段旨在计算第二次、第三次、第四次及以后的准最优重复间隔（第一个间隔被设定为一天，因为根据之前收集的数据，这似乎是最合适的间隔）。建立准最优间隔的标准是它们应该尽可能长，并且允许损失的知识记忆不超过5%。
2. 在 A、B、C 阶段中记忆的知识包括5页，每页包含大约40个项目，形式如下：_问题_：英文单词，_答案_：它的波兰语对应词。
3. 在给定阶段中使用的每页都在单次活动中被记忆，并在第二天重复。为了避免混淆，请注意，为了简化进一步的思考，我使用“第一次重复”这个术语来指代记忆一个项目或一组项目。毕竟，记忆和重新学习这两个过程的形式相同——回答问题，直到错误数量达到零。
4. 在 A 阶段（2月25日至3月16日），第三次重复分别在2、4、6、8和10天的间隔后进行。这些重复后观察到的知识损失分别为0、0、0、1、17%。因此我们选择了7的间隔来近似第二次准最优间隔。用它来分隔第二次和第三次重复。
5. 在 B 阶段（3月20日至4月13日），第三次重复在7天的间隔后进行，而第四次重复分别在6、8、11、13、16天后进行。观察到的知识损失为3、0、0、0、1%。选择了16天的间隔来近似第三次准最优间隔。注意：从科学上讲，重复B阶段并使用更长的第三次间隔变体会更有效，因为即使在选定的最长间隔后，知识损失也很小；然而，当时我太急于看到后续步骤的结果，不想花时间在看起来足够成功的B阶段上（即，结果在良好的记忆保持中）。
6. 在 C 阶段（4月20日至6月21日），第三次重复在7天的间隔后进行，第四次重复在16天的间隔后进行，第五次重复在20、24、28、33和38天的间隔后进行。观察到的知识损失为0、3、5、3、0%。C 阶段因需要测试第五次重复前的更长间隔而被重做（5月31日至8月24日）。间隔和记忆损失如下：32-8%，35-8%，39-17%，44-20%，51-5%和60-20%。因此我们选择了35天的间隔来近似第四次准最优间隔。

It is not difficult to notice, that each of the stages of the described experiment took about twice as much time as the previous one. It could take several years to establish first ten quasi-optimal inter-repetition intervals. Indeed, I continued experiments of this sort in following years in order to gain deeper understanding of the process of optimally spaced repetitions of memorized knowledge. However, at that time, I decided to employ the findings in my day-to-day process of routine learning.

不难注意到，论文中描述的实验的每个阶段大约需要前一个阶段的两倍时间。建立前十个准最优重复间隔可能需要几年时间。事实上，我确实在随后的年份继续进行了这类实验，以更深入地理解最优间隔重复记忆知识的过程。然而，当时，我决定将这些发现应用于我的日常学习过程中。

On July 31, 1985, I could already sense the outcome of the experiment. I started using SuperMemo on paper to learn human biology. That would be the best date to call for the birthday of SuperMemo.

在1985年7月31日，我已经能够感知到实验的结果。我开始使用纸面上的 SuperMemo 来学习人类生物学。那是最适合被称作 SuperMemo 生日的一天。

### 1985年7月31日的事件（The events of July 31, 1985）

On July 31, 1985, SuperMemo was born. I had most of my data from my spaced repetition experiment available. As an eager practitioner, I did not wait for the experiment to end. I wanted to start learning as soon as possible. Having built a great deal of notes in human biology, I started converting those notes into *Special Memorization Test* format (SMT was the original name for SuperMemo, and spaced repetition).

1985年7月31日，SuperMemo 诞生了。我已经从我的间隔重复实验中得到了大部分数据。作为一个热切的实践者，我已经等不及实验结束。我只想尽快开始学习。在积累了大量人类生物学的笔记之后，我开始将这些笔记转换成“特殊记忆测试”（SMT）格式（SMT是SuperMemo和间隔重复的最初名称）。

![[SuperMemo_Memorization_Test_Human_biology_1985.07.31.jpg]]

> ***Figure:** Human biology in the Special Memorization Test format started on Jul 31, 1985 (i.e. the birth of SuperMemo)*
> 
> _**图示：** 1985年7月31日，SMT格式的人类生物学笔记诞生（即SuperMemo的诞生）

My calculations told me that, at 20 min/day, I would need 537 days to process my notes and finish the job by January 1987. I also computed that each page of the test would likely cost me 2 hours of life. Despite all the promise and speed of SuperMemo, this realization was pretty painful. The speed of learning in college is way too fast for the capacity of human memory. Now that I could learn much faster and better, I also realized I wouldn’t cover even a fraction of what I thought was possible. Schools make no sense with their volume and speed. On the same day, I found out that the Polish communist government lifted import tariffs on microcomputers. This should make it possible, at some point, to buy a computer in Poland. This opened a way to SuperMemo for DOS 2.5 years later.

我的计算告诉我，以每天20分钟的速度，我需要537天来处理我的笔记，并在1987年1月之前完成这项工作。我还计算出，每页测试可能需要我花费2小时的生命。尽管 SuperMemo 充满希望和速度，这种认识还是非常痛苦的。大学的学习速度对于人类记忆的能力来说太快了。现在我可以学得更快、更好，我也意识到我甚至无法覆盖我曾经认为能够学完知识的一小部分。学校的教学量和速度是没有意义的。就在同一天，我发现波兰共产党政府取消了微型计算机的进口关税。这应该会在某个时候使在波兰购买计算机成为可能。这就为两年半后 SuperMemo for DOS 的诞生铺平了道路。

Also on July 31, I noted that if vacation could last forever, I would achieve far more in learning and even more in life. School is such a waste of time. However, the threat of conscription kept me in line. I would enter a path that would make me enroll in university for another 5 years. However, most of that time was devoted to SuperMemo and I have few regrets.

同样在7月31日，我注意到如果假期可以无限延长，我在学习和生活中会取得多得多的成就。学校真是浪费时间。然而，征兵的威胁限制了我的选择。我将走上一条让我在大学耗费五年的道路。然而，那段时间的大部分都投入到了 SuperMemo 中，我几乎没有什么遗憾。

My spaced repetition experiment ended on Aug 24, 1985. I also started learning English vocabulary. By that day, I managed to have most of my biochemistry material written down in pages for SuperMemo review.

我的间隔重复实验在1985年8月24日结束。我也开始学习英语词汇。到那天为止，我设法将大部分生物化学材料写下来，用于SuperMemo的复习。

Note: My Master’s Thesis mistakenly refers to Oct 1, 1985 as the day when I started learning human biology (not July 31 as seen in the picture above). Oct 1, 1985 was actually the first day of my computer science university and was otherwise unremarkable. With the start of the university, my time for learning and energy for learning were cut dramatically. Paradoxically, the start of school always seems to augur the end of good learning.

注：我的硕士论文错误地提到1985年10月1日是我开始学习人类生物学的日子（而不是上图所示的7月31日）。1985年10月1日实际上是我计算机科学大学的第一天，并没有什么特别的。随着大学生活的开始，我用于学习和学习精力的时间大大减少了。矛盾的是，（对我来说）学校的开始似乎反而预示着良好学习的结束。

### 第一个间隔重复算法：算法SM-0，1985年8月25日（First spaced repetition algorithm: Algorithm SM-0, Aug 25, 1985）

As a result of my spaced repetition experiment, I was able to formulate the first spaced repetition algorithm that required no computer. All learning had to be done on paper. I did not have a computer back in 1985. I was to get my first microcomputer, ZX Spectrum, only in 1986. SuperMemo had to wait for the first computer with a floppy disk drive (Amstrad PC 1512 in the year 1987).
  
作为我间隔重复实验的结果，我能够制定出第一个不需要计算机的间隔重复算法。所有的学习都必须在纸上完成。1985年的时候我还没有计算机。直到1986年我才得到我第一台微型计算机，ZX Spectrum。SuperMemo 不得不等到1987年才用上了第一台带有软盘驱动器的计算机（Amstrad PC 1512）。

I often get asked this simple question: *“How can you formulate SuperMemo after an experiment that lasted 6 months? How can you predict what would happen in 20 years?”*

我经常被问到这个简单的问题：“你怎么能在一个只持续了6个月的实验之后制定SuperMemo？你怎么能预测20年后会发生什么？”

The first experiments in reference to the length of optimum interval resulted in conclusions that made it possible to predict the most likely length of successive inter-repetition intervals without actually measuring retention beyond weeks! In short, it could be illustrated with the following reasoning. If the first months of research yielded the following optimum intervals: 1, 2, 4, 8, 16 and 32 days, you could hope with confidence that the successive intervals would increase by a factor of two.

第一次关于最优间隔长度的实验得出的结论使得人们能够在不实际测量超过几周的记忆保持的情况下，预测连续复习间隔的最可能长度！简而言之，可以用以下推理来说明。如果最初几个月的研究得出了以下最优间隔：1天、2天、4天、8天、16天和32天，你可以有信心地期待后续间隔会以两倍的因子增加。

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

**Algorithm SM-0 used in spaced repetition without a computer (Aug 25, 1985)**

1.  Split the knowledge into smallest possible question-answer items
2.  Associate items into groups containing 20-40 elements. These groups are later called pages
3.  Repeat whole pages using the following intervals (in days):I(1)=1 dayI(2)=7 daysI(3)=16 daysI(4)=35 daysfor i>4: I(i):=I(i-1)*2where:
    -   I(i) is the interval used after the i-th repetition
4.  Copy all items forgotten after the 35th day interval into newly created pages (without removing them from previously used pages). Those new pages will be repeated in the same way as pages with items learned for the first time

**无需电脑的 SM-0 间隔重复算法（1985年8月25日）**

1. 将知识分割成尽可能小的问题-答案项
2. 将项关联成包含20-40个元素的组。这些组后来被称为页面
3. 使用以下间隔（以天为单位）重复整个页面：I(1)=1天，I(2)=7天，I(3)=16天，I(4)=35天，对于i>4：I(i):=I(i-1)*2，其中：
    - I(i) 是在第 i 次重复后使用的间隔
4. 将35天后遗忘的所有项复制到新创建的页面中（不将它们从先前使用的页面中移除）。这些新页面将与首次学习的页面以相同的方式重复。

Note, that inter-repetition intervals after the fifth repetition were assumed to increase twice in subsequent repetitions. This fact was based on an intuition rather than on experiment. In two years of using the Algorithm SM-0 sufficient data were collected to confirm a reasonable accuracy of this assumption.

注意，第五次重复后的复习间隔被假定在随后的重复中翻倍增加。这一事实是基于直觉而非实验。在使用算法 SM-0 的两年中，收集到的足够数据证实了这一假设的合理准确性。

To this day I hear some people use or even prefer the paper version of SuperMemo. Here is a description from 1992.

直到今天，我仍然听说有些人使用甚至更喜欢 SuperMemo 的纸质版本。以下是1992年的描述。

Note that the intuition that intervals should increase twice is as old as the theory of learning. In 1932, C. A. Mace hinted on the efficient learning methods in his book ” *The psychology of study*“. He mentioned ” *active rehearsal*” and ” *repetitive revisions*” that should be spaced in gradually increasing intervals, roughly ” *intervals of one day, two days, four days, eight days, and so on*“. This proposition was later taken on by other authors. Those included Paul Pimsleur and Tony Buzan who both proposed their own intuitions that involved very short intervals (in minutes) or “final repetition” (after a few months). All those ideas did not permeate well into the practice of study beyond the learning elites. Only a computer application made it possible to start learning effectively without studying the methodology.

注意，间隔应该翻倍的直觉和学习理论本身一样古老。在1932年，C. A. Mace 在他的书《学习心理学》中暗示了有效的学习方法。他提到了“主动复述”和“重复回顾”，这两项应该在逐渐增加的间隔中进行，大致是“一天、两天、四天、八天等”。这一提议后来被其他作者采纳。其中包括 Paul Pimsleur 和 Tony Buzan，他们都提出了自己的直觉，涉及非常短的间隔（以分钟计）或“最终重复”（几个月后）。但所有这些想法并没有很好地渗透到学习精英们之外的学习实践中。直到计算机应用使得人们可以在不学习方法论的情况下开始有效学习。

That intuitive interval multiplication factor of 2 has also shown up in the context of studying the possibility of evolutionary optimization of memory in response to statistic properties of the environment: ” **Memory is optimized to meet probabilistic properties of the environment** “

那个直观的间隔翻倍因子也出现在“记忆为适应环境统计特性，而发生进化优化”的可能性的研究中：“记忆被优化以满足环境的概率特性”。

Despite all its simplicity, in my Master’s Thesis, I did not hesitate to call my new method “revolutionary”:

尽管非常简单，在我的硕士论文中，我毫不犹豫地称我的新方法为“革命性”：

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

Although the acquisition rate may not have seemed staggering, the Algorithm SM-0 was revolutionary in comparison to my previous methods because of two reasons:

尽管获取知识的速率看起来可能并不惊人，但与我之前的方法相比，算法 SM-0 具有革命性，原因有以下两点：

-   with the lapse of time, knowledge retention increased instead of decreasing (as it was the case with intermittent learning)
-   in a long term perspective, the acquisition rate remained almost unchanged (with intermittent learning, the acquisition rate would decline substantially over time)

- 随着时间的推移，知识保持率增加了，而不是减少了（就像间歇学习那样）。
- 从长远来看，获取知识的速率几乎保持不变（相比之下，间歇学习获取知识的速率会随时间大幅下降）。

[…]

For the first time, I was able to reconcile high knowledge retention with infrequent repetitions that in consequence led to steadily increasing volume of knowledge remembered without the necessity to increase the timeload!

有史以来第一次，我能够在保持高知识保留率的同时，减少重复次数，从而使记忆的知识量稳步增加，并且无需增加时间投入！

Retention of 80% was easily achieved, and could even be increased by shortening the inter-repetition intervals. This, however, would involve more frequent repetitions and, consequently, increase the timeload. The assumed repetition spacing provided a satisfactory compromise between retention and workload.

80%的保留率很容易达到，甚至可以通过缩短重复间隔来进一步提高。然而，这将涉及更频繁的重复，从而增加时间投入。假设的重复间隔在兼顾保留率和工作量的前提下，提供了令人满意的折衷方案。

[…]The next significant improvement of the Algorithm SM-0 was to come only in 1987 after the application of a computer to supervise the learning process. In the meantime, I accumulated about 7190 and 2817 items in my new English and biological databases respectively. With the estimated working time of 12 minutes a day for each database, the average knowledge acquisition rate amounted to 260 and 110 items/year/minute respectively, while knowledge retention amounted to 80% at worst.

算法 SM-0 的下一个重大改进直到1987年，计算机被应用于监督学习过程之后才出现。在此期间，我在新的英语和生物学知识库中分别积累了约7190个和2817个新项目。 每个数据库每天的预计学习时间为12分钟，平均知识获取率分别为260和110项/年/分钟，而知识保留率最低为80%。

### SuperMemo 诞生十周年回顾（Birth of SuperMemo from a decade’s perspective）

A decade after the birth of SuperMemo, it became pretty well-known in Poland. Here is the same story as retold by J. Kowalski, Enter in 1994:

SuperMemo诞生十年后，在波兰已经相当知名。以下是 J. Kowalski 于1994年讲述的一则故事：

> It was 1982, when a 20-year-old student of molecular biology at Adam Mickiewicz University of Poznan, Piotr Wozniak, became quite frustrated with his inability to retain newly learned knowledge in his brain. This referred to the vast material of biochemistry, physiology, chemistry, and English, which one should master wishing to embark on a successful career in molecular biology. One of the major incentives to tackle the problem of forgetting in a more systematic way was a simple calculation made by Wozniak which showed him that by continuing his work on mastering English using his standard methods, he would need 120 years to acquire all the important vocabulary. This not only prompted Wozniak to work on methods of learning, but also, turned him into a determined advocate of the idea of one language for all people (bearing in mind the time and money spent by the mankind on translation and learning languages). 
> Initially, Wozniak kept increasing piles of notes with facts and figures he would like to remember. It did not take long to discover that forgetting requires frequent repetitions and a systematic approach is needed to manage all the newly collected and memorized knowledge. Using an obvious intuition, Wozniak attempted to measure the retention of knowledge after different inter-repetition intervals, and in 1985 formulated the first outline of SuperMemo, which did not yet require a computer. By 1987, Wozniak, then a sophomore of computer science, was quite amazed with the effectiveness of his method and decided to implement it as a simple computer program. The effectiveness of the program appeared to go far beyond what he had expected. This triggered an exciting scientific exchange between Wozniak and his colleagues at Poznan University of Technology and Adam Mickiewicz University. A dozen of students at his department took on the role of guinea pigs and memorized thousands of items providing a constant flow of data and critical feedback. Dr Gorzelańczyk from Medical Academy was helpful in formulating the molecular model of memory formation and modeling the phenomena occurring in the synapse. Dr Makałowski from the Department of Biopolymer Biochemistry contributed to the analysis of evolutionary aspects of optimization of memory (NB: he was also the one who suggested registering SuperMemo for Software for Europe). Janusz Murakowski, MSc in physics, currently enrolled in a doctoral program at the University of Delaware, helped Wozniak solve mathematical problems related to the model of intermittent learning and simulation of ionic currents during the transmission of action potential in nerve cells. A dozen of forthcoming academic teachers, with Prof. Zbigniew Kierzkowski in forefront, helped Wozniak tailor his program of study to one goal: combining all aspects of SuperMemo in one cohesive theory that would encompass molecular, evolutionary, behavioral, psychological, and even societal aspects of SuperMemo. Wozniak who claims to have discovered at least several important and never-published properties of memory, intended to solidify his theories by getting a PhD in neuroscience in the US. Many hours of discussions with Krzysztof Biedalak, MSc in computer science, made them both choose another way: try to fulfill the vision of getting with SuperMemo to students around the world.

> 1982年，波兹南亚当·密茨凯维奇大学分子生物学专业的20岁学生 Piotr Wozniak 对无法在大脑中保留新学知识感到非常沮丧。这指的是生物化学、生理学、化学和英语的大量材料，要想在分子生物学领域取得成功的职业生涯，就必须掌握这些材料。更系统地解决遗忘问题的主要动机之一是 Wozniak 进行的一项简单计算，该计算表明，如果继续使用标准方法掌握英语，他将需要120年才能掌握所有重要的词汇。这不仅促使 Wozniak 研究学习方法，而且还使他成为“人类一语通”这一理念的坚定倡导者（考虑到人类在翻译和语言学习上花费的时间和金钱）。
> 最初，Wozniak 不断增加笔记，记录下他想记住的事实和数据。他很快就发现，对抗遗忘需要频繁地复习知识，并且需要一种系统的方法来管理所有新收集和记忆的知识。出于明显的直觉，Wozniak 试图测量不同重复间隔后知识的保留情况，并在1985年制定了 SuperMemo 的第一个大纲，当时还没用到计算机。到1987年，当时是计算机科学二年级的 Wozniak 对他的方法的有效性感到非常惊讶，并决定将其实现为一个简单的计算机程序。该程序的有效性似乎远远超出了他的预期。
> 这引发了 Wozniak 与波兹南理工大学和亚当·密茨凯维奇大学同事之间令人兴奋的科学交流。他所在系的十多名学生担任了“小白鼠”的角色，记忆了数千个项目，提供了源源不断的数据和关键反馈。医学院的 Gorzelańczyk 博士在制定记忆形成的分子模型和模拟突触中发生的现象方面做出了很大帮助。生物聚合物生物化学系的 Makałowski 博士为记忆优化进化方面的分析做出了贡献（注：他也是建议为 SuperMemo 注册“欧洲软件”的人）。物理学硕士 Janusz Murakowski 目前就读于特拉华大学的博士课程，帮助 Wozniak 解决了与间歇学习模型和神经细胞动作电位传递过程中离子电流模拟相关的数学问题。十几位即将成为大学教师的人，以 Zbigniew Kierzkowski 教授为首，帮助 Wozniak 将他的学习计划调整为一个目标：将 SuperMemo 的所有方面结合成一个连贯的理论，涵盖 SuperMemo 的分子、进化、行为、心理甚至社会方面。Wozniak 声称自己发现了至少几个重要且从未发表过的记忆特性，他打算通过在美国获得神经科学博士学位来巩固他的理论。与计算机科学硕士 Krzysztof Biedalak 进行的数小时的讨论，使他们两人选择了另一种方式：尝试实现将 SuperMemo 推广到世界各地学生的愿景。

## 1986年：SuperMemo 初试身手（1986: First steps of SuperMemo）

### 纸质版的 SuperMemo（SuperMemo on paper）

On Feb 22, 1984, I computed that at my learning rate and my investment in learning, it would take me 26 years to master English (in SuperMemo, Advanced English standard is 4 years at 40 min/day). With the arrival of SuperMemo on paper that statistic improved dramatically.

1984年2月22日，我计算出以我的学习速度和学习投入，掌握英语需要26年（在 SuperMemo 中，高级英语标准为每天40分钟，4年）。随着纸质版 SuperMemo 的到来，这一统计数据有了显著的改善。

In summer 1985, using SuperMemo on paper, I started learning with great enthusiasm. For the first time ever, I knew that all investment in learning would pay. Nothing could slip through the cracks. This early enthusiasm makes me wonder why I did not share my good news with others.

1985年夏天，我开始使用纸质版的 SuperMemo，充满热情地学习。我第一次知道，所有对学习的投入都会得到回报。任何努力都不会徒劳无功。这种早期的热情让我感到奇怪，为什么我没有与他人分享我的好消息。

SuperMemo wasn’t a “secret weapon” that many users employ to impress others. I just thought that science must have answered all questions related to efficient learning. My impression was that I only patched my own poor access to western literature with a bit of own investigation. My naivete of the time was astronomical. My English wasn’t good enough to understand news from the west. America was for me a land of super-humans who do super-science, land on the moon, do all major discoveries and will soon cure cancer and become immortal. At the same time, it was a land of Reagan who could blast Poland off the surface of the Earth with Pershing or cruise missiles. That gave me a couple of nightmares. Perhaps the only major source of stress in the early 1980s. I often ponder amazing inconsistencies in the brains of toddlers or kids. To me, the naivete of my early twenties tells me I must have been a late bloomer with very uneven development. Ignorance of English translated to the ignorance of the world. I was a young adult with areas of strength and areas of incredible ignorance. In that context, spaced repetition looks like a child of a need combined with ignorance, self-confidence, and passion.

SuperMemo 对我来说，并不像对许多其他用户那样，是用来给别人留下深刻印象的“秘密武器”。我只是认为科学一定已经回答了与高效学习相关的所有问题。我的印象是，我只是用一点自己的调查来弥补自己对西方文献的无知。我当时的幼稚是惊人的。我的英语不好，无法理解来自西方的新闻。对我来说，美国是一个超人类的国家，他们科研实力惊人，已经登上月球，做出所有重大发现，并将很快治愈癌症，长生不老。同时，这是一个里根统治下的国家，他可以用“潘兴”导弹或巡航导弹将波兰从地球表面炸毁。这让我做了不少噩梦。也许是我80年代早期最大的，也是唯一的压力源。我经常思考婴儿和小孩大脑中惊人的记忆不连贯性。对我来说，我二十出头的幼稚让我以为，我一定是一个发育迟缓且不均衡的人。对英语的无知转化为对世界的无知。当时我成年没多久，有强项，也有令人难以置信的无知。在这种情况下，间隔重复看起来像是（我对长久记忆的）需求与无知、自信和激情相结合的产物。

### 大学生涯（University）

In October 1985, I started my years at a computer science university. I lost my passion for the university in the first week of learning. Instead of programming, we were subject to excruciatingly boring lectures of introductory topics in math, physics, electronics, etc. With a busy schedule, I might have easily become a SuperMemo dropout. Luckily, my love for biochemistry and my need for English would not let me slow down. I continued my repetitions, adding new pages from time to time. Most of all, I had a new dream: to have my own computer and do some programming on my own. One of the first things I wanted to implement was SuperMemo. I would keep my pages on the computer and have them scheduled automatically.

1985年10月，我开始了在计算机科学大学的学习。在学习的第一周，我就失去了对大学的热情。我们没有学习编程，而是听取了枯燥乏味的数学、物理、电子学等入门课程的讲座。日程繁忙，我很容易就成为 SuperMemo 的辍学生。幸运的是，我对生物化学的热爱和对英语的需求不会让我放慢脚步。我继续重复，不时添加新页面。最重要的是，我有一个新的梦想：拥有自己的电脑并自己做一些编程。我想实现的第一件事就是 SuperMemo。我会把我的页面保存在电脑上，并让他们能够自动排列。

I casually mentioned my super-learning method to my high school friend Andrzej “Mike” Kubiak only in summer 1987 (Aug 29). We played football and music together. I finally showed him how to use SuperMemo on Nov 14, 1987. It took 836 days (2 years 3 months and 2 weeks) for me to recruit the first user of SuperMemo. Mike was later my guinea pig in trying out SuperMemo in procedural learning. He kept practicing computer-generated rhythms using a SuperMemo-like schedule. For Mike, SuperMemo was a love at first sight. His vocabulary rocketed. He remained faithful for many years up to a point when the quality of his English outstripped the need for further learning. He is a yogi and his trip to India and regular use of English have consolidated the necessary knowledge for life.

直到1987年夏天（8月29日），我才偶然向我的高中朋友 Andrzej “Mike” Kubiak 提到了我的超级学习方法。我们一起踢足球和演奏音乐。我终于在1987年11月14日向他展示了如何使用 SuperMemo。我花了836天（2年3个月零2周）才招募到 SuperMemo 的第一位用户。迈克后来成为我在尝试程序性学习中使用 SuperMemo 的“小白鼠”。他一直按照类似 SuperMemo 的时间表来练习（由计算机生成练习周期）。迈克对 SuperMemo 是一见钟情。他的词汇量猛增。他多年来勤学不辍，直到他的英语水平超过了进一步学习的需要。作为一位瑜伽士，他的印度之旅和英语的日常使用进一步巩固了他生活中需要的知识。

### 我的第一台计算器（ZX Spectrum）

In 1986 and 1987, I kept thinking about SuperMemo on a computer more and more often. Strangely, initially, I did not think much about the problem of separating pages into individual flashcards. This illustrates how close-minded we can be when falling into a routine of doing the same things daily. To get to the status of 2018, SuperMemo had to undergo dozens of breakthroughs and similarly obvious microsteps. It is all so simple and obvious in hindsight. However, there are hidden limits of human thinking that prevented incremental reading from emerging a decade earlier. Only a fraction of those limits is in technology.

在1986年和1987年，我越来越频繁地思考将 SuperMemo 搬到计算器上。奇怪的是，最初，我没有过多考虑将页面分成单个抽认卡的问题。这说明了当我们每天都陷入例行公事时，我们的思想会变得多么封闭。为了达到2018年的状态，SuperMemo 必须经历数十次突破和差不多数量的显著微调。事后看来，这一切都如此简单明了。然而，人类思维隐藏的局限性，阻碍了增量阅读在十年前的出现。这些限制中只有一小部分是因为技术原因。

In my first year of university I had very little time and energy to spare, and most of that time I invested in getting my first computer: ZX Spectrum (Jan 1986). I borrowed one from a friend for a day in Fall 1985 and was totally floored. I started programming “on paper” long before I got the toy. My first program was “planning the day” precursor of Plan. The program was ready to type in into the computer when I turned on my ZX Spectrum for the first time on Jan 4, 1986. As of that day, I spent most of my days on programming, ignoring school and writing my programs on paper even during classes.

大一那年，我没有太多时间和精力可供支配，大部分时间都花在了购买第一台计算器：ZX Spectrum（1986年1月）上。1985年秋天，我借朋友那台用了一天，就被彻底震撼了。在打开 ZX Spectrum 之前很久，我就开始“纸上”编程了。我的第一个程序是“为一天做计划”，也就是 Plan 的前身。当我第一次打开 ZX Spectrum（1986年1月4日）时，该程序已做好了输入到计算器中的准备。从那天起，我大部分时间都花在编程上，忽略了学校，甚至在课堂上也在纸上写程序。

![[ZX_Spectrum.jpg]]

> ***Figure:** ZX Spectrum 8-bit personal home computer.*

> ***图**：ZX Spectrum 8位个人家用电脑。*

### 逃离兵役（The Army）

Early 1986 was marred by the threat of conscription. I thought 5 more years of university meant 5 more years of freedom. However, The Army had different ideas. For them, second major did not count, and I had to bend over backwards to avoid the service. My anger was tripled by the fact that I would never ever contemplate 12 months of separation from my best new friend: ZX Spectrum. I told the man in uniform that they really do not want to have an angry man with a gun in their ranks. Luckily, in the mess of the communist bureaucracy, I managed to slip the net and continue my education. To this day, I am particularly sensitive to issues of freedom. Conscription isn’t much different from slavery. It was not a conscription in the name of combating fascism. It was a conscription for mindless drilling, goosestep, early alarms, hot meals in a hurry and stress. If this was to serve the readiness of Communist Bloc, this would be a readiness of Good Soldier Švejk Army. Today, millions of kids are sent to school in a similar conscription-like effort verging on slavery. Please read my *” I would never send my kids to school“* for my take on the coercive trample of the human rights of children. I am sure that some of my sentiments have been shaped by the sense of enslavement from 1986.

1986年初，征兵的威胁笼罩着我。我以为大学再读5年就意味着再有5年的自由。然而，军队有不同的想法。对他们来说，第二个专业并不算数，我不得不竭尽全力避免服役。我更加愤怒的是，我永远不会考虑与我最好的新朋友 ZX Spectrum 分离12个月。我告诉军装男子，他们绝不会想让一个愤怒的持枪男子加入他们的队伍。幸运的是，在共产主义官僚主义的混乱中，我设法逃脱了征募，继续我的教育。直到今天，我依然对自由问题特别敏感。征兵与奴隶制没有什么不同。这不是以打击法西斯主义的名义进行的征兵。而是一场为了无意识的操练、鹅步、早起、在压力中急切进餐进行的强迫。如果这是为了共产主义集团的战备，那他就是“好兵帅克”军队的战备。今天，数百万儿童被送往学校，参与类似的形同奴隶的强制劳役。请阅读我的”*我永远不会送我的孩子去上学*“，了解我对侵犯儿童人权的强制践踏的看法。我确信，我的一些情绪受到了1986年的压迫的影响。

*译注：《好兵帅克》全名《好兵帅克在第一次世界大战中的遭遇》，是捷克杰出作家哈谢克创作的一部长篇政治讽刺小说。作家以自己在奥匈帝国军队服役时所获得的大量素材提炼而成。小说以主人公帅克在第一次世界大战中的经历为主要情节，淋漓尽致地描述了奥匈帝国的军官、警察、神甫昏庸无能、愚蠢透顶的丑态，深刻揭露了奥匈帝国统治者的凶恶专横及军队的腐败堕落。作品以生动的笔触塑造出一个憨厚老实又十分幽默的、招人喜爱的好兵帅克形象，在他的身上生动地表现了捷克人民的智慧及其对异族统治者的不满和自发的斗争。*

On the day when the radioactive cloud from Chernobyl passed over Poznan, Poland, I was busy walking point to point across the vast city visiting military and civilian offices in my effort to avoid the army. I succeeded and summer 1986 was one of the sunniest ever. I spent my days on programming, jogging, learning with SuperMemo (on paper), swimming, football and more programming.

在切尔诺贝利核辐射云飘过波兰波兹南的那一天，我正忙着在整个城市中走来走去，拜访军事和民用办公室，以避免入伍。我成功了，1986年的夏天是有史以来最阳光明媚的夏天之一。我把我的日子花在编程、慢跑、用SuperMemo（纸质版）学习、游泳、足球和更多的编程上。

### 1986年的夏天（Summer 1986）

My appetite for new software was insatiable. I wrote a program for musical composition, for predicting the outcomes of the World Cup, for tic-tac-toe in 3D, for writing school tests, and many more. I got a few jobs from the Department of Biochemistry (Adam Mickiewicz University). My hero, Prof. Augustyniak, needed software for simulating the melting of DNA, and for fast search of tRNA genes (years later that led to a publication). He also commissioned a program for regression analysis that later inspired progress in SuperMemo (esp. Algorithms SM-6 and SM-8).

当时，我对新软件有着极大的渴望。我编写了用于音乐创作、预测世界杯结果、玩三维井字棋、编写学校考试的程序，以及更多其他程序。我从亚当·密茨凯维奇大学的生物化学系接到了几份工作。我的英雄——奥古斯丁亚克教授，需要软件来模拟 DNA 的融化，以及快速搜索 tRNA 基因（多年后相关成果成功出版）。他还委托我开发了一个回归分析程序，后来该程序启发了 SuperMemo 的进步（尤其是 SM-6 和 SM-8 算法）。

While programming, I had SuperMemo at the back of my mind all the time, however, all my software was characterized by the absence of any database. The programs had to be read from a cassette tape which was a major drag (it did not bother me back in 1986). It was simpler to keep my SuperMemo knowledge on paper. I started dreaming of a bigger computer. However, in Communist Poland, the cost was out of reach. Once I computed that an IBM PC would cost as much as my mom’s lifetime wages in the communist system. As late as in 1989, I could not afford a visit in a toilet in Holland because it was so astronomically expensive when compared with wages in Poland.

在编程过程中，我一直将 SuperMemo 牢记在心，然而，我所有的软件都缺乏数据库。这些程序必须从盒式磁带上读取，这是一个很大的拖累（虽然这在 1986 年并没让我困扰）。将我的 SuperMemo 知识保存在纸上更简单。我开始梦想着拥有一台更大的计算机。然而，在共产主义波兰，这事的成本是我无法承受的。我曾经计算过，一台 IBM PC 的价格相当于我母亲在共产主义制度下的终身工资。直到 1989 年，我仍然负担不起在荷兰上厕所的费用，因为与波兰的工资相比，它贵得惊人。

### 我的第一台个人电脑（PC 1512）

My whole family pulled in resources. My cousin, Dr Garbatowski, arranged a special foreign currency account for Deutsch Mark transfers. By a miracle, I was able to afford DM 1000 Amstrad PC 1512 from Germany. The computer was not smuggled as it was once reported in the press. My failed smuggling effort came two years earlier in reference to ZX Spectrum. My friends from Zaire were to buy it for me in West Berlin. In the end, I bought second-hand ZX Spectrum in Poland, at a good price, from someone who thought he was selling “just a keyboard”.

我的整个家庭都调动了资源。我的堂兄加尔巴托夫斯基医生安排了一个特殊的外国货币账户用于德国马克汇款。奇迹出现了，我花费 1000 德国马克从德国买到了 Amstrad PC 1512。正如媒体曾经报道的那样，这台电脑并不是走私来的。我失败的走私尝试发生在两年前，涉及 ZX Spectrum。我在扎伊尔的朋友们本打算在西柏林为我购买。但最后，我在波兰以一个好价钱从一个认为自己只是在卖“键盘”的人那里买到了二手 ZX Spectrum。

![[Schneider_Amstrad_PC_1512_DD.png]]

> ***Figure: Amstrad PC-1512 DD.** My version had only one diskette drive. Operating system MS-DOS had to be loaded from one diskette, Turbo Pascal 3.0 from another diskette, SuperMemo from yet another. By the time I had my first hard drive in 1991, my English collection was split into 3000-item pieces over 13 diskettes. I had many more for other areas of knowledge. On Jan 21, 1997, SuperMemo World has tracked down that original PC and bought it back from its owner: Jarek Kantecki. The PC was fully functional for the whole decade. It is now buried somewhere in dusty archives of the company. Perhaps we will publish its picture at some point. The presented picture comes from Wikipedia*
> 
>***图：Amstrad PC-1512 DD.** 我的那台只有一个软盘驱动器。操作系统 MS-DOS 必须从一张软盘加载，urbo Pascal 3.0 再从第二张软盘加载，SuperMemo 再从第三张软盘加载。当我 1991 年拥有第一台硬盘驱动器时，我的英语收藏被拆分为 3000 个项目的 13 张软盘。我还有许多其他知识领域的软盘。1997 年 1 月 21 日，SuperMemo World 找到了那台原始的 PC 并从其主人 Jarek Kantecki 那里买回了它。这台 PC 在整个十年中都功能齐全。现在它被埋藏在公司尘封的档案库中的某个地方。也许我们会在某个时候发布它的照片。展示的图片来自维基百科*

My German Amstrad-Schneider PC 1512 was ordered from a Polish company Olech. Olech was to deliver it in June 1987. They did it in September. This cost me the whole summer of stress. Some time later, Krzysztof Biedalak ordered a PC from a Dutch company Colgar and never got a PC or money back. If this happened to me, I would have lost my trust in humanity. This would have killed SuperMemo. This might have killed my passion for computers. Biedalak, on the other hand, stoically got back to hard work and earned his money back and more. That would be one of the key personality differences between me and Biedalak. Stress resilience should be one of the components of development. I developed my stress resilience late with self-discipline training (e.g. winter swimming or marathons). Having lost his money, Biedalak did not complain. He got it back in no time. Soon I was envious of his new shiny PC. His hard work and determination in achieving goals was always a key to the company’s survival. It was his own privately earned money that helped SuperMemo World survive the first months. He did not get a gift from his parents. He could always do things on his own.

我的德国 Amstrad-Schneider PC 1512 是从波兰公司 Olech 订购的。Olech 应该在 1987 年 6 月交付，但他们直到 9 月才交付。这让我整个夏天都承受着巨大的压力。一段时间后，克里斯托夫·比达拉克从荷兰公司 Colgar 订购了一台电脑，但既没有收到电脑也没有收到退款。如果这种情况发生在我身上，我会对人性失去信任。这可能会扼杀 SuperMemo。也可能会扼杀我对计算机的热情。可是，没收到电脑的比达拉克却泰然自若地重新投入到工作中，并赚回了更多的钱。这将是我和比达拉克之间的关键性格差异之一。抗压能力应该是发展的一个组成部分。我通过自律训练（例如冬泳或马拉松）才逐渐提高了抗压能力。失去钱财后，比达拉克并没有抱怨。他很快就将其追回。很快我就羡慕他的新电脑。他在实现目标方面的不懈努力和决心始终是公司生存的关键。帮助 SuperMemo World 度过最初几个月的资金是他自己辛苦赚来的钱。他没有得到父母的资助。他总是能够独立自主地做事。

### 模拟学习过程（Simulating the learning process）

On Feb 22, 1986, using my ZX Spectrum, I wrote a program to simulate long-term learning process with SuperMemo. I was worried that with the build-up of material, the learning process would slow down significantly. However, my preliminary results were pretty counterintuitive: the progress is almost linear. There isn’t much slow down in learning beyond the very initial period.

1986 年 2 月 22 日，我使用 ZX Spectrum 编写了一个程序来模拟 SuperMemo 的长期学习过程。起初我担心随着学习材料的不断增加，学习速度会显著下降。然而，初步结果却非常违反直觉：学习进度几乎呈线性增长。除了最初的阶段之外，学习速度并没有明显减慢。

On Feb 25, 1986, I extended the simulation program by new functions that would answer ” *burning questions about memory*“. The program would run on Spectrum over 5 days until I could get full results for 80 years of learning. It confirmed my original findings.

1986 年 2 月 25 日，我为模拟程序扩展了新功能，以回答“_关于记忆的迫切问题_”。该程序将在 Spectrum 上运行 5 天，直到我获得 80 年学习的完整模拟结果。它证实了我最初的发现。

On Mar 23, 1986, I managed to write the same simulation program in Pascal which was a compiled language. This time, I could run 80 years simulation in just 70 minutes. I got the same results. Today, SuperMemo still makes it possible to run similar simulations. The same procedure takes just a second or two.

1986 年 3 月 23 日，我成功地用 Pascal（一种编译语言）编写了相同的模拟程序。这一次，我可以在短短 70 分钟内完成 80 年的模拟。我得到了相同的结果。如今，SuperMemo 仍然可以运行类似的模拟，同样的过程只需要一两秒钟。

![[SuperMemo_The true history of spaced repetition_附件/Learning_process_simulation.jpg]]

> ***Figure:** SuperMemo makes it possible to simulate the course of learning over 15 years using real data collected during repetitions.*
> 
> _**图：**_ SuperMemo 可以使用在复习过程中收集的真实数据来模拟 15 年的学习过程。

Some of the results of that simulation are valid today. Below I present some of the original findings. Some might have been amended in 1990 or 1994.

该模拟的一些结果至今仍然有效。下面我将介绍一些最初的发现。其中一些可能在 1990 年或 1994 年进行了修正。

#### 学习曲线几乎是线性的（Learning curve is almost linear）

The learning curve obtained by using the model, except for the very initial period, is almost linear.

除了最初的阶段，使用该模型获得的学习曲线几乎是线性的。

![[SuperMemo_The true history of spaced repetition_附件/Linear_learning_curve-1.gif]]

> ***Figure:** Learning curve for a generic material, forgetting index equal to 10%, and daily working time of 1 minute.*
> 
> _**图：**_ 遗忘指数为 10%、每日学习时间为 1 分钟的一般学习材料的学习曲线。

#### 新项目占用了 5% 的时间（New items take 5% of the time）

In a long-term process, for the forgetting index equal to 10%, and for a fixed daily working time, the average time spent on memorizing new items is only 5% of the total time spent on repetitions. This value is almost independent of the size of the learning material.

在长期学习过程中，在遗忘指数为 10% 且每日学习时间固定的情况下，记忆新项目所花费的平均时间仅占复习总时间的 5%。这一数值几乎与学习材料的大小无关。

#### 学习速度（Speed of learning）

According to the simulation, the number of items memorized in consecutive years when working one minute per day can be approximated with the following equation:

NewItems=aar*(3*e <sup>-0.3*year</sup>+1)

where:

-   NewItems – items memorized in consecutive years when working one minute per day,
-   year – ordinal number of the year,
-   aar – asymptotic acquisition rate, i.e. the minimum learning rate reached after many years of repetitions (usually about 200 items/year/min)

根据该模拟，连续几年内每天工作一分钟的情况下记忆的项目数量可以用以下方程来近似：

NewItems=aar*(3*e <sup>-0.3*year</sup>+1)

其中各代数的含义如下：

-   NewItems – 每天工作一分钟的情况下，连续几年内记忆的项目数量
-   year – 年份的序数（如第一年、第二年等）
-   aar –渐近获取率，即经过多年复习后达到的最低学习率（通常约为 200 个项目/年/分钟）

In a long-term process, for the forgetting index equal to 10%, the average rate of learning for generic material can be approximated to 200-300 items/year/min, i.e. one minute of learning per day results in the acquisition of 200-300 items per year. Users of SuperMemo usually report the average rate of learning from 50-2000 items/year/min.

在长期学习过程中，对于遗忘指数为 10% 的一般学习材料，平均学习速度可以近似为 200-300 个项目/年/分钟，即每天学习一分钟可记住 200-300 个项目。 SuperMemo 用户通常报告的平均学习速度为 50-2000 个项目/年/分钟。

#### 工作负荷（Workload）

For a generic material and the forgetting index of about 10%, the function of time required daily for repetitions per item can roughly be approximated using the formula:

time=1/500*year <sup>-1.5</sup>+1/30000

where:

-   time – average daily time spent for repetitions per item in a given year (in minutes),
-   year – year of the process.

对于遗忘指数约为 10% 的一般学习材料，用于复习每个项目所需的每日时间函数可以用以下公式粗略近似：

time=1/500×year <sup>-1.5</sup>+1/30000

其中各代数的含义如下：

- **time** – 每年复习每个项目所花费的平均每日时间（以分钟为单位），
- **year** – 学习过程中的年份。

As the time necessary for repetitions of a single item is almost independent of the total size of the learned material, the above formula may be used to approximate the workload for learning material of any size. For example, the total workload for a 3000-element collection in the first year will be 3000/500*1+3000/30000=6.1 (min/day).

由于复习单个项目所需的时间几乎与所学材料的总大小无关，因此上述公式可用于近似任何大小的学习材料的工作量。例如，第一年学习 3000 个元素的总工作量为 3000/500*1+3000/30000=6.1（分钟/天）。

![[SuperMemo_The true history of spaced repetition_附件/Workload-1.gif]]

> ***Figure:** Workload, in minutes per day, in a generic 3000-item learning material, for the forgetting index equal to 10%.*
> 
> _**图：**_ 遗忘指数为 10% 的 3000 项一般学习材料的每日工作量（以分钟为单位）。

#### 最佳遗忘指数（Optimum forgetting index）

The greatest overall knowledge acquisition rate is obtained for the forgetting index of about 20-30%. This results from the trade-off between reducing the repetition workload and increasing the relearning workload as the forgetting index progresses upward. In other words, high values of the forgetting index result in longer intervals, but the gain is offset by an additional workload coming from a greater number of forgotten items that have to be relearned.

遗忘指数约为 20-30% 时，可获得最大的总体知识获取率。这是由于随着遗忘指数的上升，在复习工作量和重新学习的工作量之间达到了最佳平衡。换句话说，较高的遗忘指数允许复习间隔更长时间，但同时会使被遗忘项目数量增加，并带来额外的重新学习工作，最终抵消遗忘间隔拉长带来的时间收益。

For the forgetting index greater than 20%, the positive effect of long intervals on memory resulting from the spacing effect is offset by the increasing number of forgotten items.

当遗忘指数大于 20% 时，拉长间隔对记忆的积极影响被遗忘项目数量的增加所抵消。

![[SuperMemo_The true history of spaced repetition_附件/Knowledge_acquisition_rate_vs_forgetting_index-1.gif]]

> ***Figure:** Dependence of the knowledge acquisition rate on the forgetting index.*
> 
> _**图：**_ 知识获取率与遗忘指数的相关性。

When the forgetting index drops below 5%, the repetition workload increases rapidly (see the figure above). The recommended value of the forgetting index used in the practice of learning is 6-14%.

当遗忘指数低于 5% 时，复习工作量会迅速增加（见上图）。在实际学习中，推荐的遗忘指数值为 6-14%。

![[SuperMemo_The true history of spaced repetition_附件/Knowledge_retention_vs_workload-1.gif]]

> ***Figure:** Trade-off between the knowledge retention ( forgetting index) and the workload (number of repetitions of an average item in 10,000 days).*
> 
> _**图：**_ 知识保留（遗忘指数）与复习工作量（10,000 天内平均项目复习次数）之间的平衡关系。

In later years, the value of the optimum forgetting index was found to differ depending on the tools used (e.g. Algorithm SM-17).

在后来的研究中，发现最优遗忘指数的值会根据所使用的工具（例如 SM-17 算法）的不同而有所差异。

#### 记忆容量（Memory capacity）

The maximum lifetime capacity of the human brain to acquire new knowledge by means of learning procedures based on the discussed model can be estimated as no more than several million items. As nobody is likely to spend all his life on learning, I doubt I will ever see anyone with a million items in his memory.

根据上面讨论的模型，人类大脑通过学习程序获取新知识的终身最大容量估计不超过数百万个项目。由于人终生都在学习的可能性微乎其微，我怀疑严重怀疑是否有人能真的记住 100 万个项目。

## 1987年：DOS 上的 SuperMemo 1.0（1987: SuperMemo 1.0 for DOS）

### DOS 上的 SuperMemo 1.0：日复一日（1987年）（SuperMemo 1.0 for DOS: day by day (1987)）

SuperMemo history file says ” *Wozniak wrote his first SuperMemo in 16 evenings*“. The reality was slightly more complex and I thought I would describe it in more details using the notes of the day.

SuperMemo历史文件中声称“Wozniak花了16个晚上写出他的第一个SuperMemo”。 实际情况要更复杂一些，我想用按当时的笔记来更详细地描述这一过程。

I cannot figure out what I meant writing on Jul 3, 1987 that ” *I have an idea of a revolutionary program arranging my work and scientific experiments SMTests*” (SMTests stands for SuperMemo on paper). A transition from paper to a computer seems like an obvious step. There must have been some mental obstacle on the way that required “thinking out of the box”. Unfortunately, I did not write down details. Today it only matters in that it illustrates how excruciatingly slow a seemingly obvious idea may creep into the mind.

我在1987年7月3日的笔记中写道：“我想到了一个革命性的程序，可以安排我的工作和科学实验中的 SMTests（SMTests 代表纸上的 SuperMemo）。”现在我已经记不清当时的具体想法了。 从纸质笔记转向计算机软件似乎是一个自然而然的步骤。 但当时一定存在某种心理障碍，阻碍了我迈出需要“跳出框架思考”的这一步，。 遗憾的是，我没有记录下当时的具体想法。 现在回想起来，这也许说明了一个看似显而易见的想法真正进入脑海需要的时间可能长的让人难以忍受。

On Sep 8, 1987, my first PC arrived from Germany (Amstrad PC 1512). My enthusiasm was unmatched! I could not sleep. I worked all night. The first program I planned to write was to be used for mathematical approximations. SuperMemo was second in the pipeline.

1987年9月8日，我的第一台 PC（Amstrad PC 1512）从德国运抵。 我兴奋不已，整夜难以入眠。 我计划编写的第一个程序是用于数学近似的工具，SuperMemo 则排在计划中的第二位。

![[SuperMemo_The true history of spaced repetition_附件/Schneider_Amstrad_PC_1512_DD-1.png]]

> ***Figure: Amstrad PC-1512 DD.** My version had only one diskette drive. Operating system MS-DOS had to be loaded from one diskette, Turbo Pascal 3.0 from another diskette, SuperMemo from yet another. By the time I had my first hard drive in 1991, my English collection was split into 3000-item pieces over 13 diskettes. I had many more for other areas of knowledge. On Jan 21, 1997, SuperMemo World has tracked down that original PC and bought it back from its owner: Jarek Kantecki. The PC was fully functional for the whole decade. It is now buried somewhere in dusty archives of the company. Perhaps we will publish its picture at some point. The presented picture comes from Wikipedia
> 
> **图：Amstrad PC-1512 DD.** 我的那台只有一个软盘驱动器。操作系统 MS-DOS 必须从一张软盘加载，Turbo Pascal 3.0 再从第二张软盘加载，SuperMemo 再从第三张软盘加载。当我 1991 年拥有第一台硬盘驱动器时，我的英语收藏被拆分为 3000 个项目的 13 张软盘。我还有许多其他知识领域的软盘。1997 年 1 月 21 日，SuperMemo World 找到了那台原始的 PC 并从其主人 Jarek Kantecki 那里买回了它。这台 PC 在整个十年中都功能齐全。现在它被埋藏在公司尘封的档案库中的某个地方。也许我们会在某个时候发布它的照片。展示的图片来自维基百科**

Oct 16, 1987, Fri, in 12 hours I wrote my first SuperMemo in GW-Basic (719 minutes of non-stop programming). It was slow like a snail and buggy. I did not like it much. I did not start learning. Could this be the end of SuperMemo? Wrong choice of a programming language? Busy days at school kept me occupied with a million unimportant things. Typical school effect: learn nothing about everything. No time for creativity and your own learning. Luckily, all the time I used SuperMemo on paper. The idea of SuperMemo could not have died. It had to be automated sooner or later.

1987年10月16日，星期五，我在12个小时内用GW-Basic写出了我的第一个SuperMemo（花费了719分钟不间断编程）。它慢如蜗牛，而且满是漏洞。我不太喜欢它，也没有开始学习。这就是 SuperMemo 的终结吗？编程语言选择错误了吗？学校里繁忙的日子让我忙于无数琐事。这就是学校教育的典型：什么都学一点，却什么都学不好。没有时间用于创造力和自己的学习。幸运的是，我一直都在纸上使用 SuperMemo。SuperMemo 的理念不可能就此消亡。它迟早会被自动化。

On Nov 14, 1987, Sat, SuperMemo on paper got its first user: Mike Kubiak. He was very enthusiastic. The fire kept burning. On Nov 18, I learned about Turbo Pascal. It did not work on my computer. In those days, if you had a wrong graphics card, you might struggle. Instead of Hercules, I had a text-mode monochrome (black-and-white) CGA. I managed to solve the problem by editing programs in the RPED text editor rather than in the Turbo Pascal environment. Later I got the right version for my display card. Incidentally, old SuperMemos show in colors. I was programming it in shades of gray and never knew how it really looked in the color mode.

1987年11月14日，星期六，纸上的 SuperMemo 迎来了它的第一位用户：迈克·库比亚克。他非常热情。火种得以继续燃烧。11月18日，我了解到 Turbo Pascal。它在我的电脑上无法运行。在那个时代，使用错误的图形卡可能会带来麻烦。我没有 Hercules 卡，而是使用了文本模式的单色（黑白）CGA 卡。我通过在 RPED 文本编辑器而不是 Turbo Pascal 环境中编辑程序解决了这个问题。后来我得到了适合我的正确版本的图形卡。顺便说一句，旧的SuperMemos显示为彩色。但我在黑白模式下编程，从未知道它在彩色模式下的真实外观。

Nov 21, 1987 was an important day. It was a Saturday. Days free from school are days of creativity. I hoped to get up at 9 am but I overslept by 72 minutes. This is bad for the plan, but this is usually good for the brain and performance. I started the day from SuperMemo on paper (reviewing English, human biology, computer science, etc.). Later in the day, I read my Amstrad PC manual, learned about Pascal and Prolog, spent some time thinking how human cortex might work, did some exercise, and in the late evening, in a slightly tired state of mind, in afterthought, decided to write SuperMemo for DOS. This would be my second attempt. However, this time I chose Turbo Pascal 3.0 and never regretted. To this day, as a direct consequence, SuperMemo 17 code is written in Pascal (Delphi).

1987年11月21日是一个重要日子。那天是星期六。远离学校的日子总是充满创造力。我本打算9点起床，但多睡了72分钟。这不利与执行计划，但通常有利于大脑和个人表现。我从纸上的 SuperMemo 开始这一天（复习英语、人类生物学、计算机科学等）。当天晚些时候，我阅读了我的 Amstrad PC 手册，学习了 Pascal 和 Prolog，花了一些时间思考人类大脑皮层的工作原理，做了一些运动，之后的傍晚时分，我在略微疲惫的状态下，思索之后决定开始为 DOS 编写 SuperMemo。这将是我的第二次尝试。然而，这一次我选择了 Turbo Pascal 3.0，这是一个我从未后悔的决定。直到今天，作为直接结果，SuperMemo 17 的代码都是用Pascal（Delphi）编写的。

For the record, the name SuperMemo was proposed much later. In those days, I called my program: SMTOP for Super-Memorization Test Optimization Program. In 1988, Tomasz Kuehn insisted we call it CALOM for Computer-Aided Learning Optimization Method.

根据记录，SuperMemo 这个名字是在很久以后才被提出的。在那些日子里，我把我的程序称为 SMTOP，即“超记忆测试优化程序”。1988年，托马斯·库恩坚持认为我们应该称之为 CALOM，即“计算机辅助学习优化方法”。

Nov 22, 1987 was a mirror copy of Nov 21. I concluded that I know how cortex works and that one day it would be nice to build a computer using similar principles (check Jeff Hawkins‘s work). The fact that I returned to programming SuperMemo in the late evening, i.e. very bad time for creative work, seems to indicate that the passion has not kicked in yet.

1987年11月22日与11月21日如出一辙。我得出结论，我知道大脑皮层是如何工作的，在未来用类似的原理构建一台计算机将是一件很棒的事情（参见杰夫·霍金斯的工作）。我在深夜才回到 SuperMemo 的编程工作，这一时段非常不适合进行创造性工作，这似乎表明激情尚未燃起。

Nov 23, 1987 looked identical. I am not sure why I did not have any school obligations on Monday, but this might have saved SuperMemo. On Nov 24, 1987, the excitement kicked in and I worked for 8 hours straight (in the evening again). The program had a simple menu and could add new items to the database.

1987年11月23日看起来也完全相同。我不确定为什么周一不用上学，但这可能挽救了 SuperMemo。1987年11月24日，兴奋感涌现，我连续工作了8个小时（同样是在晚上）。程序拥有了简单的菜单，可以将新项目添加到数据库中。

Nov 25, 1987 was wasted: I had to go to school, I was tired and sleepy. We had excruciatingly boring classes in computer architecture, probably a decade behind the status quo in the west.

1987年11月25日浪费了：我不得不去学校，感到疲倦和困倦。我们上了令人痛苦的计算机体系结构课程，可能比西方落后了十年。

Nov 26 was free again and again I was able to catch up with SuperMemo work. The program grew to be 15,400 bytes huge. I concluded the program might be ” *very usefull*” (sic!).

11月26日再次自由，我又能够赶上 SuperMemo 的工作。程序增长到15,400字节之巨。我得出结论，该程序可能“非常有用”（原文如此！）。

On Nov 27, I added 3 more hours of work after school.

**11月27日**，放学后我又增加了3个小时的工作。

Nov 28 was Saturday and I could add 12 enthusiastic hours of non-stop programming. SuperMemo now looked like almost ready for use.

**11月28日**是星期六，我可以连续12个小时充满热情地编程。SuperMemo现在看起来几乎可以使用了。

On Nov 29, Sunday, I voted for economic reforms and democratization in Poland. In the evening, I did not make much progress. I had to prepare an essay for my English class. The essay described the day when I experimented with alcohol one day in 1982. I was a teetotaller, but as a biologist, I concluded I need to know how alcohol affects the mind.

11月29日，星期日，我投票支持波兰的经济改革和民主化。晚上，我没有取得太大进展。我必须为英语课准备一篇论文。这篇论文描述了我在1982年尝试酒精的一天。我是一个禁酒者，但作为一名生物学家，我认为我需要了解酒精如何影响大脑。

Nov 30 was wasted at school, but we had a nice walk home with Biedalak. We had a long conversation in English about our future. That future was mostly to be about science, probably in the US.

11月30日在学校浪费了时间，但我和比达拉克一起愉快地步行回家。我们用英语就我们的未来进行了长时间的交谈。那个未来主要与科学有关，可能是在美国。

Dec 1-4 were wasted at school again. No time for programming. In a conversation with some Russian professor, I realized that I completely forgot Russian in short 6 years. I used to be proudly fluent! I had to channel my programming time into some boring software for designing electronic circuits. I had to do it to credit a class in electronics. I had a deal with the teacher that I would not attend, just write this piece of software. I did not learn anything and to this day I mourn the waste of time. If I was free, I could have invested this energy in SuperMemo.

12月1日至4日又在学校浪费了时间。没有时间编程。在与一位俄罗斯教授的交谈中，我意识到短短6年时间里，我完全忘记了俄语。我曾经流利得引以为傲！我不得不将我的编程时间投入到一些用于设计电子电路的无聊软件中。我必须这样做才能获得电子课程的学分。我和老师达成了协议，我不参加课程，只需编写这个软件。我没有学到任何东西，直到今天我还在为浪费的时间而哀悼。如果我自由了，我本可以将这些精力投入到SuperMemo中。

Dec 5 was a Saturday. Free from school. Hurray! However, I had to start from wasting 4 hours on some “keycode procedure”. In those days, even decoding the key pressed might become a challenge. And then another hour wasted on changing some screen attributes. In addition, I added 6 hours for writing “item editor”. This way, I could conveniently edit items in SuperMemo. The effortless things you take for granted today: cursor left, cursor right, delete, up, new line, etc. needed a day of programming back then.

12月5日是星期六。不用上学了。万岁！然而，我不得不花4个小时来处理一些“按键编码过程”。在那些日子里，连为按下的按键解码都可能成为一项挑战。然后又花了一个小时来改变一些屏幕属性。此外，我又花了6个小时来编写“项目编辑器”。这样，我就可以方便地编辑SuperMemo中的项目了。今天你认为理所当然的轻松操作：光标左移、右移、删除、上移、换行等，在当时需要一天的编程时间。

Dec 6 was a lovely Sunday. I spent 7 hours debugging SuperMemo, adding “final drill”, etc. The excitement kept growing. In a week, I might start using my new breakthrough speed-learning software.

12月6日是可爱的星期天。我花了7个小时调试 SuperMemo，添加了“最终复习”等功能。兴奋感不断增长。一周后，我可能就能开始使用我突破性的新快速学习软件。

On Monday, Dec 7, after school, I added a procedure for deleting items.

12月7日，周一放学后，我添加了一个删除项目的程序。

On Dec 8, while Reagan and Gorbachev signed their nuclear deal, I added a procedure for searching items and displaying some item statistics. SuperMemo “bloated” to 43,800 bytes.

12月8日，当里根和戈尔巴乔夫签署核裁军协议时，我添加了一个搜索项目和显示一些项目统计数据的程序。SuperMemo“膨胀”到43,800字节。

Dec 9 was marred by school and programming for the electronics class.

12月9日被学校和电子课程的编程毁了。

On Dec 10, I celebrated power cuts at school. Instead of boring classes, I could do some extra programming.

12月10日，我为学校停电庆祝。我可以进行一些额外的编程，而不是上无聊的课。

On Dec 11, we had a lovely lecture with one of the biggest brains at school: Prof. Jan Węglarz. He insisted that he could do more in Poland than abroad. This was a powerful message. However, in 2018, his Wikipedia entry says that his two-phase method discovery was ignored, and later duplicated in the west because he opted for publishing in Polish. Węglarz created a formidable team of best operations research brains in Poznan indeed. If I did not sway in the direction of SuperMemo, I would sure come with a begging hat to look for an employment opportunity. In the evening, I added a procedure for inspecting the number of items to review each day (today’s Workload).

12月11日，我们聆听了学校一位最聪明的大脑——扬·韦格拉兹教授的精彩演讲。他坚持认为，他在波兰能比在国外做得更多。这是一个强有力的信息。然而，在2018年的维基百科词条中提到，他的两阶段法的发现被忽视了，后来在西方被复制，因为他选择用波兰语发表。韦格拉兹确实在波兹南组建了一支强大的最佳运筹学人才队伍。如果我没有转向 SuperMemo，我一定会带着乞讨帽去寻找就业机会。晚上，我添加了一个检查每天复习项目数量（今日工作量）的程序。

*注：两阶段法(two-phase method)是寻找线性规划问题初始基可行解的一种方法，把增加人工变量的线性规划问题分为两个阶段去求解。第一阶段主要是为了得到原问题的一个基本可行解，第二阶段是在第一阶段得到的基本可行解的基础上求解原线性规划问题。*

Dec 12 was a Saturday. I expanded SuperMemo by a pending queue editor, and seemed ready to start learning, however, …

12月12日是星期六。我通过待处理队列编辑器扩展了SuperMemo，似乎已经准备好开始学习了，但是……

… on Dec 13, I was hit by a bombshell: ” *Out of memory*“. I somehow managed to fix the problem by optimizing the code. The last option I needed to add was for the program to read the date. Yes. That was a big deal hack. Without it, I would need to type in the current date at the start of the work with the program. Finally, at long last, in the afternoon, on Dec 13, 1987, I was able to add my first items to my human biology collection: questions about the autonomic nervous system. By Dec 23, 1987, my combined paper and computer databases included 3795 questions on human biology (of which almost 10% already in SuperMemo). Sadly, I had to remove full repetition histories from SuperMemo on that day. There wasn’t enough space on 360K diskettes. Spaced repetition research would need to wait a few more years.

……12月13日，我遭遇了晴天霹雳：“*内存不足*”。我不知何故通过优化代码解决了这个问题。我需要添加的最后一个选项是让程序读取日期。是的，这是一个大难题。没有它，我在每次开始使用程序时都需要输入当前日期。终于，在1987年12月13日的下午，我能够将第一批项目（关于自主神经系统的问题）添加到我的“人类生物学”收藏中。到1987年12月23日，我的纸质和计算机数据库结合起来，包含了3795个关于人类生物学的问题（其中近10%已经在 SuperMemo 中）。可悲的是，那天我不得不从 SuperMemo 中删除完整的重复历史记录。360K 磁盘没有足够的空间。关于间隔重复的研究还需要等待几年。

![[SuperMemo_The true history of spaced repetition_附件/Sm1_BW.jpg]]

> ***Figure:** SuperMemo 1.0 for DOS (1987).*
> 
> ***图：**DOS 上的 SuperMemo 1.0（1987年）。*

### SM-2 算法（Algorithm SM-2）

Here is the description of the algorithm used in SuperMemo 1.0. The description was taken from my Master’s Thesis written 2.5 years later (1990). SuperMemo 1.0 was soon replaced by a nicer SuperMemo 2.0 that I could give away to friends at university. There were insignificant updates to the algorithm that was named Algorithm SM-2 after the version of SuperMemo. This means there has never been Algorithm SM-1.

以下是 SuperMemo 1.0中使用的算法的描述。该描述摘自我在2.5年后（1990年）撰写的硕士论文。SuperMemo 1.0很快就被一个更好的 SuperMemo 2.0所取代，2.0版已经可以被我赠送给大学的朋友们了。其中对该算法进行了微不足道的更新，该算法以 SuperMemo 的版本命名为算法SM-2。这意味着从未有过算法 SM-1。

I mastered 1000 questions in biology in the first 8 months. Even better, I memorized exactly 10,000 items of English word pairs in the first 365 days working 40 min/day. This number was used as a benchmark in advertising SuperMemo in its first commercial days. Even today, 40 min is the daily investment recommended to master Advanced English in 4 years (40,000+ items).

我在前8个月内掌握了1000个生物学问题。更好的是，在前365天每天工作40分钟的情况下，我准确地记忆了10,000个英语单词对。这个数字在 SuperMemo 最初的商业化阶段被用作广告基准。即使在今天，40分钟也是推荐的每日投入时长，可以在4年内掌握高级英语（40,000多个项目）。

To this day, **Algorithm SM-2** remains popular and is still used by applications such as Anki, Mnemosyne and more.

直到今天，**算法 SM-2** 仍然很受欢迎，并且仍然被 Anki、Mnemosyne 等应用程序使用。

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？
*注：这个是 Wozniak 博士硕士论文的标题，应该是想强调用文字记录知识的重要性*

**3.2. Application of a computer to improve the results obtained in working with the SuperMemo method**

**3.2. 计算机在改进 SuperMemo 方法结果中的应用**

**I wrote the first SuperMemo program in December 1987 (Turbo Pascal 3.0, IBM PC). It was intended to enhance the SuperMemo method in two basic ways:**

-   apply the optimization procedures to smallest possible items (in the paper-based SuperMemo items were grouped in pages),
-   differentiate between the items on the base of their different difficulty.

我在1987年12月编写了第一个 SuperMemo 程序（Turbo Pascal 3.0，IBM PC）。它的目的是从两个基本方面增强 SuperMemo 方法：

- 将优化流程应用于尽可能小的项目（在纸质 SuperMemo 中，项目按页分组），
- 根据项目的不同难度进行区分。

Having observed that subsequent inter-repetition intervals are increasing by an approximately constant factor (e.g. two in the case of the SM-0 algorithm for English vocabulary), I decided to apply the following formula to calculate inter-repetition intervals:

I(1):=1

I(2):=6

for n>2 I(n):=I(n-1)×EF

where:

-   I(n) – inter-repetition interval after the n-th repetition (in days)
-   EF – easiness factor reflecting the easiness of memorizing and retaining a given item in memory (later called the E-Factor).

观察到最后的两次重复间隔以大致恒定的因子增加（例如，在英语词汇的 SM-0 算法中为2），我决定应用以下公式来计算重复间隔：

I(1):=1

I(2):=6

对于n>2 I(n):=I(n-1)×EF

其中：

- I(n) 指的是第 n 次重复后的两次重复间隔（以天为单位）
- EF 指的是“易度因子”，反映记忆和保留给定项目在记忆中的难易程度（后来称为 E 因子）。

E-Factors were allowed to vary between 1.1 for the most difficult items and 2.5 for the easiest ones. At the moment of introducing an item into a SuperMemo database, its E-Factor was assumed to equal 2.5. In the course of repetitions, this value was gradually decreased in case of recall problems. Thus the greater problems an item caused in recall the more significant was the decrease of its E-Factor.

E 因子允许在1.1（最难的项目）和2.5（最容易的项目）之间变化。在将项目引入 SuperMemo 数据库时，假设其 E 因子等于2.5。在重复过程中，如果回忆出现问题，则该值会逐渐降低。因此，项目在回忆中引起的问题越大，其E因子的降低就越显着。

Shortly after the first SuperMemo program had been implemented, I noticed that E-Factors should not fall below the value of 1.3. Items having E-Factors lower than 1.3 were repeated annoyingly often and always seemed to have inherent flaws in their formulation (usually they did not conform to the minimum information principle). Thus not letting E-Factors fall below 1.3 substantially improved the throughput of the process and provided an indicator of items that should be reformulated. The formula used in calculating new E-Factors for items was constructed heuristically and did not change much in the following 3.5 years of using the computer-based SuperMemo method.

在第一个 SuperMemo 程序实现后不久，我注意到 E 因子不应低于1.3。E 因子低于1.3的项目的重复频繁到了令人讨厌的地步，并且似乎总是存在固有的表述缺陷（通常它们不符合最小信息原则）。因此，不让 E 因子低于1.3大大提高了记忆过程的吞吐量，并提供了判断哪些项目应该重新编写的指标。用于计算项目新 E 因子的公式是启发式构建的，并且在接下来的使用基于计算机的 SuperMemo 方法的3.5年中没有发生太大变化。

In order to calculate the new value of an E-Factor, the student has to assess the quality of his response to the question asked during the repetition of an item (my SuperMemo programs use the 0-5 grade scale – the range determined by the ergonomics of using the numeric key-pad). The general form of the formula used was:

EF’:=f(EF,q)

where:

-   EF’ – new value of the E-Factor
-   EF – old value of the E-Factor
-   q – quality of the response
-   f – function used in calculating EF’.

为了计算 E 因子的新值，学生必须评估他在重复项目期间对所提问题的回答质量（我的 SuperMemo 程序使用0-5的评分等级——范围由使用数字键盘的人体工程学决定）。使用的公式的一般形式为：

EF’:=f(EF,q)

其中：

- EF’ – E因子的新值
- EF – E因子的旧值
- q – 回答质量（响应质量）
- f – 用于计算EF’的函数。

The function f had initially multiplicative character and was in later versions of SuperMemo program, when the interpretation of E-Factors changed substantially, converted into an additive one without significant alteration of dependencies between EF’, EF and q. To simplify further considerations only the function f in its latest shape is taken into account:

> EF’:=EF-0.8+0.28*q-0.02*q*q

which is a reduced form of:

> EF’:=EF+(0.1-(5-q)×(0.08+(5-q)×0.02))

Note, that for q=4 the E-Factor does not change.

函数 f 最初具是乘法运算，在 SuperMemo 程序的后续版本中，当对 E 因子的解释发生实质性变化时，将其转换为加法运算，而不会显着改变 EF’，EF 和 q 之间的依赖关系。为了便于大家理解，仅考虑函数 f 的最新形式：

> EF’:=EF-0.8+0.28×q-0.02×q×q

上述公式其实是下面公式的简化版本：

> EF’:=EF+(0.1-(5-q)×(0.08+(5-q)×0.02))

请注意，在 q=4 的情况下 E 因子不会发生变化

Let us now consider the final form of the SM-2 algorithm that with minor changes was used in the SuperMemo programs, versions 1.0-3.0 between December 13, 1987 and March 9, 1989 (the name SM-2 was chosen because of the fact that SuperMemo 2.0 was by far the most popular version implementing this algorithm).

现在，让我们来看 SM-2 算法的最终形式，该算法经过微小的改动，在1987年12月13日至1989年3月9日期间用于 SuperMemo 程序1.0-3.0版本（之所以选择名称 SM-2 是因为 SuperMemo 2.0是实施该算法的最受欢迎的版本）。

Algorithm SM-2 used in the computer-based variant of the SuperMemo method and involving the calculation of easiness factors for particular items:

1.  Split the knowledge into smallest possible items.
2.  With all items associate an E-Factor equal to 2.5.
3.  Repeat items using the following intervals:**I(1):=1****I(2):=6****for n>2: I(n):=I(n-1)*EF**where:
    -   I(n) – inter-repetition interval after the n-th repetition (in days),
    -   EF – E-Factor of a given itemIf interval is a fraction, round it up to the nearest integer.
4.  After each repetition assess the quality of repetition response in 0-5 grade scale:5 – perfect response4 – correct response after a hesitation3 – correct response recalled with serious difficulty2 – incorrect response; where the correct one seemed easy to recall1 – incorrect response; the correct one remembered0 – complete blackout.
5.  After each repetition modify the E-Factor of the recently repeated item according to the formula:EF’:=EF+(0.1-(5-q)*(0.08+(5-q)*0.02))where:
    -   EF’ – new value of the E-Factor,
    -   EF – old value of the E-Factor,
    -   q – quality of the response in the 0-5 grade scale.If EF is less than 1.3 then let EF be 1.3.
6.  If the quality response was lower than 3 then start repetitions for the item from the beginning without changing the E-Factor (i.e. use intervals I(1), I(2) etc. as if the item was memorized anew).
7.  After each repetition session of a given day repeat again all items that scored below four in the quality assessment. Continue the repetitions until all of these items score at least four.

算法 SM-2 被用于基于计算机的 SuperMemo 方法中，并涉及计算特定项目的易度因子：

1. 将知识分解为尽可能小的项目。
2. 将所有项目的E因子关联为2.5。
3. 使用以下间隔，重复项目： I(1):=1 I(2):=6 对于n>2: I(n):=I(n-1)×EF 其中：
    - I(n) – 第n次重复后的两次重复间隔（以天为单位），
    - EF – 给定项目的 E 因子，如果间隔是小数，则将其四舍五入到最接近的整数。
4. 在每次重复后，以0-5的等级评估重复响应的质量： 
	- 5 - 完美的回答
	- 4 - 犹豫后正确回答
	- 3 - 艰难地回忆起正确答案
	- 2 - 错误的回答；正确的答案似乎很容易回忆
	- 1 - 错误的回答；记住了正确的答案
	- 0 - 完全空白。
5. 每次重复后，根据以下公式修改最近重复项目的 E 因子： EF’:=EF+(0.1-(5-q)×(0.08+(5-q)×0.02)) 其中：
    - EF’ – E 因子的新值，
    - EF – E 因子的旧值，
    - q – 0-5等级尺度中的响应质量。 如果 EF 小于1.3，则令 EF 为1.3。
6. 如果响应质量低于3，则从头开始重复该项目，而不更改 E 因子（即从头开始使用间隔 I(1)，I(2) 等，就好像该项目被重新记忆一样）。
7. 在给定日期的每次重复会话后，再次重复所有在质量评估中得分低于4的项目。继续重复，直到所有这些项目的得分至少为4。

The optimization procedure used in finding E-Factors proved to be very effective. In SuperMemo programs you will always find an option for displaying the distribution of E-Factors (later called the E-Distribution). The shape of the E-Distribution in a given database was roughly established within few months since the outset of repetitions. This means that E-Factors did not change significantly after that period and it is safe to presume that E-Factors correspond roughly to the real factor by which the inter-repetition intervals should increase in successive repetitions.

用于确定 E 因子的优化程序被证明是非常有效的。在 SuperMemo 程序中，始终都有显示 E 因子分布（后来称为 E-分布）的选项。自开始重复以来几个月内，给定数据库中 E-分布的形状大致确定。这意味着 E 因子在那段时间之后没有显着变化，可以安全地假设 E 因子大致对应于在连续重复中两次重复间隔应增加的真实因子。

During the first year of using the SM-2 algorithm (learning English vocabulary), I memorized 10,255 items. The time required for creating the database and for repetitions amounted to 41 minutes per day. This corresponds to the acquisition rate of 270 items/year/min. The overall retention was 89.3%, but after excluding the recently memorized items (intervals below 3 weeks) which do not exhibit properly determined E-Factors the retention amounted to 92%. Comparing the SM-0 and SM-2 algorithms one must consider the fact that in the former case the retention was artificially high because of hints the student is given while repeating items of a given page. Items preceding the one in question can easily suggest the correct answer.Therefore the SM-2 algorithm, though not stunning in terms of quantitative comparisons, marked the second major improvement of the SuperMemo method after the introduction of the concept of optimal intervals back in 1985. Separating items previously grouped in pages and introducing E-Factors were the two major components of the improved algorithm. Constructed by means of the trial-and-error approach, the SM-2 algorithm proved in practice the correctness of nearly all basic assumptions that led to its conception.

在使用 SM-2 算法的第一年（学习英语词汇）中，我记忆了10,255个项目。创建数据库（记下项目）和重复所需的时间为每天41分钟。这相当于270个项目/年/分钟的记忆速度。总体保留率为89.3%，但在排除最近记忆的项目（3周之内记忆的项目用于确定 E 因子的证据不足）后，保留率达到了92%。比较 SM-0 和 SM-2 算法时，必须考虑到以下事实：在前一种情况下，由于学生在重复给定页面上的项目时会得到提示（*注：应该是指看某一页上面的项目时总会不经意瞟到同一页的其他项目，或者触发连带记忆*），因此保留率人为地高。前面的项目可以很容易地暗示正确的答案。因此，尽管 SM-2 算法在定量比较方面并不惊人，但在1985年引入最佳间隔概念之后，它标志着 SuperMemo 方法的第二次重大改进。分离先前按页分组的项目和引入 E 因子是改进算法的两个主要组成部分。通过试错法构建的 SM-2 算法在实践中证明了产生其概念的所有基本假设的正确性。

## 1988年：记忆的两个组成部分（1988: Two component of memory）

Two-component model of long-term memory lays at the foundation of SuperMemo, and is expressed explicitly in Algorithm SM-17. It differentiates between how stable knowledge is in long term memory storage, and how easy it is to retrieve. This remains a little known and quintessential fact of the theory of learning that one can be fluent and still remember poorly.

长期记忆的二元模型是 SuperMemo 的基础，并在算法 SM-17 中明确表达。它区分了知识在长期记忆存储中的稳定性以及检索的难易程度。这是一个鲜为人知且重要的学习理论事实，即一个人可以流利而仍然记得不好。

Fluency is a poor measure of learning in the long term

流利度是衡量长期学习的糟糕标准。

### 长期记忆的组成部分（Components of long-term memory）

I first described the idea of two components of memory in a paper for my computer simulations class on Jan 9, 1988. In the same paper, I concluded that different circuits must be involved in declarative and procedural learning.

我于1988年1月9日在计算机模拟课的论文中首次描述了记忆二元论的想法。在同一篇论文中，我得出结论，陈述性记忆（declarative memory）和程序性记忆（procedural memory）一定涉及不同的脑回路。

*注：陈述性记忆（declarative memory）和程序性记忆（procedural memory）都是心理学中的概念，陈述性记忆（declarative memory）指的是能够明确想起某个事件或事实的一种记忆，有时也被称为外显记忆 （Explicit memory），程序性记忆（procedural memory）指的是属于无意识，不能被表述的记忆，有时也被称为内隐记忆（implicit memory）*

If you pause for a minute, the whole idea of two components should be pretty obvious. If you take two items right after a review, one with a short optimum interval and the other with a long optimum interval, the memory status of the two must differ. Both can be recalled perfectly (maximum retrievability) and they also need to differ in how long they can last in memory (different stability). I was surprised I could not find any literature on the subject. However, if the literature has no mention of the existence of the optimum interval in spaced repetition, this seemingly obvious conclusion might be hiding behind another seemingly obvious idea: the progression of increasing interval in optimally spaced review. This is a lovely illustration how human progress is incremental and agonizingly slow. We are notoriously bad at thinking out of the box. The darkest place is under the candlestick. This weakness can be broken with an explosion of communication on the web. I advocate less peer review and more bold hypothesizing. I speak of a fantastic example coming from Robin Clarke’s paper in reference to Alzheimer’s. Strict peer review is reminiscent of Prussian schooling: in the quest for perfection, we lose our creativity, then humanity, and ultimately the pleasure of life.

如果您停下来思考一分钟，记忆有两个组成部分（*注：结合上下文，Piotr Wozniak 博士所说的“两个组成部分”应该是指“可检索性”（有多容易记起来）和“稳定性”（能记多久）*）这件事应该是非常明显的。如果您在复习后立即取两个项目，一个具有较短的最优间隔，另一个具有较长的最优间隔，则两个项目的记忆状态一定不同。两者都可以完美地回忆起来（最大可检索性），那么它们在记忆中的持续时间也一定不同（不同的稳定性）。（*注：即可检索性相同的记忆，稳定性可能不同，Wozniak 博士试图以此证明记忆一定存在两种不同的属性，即两个组成部分*）我很惊讶我没有找到任何关于这个主题的文献。但是，如果文献中没有提到间隔重复中最佳间隔的存在，那么这个看似显而易见的结论可能隐藏在另一个看似显而易见的想法背后：最佳间隔复习中，间隔增加的进展。这是一个很好的例子，说明人类的进步是渐进的和痛苦缓慢的。我们非常不擅长跳出框架思考。最黑暗的地方就在烛台之下。这种弱点可以通过网络上爆炸性的交流来打破。我主张减少同行评审，增加大胆的假设。我以罗宾·克拉克（Robin Clarke）关于阿尔茨海默病的论文为例。严格的同行评审让人想起普鲁士学校：在追求完美的过程中，我们失去了创造力，然后失去了人性，最终失去了生活的乐趣。

When I first presented my ideas to my teacher Dr Katulski on Feb 19, 1988, he was not too impressed, but he gave me a pass for computer simulations credit. Incidentally, a while later, Katulski became one of the first users of SuperMemo 1.0 for DOS.

当我于1988年2月19日首次向我的老师卡图尔斯基博士介绍我的想法时，他并没有什么触动，但他给我通过了计算机模拟课的学分。顺便说一句，不久之后，卡图尔斯基老师成为了 DOS 版 SuperMemo 1.0的首批用户之一。

In my Master’s Thesis (1990), I added a slightly more formal proof of the existence of the two components. That part of my thesis remained unnoticed.

在我的硕士论文（1990年）中，我添加了对长期记忆的两个组成部分存在性的稍微更正式的证明。我的那部分论文仍然没有引起注意。

In 1994, J. Kowalski wrote in Enter, Poland:

> We got to the point where the evolutionary interpretation of memory indicates that it works using the principles of increasing intervals and the spacing effect. Is there any proof for this model of memory apart from the evolutionary speculation? In his Doctoral Dissertation, Wozniak discussed widely molecular aspects of memory and has presented a hypothetical model of changes occurring in the synapse in the process of learning.

1994 年，J. Kowalski 在波兰的 Enter 期刊上写道：

> 我们已经找到了记忆进化的解释，即它遵循增加间隔和间隔效应的原则。除了基于记忆进化过程的推测之外，这种记忆模型还有什么证据吗？Wozniak（*注：即本文作者*）在他的博士论文中广泛讨论了记忆在分子层面的表现，并提出了学习过程中突触发生变化的假设模型。

The novel element presented in the thesis was the distinction between the stability and retrievability of memory traces. This could not be used to support the validity of SuperMemo because of the simple fact that it was SuperMemo itself that laid the groundwork for the hypothesis. However, an increasing molecular evidence seems to coincide with the stability-retrievability model providing, at the same time, support for the correctness of assumptions leading to SuperMemo. 

论文中提出的一项新颖元素是记忆痕迹的稳定性和可检索性之间的区别。这不能用来支持 SuperMemo 的有效性，因为正是 SuperMemo 为这一假设奠定了基础。然而，越来越多分子层面的证据似乎与稳定性-可检索性模型一致，同时支持导致 SuperMemo 诞生的假设的正确性。

In plain terms, retrievability is a property of memory which determines the level of efficiency with which synapses can fire in response to the stimulus, and thus elicit the learned action. The lower the retrievability the less you are likely to recall the correct response to a question. On the other hand, stability reflects the history of earlier repetitions and determines the extent of time in which memory traces can be sustained. The higher the stability of memory, the longer it will take for the retrievability to drop to the zero level, i.e. to the level where memories are permanently lost. According to Wozniak, when we learn something for the first time we experience a slight increase in the stability and retrievability in synapses involved in coding the particular stimulus-response association. In time, retrievability declines rapidly; the phenomenon equivalent to forgetting. At the same time, the stability of memory remains at the approximately same level. However, if we repeat the association before retrievability drops to zero, retrievability regains its initial value, while stability increases to a new level, substantially higher than at primary learning. Before the next repetition takes place, due to increased stability, retrievability decreases at a slower pace, and the inter-repetition interval might be much longer before forgetting takes place. Two other important properties of memory should also be noted: (1) repetitions have no power to increase the stability at times when retrievability is high (spacing effect), (2) upon forgetting, stability declines rapidly.

简单来说，可检索性是记忆的一种属性，它决定着突触响应刺激并引发学习行为的效率水平。可检索性越低，您就越不可能回忆起问题的正确答案。另一方面，稳定性反映了早期重复的历史，并决定了记忆痕迹可以维持的时间长度。记忆的稳定性越高，可检索性下降到零水平（即记忆永久丢失）所需的时间就越长。Wozniak 认为，当我们第一次学习某样东西时，参与编码特定刺激-反应关联的突触的稳定性和可检索性会略有增加。随着时间的推移，可检索性会迅速下降；这相当于发生遗忘现象。同时，记忆的稳定性大致保持在相同水平。但是，如果我们在可检索性降至零之前重复关联，则可检索性将恢复到初始值，而稳定性则会增加到一个新的水平，远高于初次学习时。在下一次重复发生之前，由于稳定性增加，可检索性下降的速度会更慢，并且在遗忘发生之前，重复间隔可能会更长。通识还应该注意记忆的另外两个重要特性：（1）当可检索性很高时，重复不能增加稳定性（间隔效应），（2）遗忘后，稳定性会迅速下降。

We published our ideas with Drs Janusz Murakowski and Edward Gorzelańczyk in 1995. Murakowski perfected the mathematical proof. Gorzelańczyk fleshed out the molecular model. We have not heard much enthusiasm or feedback from the scientific community. The idea of two components of memory is like wine, the older it gets, the better it tastes. We keep wondering when it will receive a wider recognition. After all, we do not live in Mendel‘s time to keep a good gem hidden in some obscure archive. There are millions of users of spaced repetition and even if 0.1% got interested in the theory, they would hear of our two components. Today, even the newest algorithm in SuperMemo is based on the two-component model and it works like a charm. Ironically, users tend to flock to simpler solutions where all the mechanics of human memory remain hidden. Even at supermemo.com we make sure we do not scare customers with excess numbers on the screen.

我们与 Janusz Murakowski 博士和 Edward Gorzelańczyk 博士在 1995 年发表了我们的想法。Murakowski 完善了数学证明。Gorzelańczyk 充实了分子模型。但我们没有从科学界听到太多的热情或反馈。记忆二元论就像酒一样，越陈越香。我们一直在想它什么时候会得到更广泛的认可。毕竟，我们不像孟德尔那样，把一个好的宝石藏在某个不知名的档案馆里。有数百万人使用间隔重复，即使只有 0.1% 的人对这个理论感兴趣，他们也会听说我们提出的两个要素。今天，即使是 SuperMemo 中最新的算法也基于记忆二元模型，并且运行良好。具有讽刺意味的是，用户倾向于使用更简单的解决方案，在这些解决方案中，人类记忆的所有机制都被隐藏了。即使在 supermemo.com 网站上，我们也需要确保不要让客户被屏幕上的过多数字吓到。

The concept of the two components of memory has parallels to prior research, esp. by Bjork.

记忆二元论的概念与之前的研究（尤其是 Bjork 的研究）存在相似之处。

In the 1940s, scientists investigated habit strength and response strength as independent components of behavior in rats. Those concepts were later reformulated in Bjork’s disuse theory. Herbert Simon seems to have noticed the need for memory stability variable in his paper in 1966. In 1969, Robert Bjork formulated the Strength Paradox: a reverse relationship between the probability of recall and the memory effect of a review. Note that his is a restatement of the spacing effect in terms of the two component model, which is just a short step away from formulating the distinction between the variables of memory. This led to Bjork’s New Theory of Disuse (1992) that would distinguish between the storage strength and the retrieval strength. Those are close equivalents of retrievability and stability with a slightly different interpretation of the mechanisms that underlie the distinction. Most strikingly, Bjork believes that when retrievability drops to zero, stable memories are still retained (in our model, stability becomes indeterminate). At the cellular level, Bjork might be right, at least for a while, but practise of SuperMemo shows the power of complete forgetting, while, from the neural point of view, retaining memories in disuse would be highly inefficient independent of their stability. Last but not least, Bjork defines storage strength in terms of connectivity, which is very close to what I believe happens in good students: coherence affects stability.

1940 年代，科学家将大鼠行为中的习惯强度和反应强度作为独立成分进行了研究。这些概念后来在 Bjork 的废用理论中被重新表述。赫伯特·西蒙 (Herbert Simon) 在 1966 年的论文中似乎意识到了需要引入记忆稳定性的变量。1969 年，罗伯特·比约克 (Robert Bjork) 提出“强度悖论”：回忆概率与复习的记忆效应之间呈负相关关系。请注意，这其实是记忆二元模型中的间隔效应的另一种表述，距离区分记忆变量只是一步之遥。这导致了 Bjork 在 1992 年提出的“新的废用理论”，该理论将存储强度和检索强度区分开来。这已经与可检索性和稳定性非常接近，只是对底层机制的解释略有不同。最引人注目的是，Bjork 认为当可检索性降至零时，稳定的记忆仍然会保留（在我们的模型中，稳定性变得不确定）。在细胞层面，Bjork 可能至少在一段时间内是对的，但 SuperMemo 的实践表明了完全遗忘的威力，同时从神经元的角度来看，以废用的方式保留记忆会非常低效，这与它们的稳定性无关。最后还必须强调，Bjork 用连接性来定义存储强度，这非常接近我认为优秀学习者身上发生的事情：连贯性会影响稳定性。

Why aren’t two components of memory entering mainstream research yet? I claim that if human mind tends to be short-sighted, and we all are, by design, the mind of science can be truly strangulated by strenuous duties, publish or perish, battles for grants, hierarchies, conflict of interest, peer review, teaching obligations and even the code of conduct. Memory researchers tend to live in a single dimension of “memory strength”. In that dimension, they cannot truly appreciate true dynamics of molecular processes that need to be investigated to crack the problem. Ironically, progress may come from those who tend to work in artificial intelligence or neural network. Prodigious minds of Demis Hassabis or Andreas Knoblauch come up with twin ideas by independent reasoning process, models, and simulations. Biologists will need to listen to the language of mathematics or computer science.

为什么记忆的两个组成部分还没有进入主流研究？我认为，如果人类思维倾向于短视，而我们所有人天生都这样，那么科学思维可能会被繁重的任务所扼杀，发表文章或消亡、争夺资助、等级制度、利益冲突、同行评审、教学义务甚至行为准则。记忆研究人员倾向于生活在“记忆强度”的单一维度中。在这个维度中，他们无法真正理解破解问题所需的分子过程的真实动态。具有讽刺意味的是，进步可能来自那些倾向于在人工智能或神经网络领域工作的人。像德米斯·哈萨比斯 (Demis Hassabis) 或安德烈亚斯·克诺布劳赫 (Andreas Knoblauch) 这样杰出的头脑通过独立的推理过程、模型和模拟提出了孪生模型。生物学家将需要倾听数学或计算机科学的语言。

*注：这里不太确定 Wozniak 教授说的“孪生想法（twin idea）”指的具体是什么，根据译者的搜索结果来看，可能指的是“数字孪生模型”，但译者搜索能力有限，没能找到数字孪生模型和 Wozniak 教授提到的这两位提出者之间的关联。数字孪生是充分利用物理模型、传感器、运行历史等数据，集成多学科、多物理量、多尺度、多概率的仿真过程，在虚拟空间中完成映射，从而反映相对应的实体装备的全生命周期过程。数字孪生是一种超越现实的概念，可以被视为一个或多个重要的、彼此依赖的装备系统的数字映射系统。（简单来说，在虚拟空间模拟产品在现实中的所有过程）*

### 算法SM-17中的二元模型（Two component model in Algorithm SM-17）

The two component model of long-term memory underlies Algorithm SM-17. The success of Algorithm SM-17 is the ultimate practical proof for the correctness of the model.

算法SM-17的基础是长期记忆的二元模型。算法 SM-17 的成功是对该模型正确性的最终实践证明。

A graph of actual changes in the value of the two components of memory provides a conceptual visualization of the evolving memory status:

记忆的两个组成部分（即“二元模型”中的“二元”）实际变化的图表提供了对不断发展的记忆状态的概念可视化：

![[SuperMemo_The true history of spaced repetition_附件/Memory_status.jpg]]

> ***Figure:** Changes in memory status over time for an exemplary item. The horizontal axis represents time spanning the entire repetition history. The top panel shows retrievability (tenth power, R^10, for easier analysis). Retrievability grid in gray is labelled by R=99%, R=98%, etc. The middle panel displays optimum intervals in navy. Repetition dates are marked by blue vertical lines and labelled in aqua. The end of the optimum interval where R crosses 90% line is marked by red vertical lines (only if intervals are longer than optimum intervals). The bottom panel visualizes stability (presented as `ln(S)/ln(days)` for easier analysis). The graph shows that retrievability drops fast (exponentially) after early repetitions when stability is low, however, it only drops from 100% to 94% in long 10 years after the 7th review. All values are derived from an actual repetition history and the three component model of memory.*
> 
> _**图：**_ 示例项目的记忆状态随时间变化的示意图。水平轴表示跨越所有重复过程的时间。图片顶部显示可检索性（第十次方，R^10，便于分析）。灰色的可检索性网格由R=99%，R=98%等标记。图片中间以海军蓝显示最佳间隔。重复日期用蓝色垂直线标记并用浅绿色标注。R越过90%线的最佳间隔结束处用红色垂直线标记（仅当间隔长于最佳间隔时）。底部面板显示稳定性（用`ln(S)/ln(days)`表示，便于分析）。该图显示，在早期重复后，当稳定性较低时，可检索性下降很快（呈指数级），然而，在第七次复习后的10年里，它只从100%下降到94%。所有值均来自真实的重复过程和记忆的三成分模型。

Due to the fact that real-life application of SuperMemo requires tackling learning material of varying difficulty, the third variable involved in the model is item difficulty (D). Some of the implications of item difficulty have also been discussed in the above article. In particular, the impact of composite memories with subcomponents of different memory stability (S).

由于 SuperMemo 的实际应用需要处理难度不同的学习材料，因此模型中涉及的第三个变量是项目难度（D）。 上文也讨论了项目难度的一些影响，特别是具有不同记忆稳定性（S）的子组件的复合记忆的影响。

For the purpose of the new algorithm we have defined the three components of memory as follows:

-   Memory Stability (S) is defined as the inter-repetition interval that produces average recall probability of 0.9 at review time
-   Memory Retrievability (R) is defined as the expected probability of recall at any time on the assumption of negatively exponential forgetting of homogenous learning material with the decay constant determined by memory stability (S)
-   Item Difficulty (D) is defined as the maximum possible increase in memory stability (S) at review mapped linearly into 0..1 interval with 0 standing for easiest possible items, and 1 standing for highest difficulty in consideration in SuperMemo (the cut off limit currently stands at stability increase 6x less than the maximum possible)

为了提出新算法，我们定义了记忆的三个组成部分如下：

- **记忆稳定性（S）** 定义为“使得复习时，能回忆起的内容占比90%”的重复间隔。
- **记忆可检索性（R）** 定义为在假设具有相同衰减常数（由记忆稳定性（S）确定）的学习材料被负指数遗忘的情况下，任何时间点的能回想起学习材料的概率。
- **项目难度（D）** 定义为复习时记忆稳定性（S）的最大可能增加，线性映射到0..1区间，其中0代表最简单的项目，1代表 SuperMemo 中设置的最高难度（目前，作为极限的最高难度下，稳定性（S）每次增加的数值小于最大可能值的1/6）。


### 证明（Proof）

The actual proof from my Master’s Thesis follows. For a better take on this proof, see Murakowski proof.

以下是我硕士论文中的实际证明。有关这个证明的更深入的理解，请参考 Murakowski 的证明。

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

**10.4.2. Two variables of memory: stability and retrievability**

**10.4.2. 记忆的两个变量：稳定性和可检索性**

There is an important conclusion that comes directly from the SuperMemo theory that there are two, and not one, as it is commonly believed, independent variables that describe the conductivity of a synapse and memory in general. To illustrate the case, let us again consider the calpain model of synaptic memory. It is obvious from the model, that its authors assume that only one independent variable is necessary to describe the conductivity of a synapse. Influx of calcium, activity of calpain, degradation of fodrin and number of glutamate receptors are all examples of such a variable. Note that all the mentioned parameters are dependent, i.e. knowing one of them we could calculate all others; obviously only in the case if we were able to construct the relevant formulae. The dependence of the parameters is a direct consequence of causal links between all of them.

SuperMemo 理论得出一个重要结论：描述突触传导率和一般记忆的独立变量有两个，而非普遍认为的一个。为了说明这一点，让我们再次考虑突触记忆的钙蛋白酶模型。从该模型中可以明显看出，其作者假设描述突触传导率只需要一个独立变量。钙离子流入、钙蛋白酶活性、fodrin 降解和谷氨酸受体数量都是此类变量的实例。请注意，这里提到的所有参数都是相互依赖的，即知道其中一个，我们就可以计算出所有其他参数；前提是，只有在我们能够构建相关关联性公式的情况下才能做到这一点。参数之间的依赖性是它们之间因果关系的直接结果。

However, the process of optimal learning requires exactly two independent variables to describe the state of a synapse at a given moment:

-   A variable that plays the role of a clock that measures time between repetitions. Exemplary parameters that can be used here are:
    -   T <sub>e</sub> – time that has elapsed since the last repetition (it belongs to the range <0,optimal-interval>),
    -   T <sub>l</sub> – time that has to elapse before the next repetition will take place (T <sub>l</sub>=optimal-interval-T <sub>e</sub>),
    -   P <sub>f</sub> – probability that the synapse will lose the trace of memory during the day in question (it belongs to the range <0,1>).Obviously, one can conceive a countless number of parameters that could be used in representing the clock variable. All these parameters are dependent, i.e. one of them is sufficient to compute all the others.
-   A variable that measures the durability of memory. Exemplary parameters that can be used here are:
    -   I(n+1) – optimal interval that should be used after the next repetition (I(n+1)=I(n)×C where C is a constant greater than three),
    -   I(n) – current optimal interval,
    -   n – number of repetitions preceding the moment in question, etc. Again the parameters are dependent and only one of them is needed to characterize the durability of memory.

然而，最佳学习过程明确需要两个独立变量来描述突触在给定时刻的状态：

- **一个变量充当时钟，测量两次重复之间的时间。** 示例参数包括：
    - T<sub>e</sub> - 自上次重复以来经过的时间（T<sub>e</sub> 取值范围为<0,optimal-interval>），
    - T<sub>l</sub> - 下次重复之前必须经过的时间（T<sub>l</sub>=optimal-interval-T<sub>e</sub>），
    - P<sub>f</sub> - 突触在当天丢失记忆痕迹的概率（范围为<0,1>）。 显然，可以设想无数个可用于表示时钟变量的参数。所有这些参数都是相互依赖的，即其中一个足以计算出所有其他参数。
- **一个变量测量记忆的持久性。** 示例参数包括：
    - I(n+1) - 下次重复（记忆）后应使用的最佳（记忆）间隔（I(n+1)=I(n)×C，其中 C 是大于 3 的常数），
    - I(n) - 当前最佳（记忆）间隔，
    - n - 已经发生的重复次数，等等。 这些参数同样相互依赖，只需要其中一个来表征记忆的持久性。

Let us now see if the above variables are necessary and sufficient to characterize the state of synapses in the process of time-optimal learning. To show that variables are independent, we will show that none of them can be calculated from the other. Let us notice that the I(n) parameter remains constant during a given inter-repetition interval, while the T <sub>e</sub> parameter changes from zero to I(n). This shows that there is no function f that satisfies the condition:

> T <sub>e</sub>=f(I(n))

现在让我们看看上述变量是否必要且足以表征“时间最优学习”过程中突触的状态。为了证明变量是独立的，我们将证明其中任何一个都不能从另一个计算出来。 让我们注意到，在给定的两次重复间隔内，I(n) 参数保持不变，而 T<sub>e</sub> 参数从零变为 I(n)。 这表明不存在满足以下条件的函数 f：

> T<sub>e</sub>=f(I(n))

On the other hand, at the moment of subsequent repetitions, T <sub>e</sub> always equals zero while I(n) has always a different, increasing value. Therefore there is no function g that satisfies the condition:

> I(n)=g(T <sub>e</sub>)

另一方面，在随后的重复开始的时刻，T<sub>e</sub> 始终等于零，而 I(n) 始终具有不同的递增值。 因此，不存在满足以下条件的函数 g：

> I(n)=g(T <sub>e</sub>)

Hence independence of I(n) and T <sub>e</sub>.

I(n) 和 T<sub>e</sub> 的独立性由此得证。

To show that no other variables are necessary in the process of optimal learning, let us notice that at any given time we can compute all the moments of future repetitions using the following algorithm:

1.  Let there elapse I(n)-T <sub>e</sub> days.
2.  Let there be a repetition.
3.  Let T <sub>e</sub> be zero and I(n) increase C times.
4.  Go to 1.

为了证明在最佳学习过程中不需要其他变量，请大家注意，在任何给定时间，我们可以使用以下算法计算所有未来的重复该在何时进行：

1. 等待 I(n)-T<sub>e</sub> 天。
2. 进行一次重复。
3. 将 T<sub>e</sub> 设为零，并将 I(n) 乘以 C。
4. 返回步骤 1。

Note that the value of C is a constant characteristic for a given synapse and as such does not change in the process of learning. I will later use the term **retrievability** to refer to the first of the variables and the term **stability** to refer to the second one. To justify the choice of the first term, let me notice that we use to think that memories are strong after a learning task and that they fade away afterwards until they become no longer retrievable. This is retrievability that determines the moment at which memories are no longer there. It is also worth mentioning that retrievability was the variable that was tacitly assumed to be the only one needed to describe memory (as in the calpain model). The invisibility of the stability variable resulted from the fact that researchers concentrated their effort on a single learning task and observation of the follow-up changes in synapses, while the importance of stability can be visualized only in the process of repeating the same task many times. To conclude the analysis of memory variables, let us ask the standard question that must be posed in development of any biological model. What is the possible evolutionary advantage that arises from the existence of two variables of memory?

请注意，C 的值对于给定的突触来说是一个恒定的特征，因此在学习过程中不会改变。我稍后将使用术语“可检索性”来指代第一个变量，使用术语“稳定性”来指代第二个变量。为了证明选择第一个术语的合理性，让我注意到，我们习惯于认为记忆在学习任务之后是强大的，然后逐渐淡化，直到不再可检索。正是可检索性决定了记忆不再存在的时刻。还值得一提的是，可检索性被默认为是描述记忆所需要的唯一变量（如在钙蛋白酶模型中）。稳定性变量的不可见性源于研究人员将精力集中在单个学习任务上并观察突触的后续变化，而稳定性的重要性只有在多次重复同一任务的过程中才能显现出来。为了结束对记忆变量的分析，让我们提出在开发任何生物模型时都必须提出的标准问题：记忆存在两个变量会带来什么可能的进化优势？

Retrievability and stability are both necessary to code for a process of learning that allows subsequent inter-repetition intervals to increase in length without forgetting. It can be easily demonstrated that such model of learning is best with respect to the survival rate of an individual if we acknowledge the fact that remembering without forgetting would in a short time clog up the memory system which is a finite one. If memory is to be forgetful it must have a means of retaining of these traces that seem to be important for survival. Repetition as a memory strengthening factor is such a means. Let us now consider what is the most suitable timing of the repetitory process. If a given phenomenon is encountered for the n-th time, the probability that it will be encountered for the n+1 time increases and therefore a longer memory retention time seems advantageous. The exact function that describes the best repetitory process depends on the size of memory storage, number of possible phenomena encountered by an individual, and many others. However, the usefulness of increasing intervals required to sustain memory by repetitions is indisputable and so is the evolutionary value of retrievability and stability of memory. One can imagine many situations interfering with this simple picture of the development of memory in the course of evolution. For example, events that were associated with an intense stress should be remembered better. Indeed, this fact was proved in research on the influence of catecholamines on learning. Perhaps, using hormonal stimulation one could improve the performance of a student applying the SuperMemo method.

可检索性和稳定性对于编码一种学习过程都是必要的，这种学习过程允许随后的重复间隔时间增加而记忆不被遗忘。只要我们承认这样一个事实：如果不遗忘地记住所有东西，在短时间内就会堵塞有限的记忆系统，那么很容易证明这种学习模型对于个体的生存率是最好的。如果记忆要遗忘，它必须有一种方法来保留那些似乎对生存很重要的痕迹。重复作为一种记忆强化因素就是这样一种方法。现在让我们考虑一下重复过程最合适的时机。如果某个现象被遇到了第 n 次，那么它被遇到第 n+1 次的概率就会增加，因此更长的记忆保留时间似乎更有优势。描述最佳重复过程的确切函数取决于记忆存储的大小、个体可能遇到的现象数量以及许多其他因素。然而，让维持记忆所需的间隔随重复次数增长，这种策略的实用性是无可争辩的，记忆的可检索性和稳定性在进化中的价值也是同样。可以想象，在进化的背景下，许多情况都会对这种记忆（机制随进化而）演化的过程产生干预。例如，与强烈压力相关的事件应该被更好地记住。事实上，这一事实已在关于儿茶酚胺对学习影响的研究中得到证实。也许，使用激素刺激可以提高应用 SuperMemo 记忆法的学生的表现。

**Interim summary**：
1.  Existence of two independent variables necessary to describe the process of optimal learning was postulated. These variables were named retrievability and stability of memory
2.  Retrievability of memory reflects the lapse of time between repetitions and indicates to what extent memory traces can successfully be used in the process of recall
3.  Stability of memory reflects the history of repetitions in the process of learning and increases with each stimulation of the synapse. It determines the length of the optimum inter-repetition interval

**阶段性总结：**
1. 存在两个独立变量是描述最佳学习过程所必需的。这两个变量被命名为记忆的可检索性和稳定性。
2. 记忆的可检索性反映了重复之间的时间间隔，并表明在回忆过程中记忆痕迹能够成功使用的程度。
3. 记忆的稳定性反映了学习过程中重复的历史，并随着每次突触刺激而增加。它决定了最佳重复间隔的长度。

![[Hypothetical_mechanism_of_optimal_learning-1.jpg]]

> ***Figure:** Hypothetical mechanism involved in the process of optimal learning. (A) Molecular phenomena (B) Quantitative changes in the synapse.*
> 
> ***图：** 最佳学习过程中涉及的机制假设。（A）分子现象 （B）突触的定量变化。*

### Murakowski 的证明（Proof by Murakowski）

Here is an improved proof by Murakowski:

这里是 Murakowski 提供的更详尽的证明：

其中：

- I <sub>i</sub> – 第 i 次重复后的间隔时间 
- C <sub>1</sub> – 第一次间隔的长度（取决于所选的知识保留率，通常为几天）
- C <sub>2</sub> – 表示后续重复中间隔时间增长的常数（取决于所选的知识保留率和记忆项目的难度）

上述公式是通过计算机优化程序监督人类受试者使用主动回忆淘汰技术自定进度学习单词对的过程中得到的。[…]

It has been found in earlier research that the optimum spacing of repetitions in paired-associate learning, understood as the spacing which takes a minimum number of repetitions to indefinitely maintain a constant level of knowledge retention (e.g. 95%), can roughly be expressed using the following formulae ( Wozniak and Gorzelańczyk 1994).

-   (1) I <sub>1</sub>=C <sub>1</sub>
-   (2) I <sub>i</sub>=I <sub>i-1</sub>×C <sub>2</sub>

where:

-   I <sub>i</sub> – inter-repetition interval after the i-th repetition
-   C <sub>1</sub> – length of the first interval (dependent on the chosen knowledge retention, and usually equal to several days)
-   C <sub>2</sub> – constant that denotes the increase of inter-repetition intervals in subsequent repetitions (dependent on the chosen knowledge retention, and the difficulty of the remembered item)

早期的研究发现，在配对联想学习中，最佳重复间隔（即通过最小重复次数，实现长期维持一定水平的知识保留率（例如 95%）对应的间隔）可以用以下公式近似表示（Wozniak 和 Gorzelańczyk 1994）。

-   (1) I <sub>1</sub>=C <sub>1</sub> 
-   (2) I <sub>i</sub>=I <sub>i-1</sub>×C <sub>2</sub>

其中：

- I <sub>i</sub> – 第 i 次重复后的间隔时间
- C <sub>1</sub> – 第一次间隔的长度（取决于所选的知识保留率，通常为几天）
- C <sub>2</sub> – 表示后续重复中间隔时间增长幅度的常数（取决于所选的知识保留率和记忆项目的难度）

The above formulae have been found for human subjects using computer optimization procedures employed to supervise the process of self-paced learning of word-pairs using the active recall drop-out technique. […]

上述公式是通过真人实验项目得到的，实验内容为，使用计算机优化程序，监测受试者“使用主动回忆淘汰技术，自定进度学习单词对”的过程。[…]

As it will be shown below, the widely investigated strength of memory (or synaptic potentiation) does not suffice to account for the regular pattern of optimum repetition spacing: […]

1.  We want to determine the set of (molecular) variables involved in storing memory traces that will suffice to account for the optimum spacing of repetitions. Let us, initially, assume two correlates of these variables in learning that is subject to optimum spacing as expressed by Eqns. (1) and (2):*r* – time which remains from the present moment until the end of the current optimum interval (optimum interval is the interval at the end of which the retention drops to the previously defined level, e.g. 95%)*s* – length of the current optimum interval.
2.  Just at the onset of the i-th repetition, *r*=0, while *s* <sub>i</sub>> *s* <sub>i-1</sub>>0 ( *s* <sub>i</sub> denotes *s* right at the onset of the i-th repetition). This indicates that there is no function g <sub>1</sub> such that s=g <sub>1</sub>( *r*), i.e. *s* cannot be a function of *r* only.
3.  During the inter-repetition interval, *r*(t <sub>1</sub>)<> *r*(t <sub>2</sub>) if t <sub>1</sub><>t <sub>2</sub> (t denotes time and *r*(t) denotes *r* at the moment t). On the other hand, *s*(t <sub>1</sub>)= *s*(t <sub>2</sub>) ( *s*(t) denotes *s* at the moment t). This shows that there is no function g <sub>2</sub> such that *r*=g <sub>2</sub>( *s*), or we would have: *r*(t <sub>1</sub>)=g <sub>2</sub>( *s*(t <sub>1</sub>))=g <sub>2</sub> ( *s*(t <sub>2</sub>))= *r*(t <sub>2</sub>), which leads to a contradiction. *r* cannot be a function of *s* only.
4.  In Steps 2 and 3 we have shown that *r* and *s* are independent, as there are no functions g <sub>1</sub> and g <sub>2</sub> such that *s*=g <sub>1</sub>( *r*) or *r*=g <sub>2</sub>( *s*). This obviously does not mean that there exists no parameter x and functions y <sub>s</sub> and y <sub>r</sub> such that *s*=y <sub>s</sub>(x) and *r*=y <sub>r</sub>(x).
5.  It can be shown that *r* and *s* suffice to compute the optimum spacing of repetitions (cf. Eqns. (1) and (2)). Let us first assume that the two following functions f <sub>r</sub> and f <sub>s</sub> are known in the system involved in memory storage: *r* <sub>i</sub>=f <sub>r</sub>( *s* <sub>i</sub>) and *s* <sub>i</sub>=f <sub>s</sub>( *s* <sub>i-1</sub>). In our case, these functions have a trivial form f <sub>r</sub>: *r* <sub>i</sub>= *s* <sub>i</sub> and f <sub>s</sub>: *s* <sub>i</sub>= *s* <sub>i-1</sub>*C <sub>2</sub> (where C <sub>2</sub> is the constant from Eqn. (2)). In such a case, the variables *r* and *s* are sufficient to represent memory at any moment t in optimum spacing of repetitions. Here is a repetition spacing algorithm which shows this to be true:
    1.  assume that the variables *r* <sub>i</sub> and *s* <sub>i</sub> describe the state of memory after the i-th repetition
    2.  let there elapse *r* <sub>i</sub> time
    3.  let there be a repetition
    4.  let the function f <sub>s</sub> be used to compute the new value of *s* <sub>i+1</sub> from *s* <sub>i</sub>
    5.  let the function f <sub>r</sub> be used to compute the new value of *r* <sub>i+1</sub> from *s* <sub>i+1</sub>
    6.  i:=i+1
    7.  goto 2

正如下面所示，被广泛研究的记忆强度（或突触强化）模型不足以解释最佳间隔随重复次数变化的规律：[…]

1. 我们想要确定存储记忆痕迹中涉及的一组（分子）变量，使这些变量足以解释最佳重复间隔。 最初，让我们假设与这些变量相关的因素有两个，这些因素在学习过程中表现出来（学习过程中的重复间隔遵循公式（1）和（2）的计算结果）：
	- *r* - 从现在到当前最佳间隔结束之间剩余的时间（最佳间隔是指，使保留率下降到先前定义的水平的间隔，例如 95% 的间隔）
	- *s* - 当前最佳间隔的长度。
2. 在第 i 次重复刚刚开始时，*r*=0，而 *s* <sub>i</sub>> *s* <sub>i-1</sub>>0（*s* <sub>i</sub> 表示第 i 次重复开始时的 *s*）。 这表明不存在函数 g <sub>1</sub> 使得 s=g <sub>1</sub>(*r*)，即 *s* 不能仅是 *r* 的函数。
3. 在重复间隔期间，如果 t <sub>1</sub><>t <sub>2</sub> 则 *r*(t <sub>1</sub>)<> *r*(t <sub>2</sub>)（t 表示时间，*r*(t) 表示时刻 t 的 *r*）。 另一方面，*s*(t <sub>1</sub>)= *s*(t <sub>2</sub>)（*s*(t) 表示时刻 t 的 *s*）。 这表明不存在函数 g <sub>2</sub> 使得 *r*=g <sub>2</sub>(*s*)，否则我们将有：*r*(t <sub>1</sub>)=g <sub>2</sub>(*s*(t <sub>1</sub>))=g <sub>2</sub> (*s*(t <sub>2</sub>))= *r*(t <sub>2</sub>)，这会导致矛盾。 *r* 不能仅是 *s* 的函数。
4. 在步骤 2 和 3 中，我们已经证明 *r* 和 *s* 是独立的，因为不存在函数 g <sub>1</sub> 和 g <sub>2</sub> 使得 *s*=g <sub>1</sub>(*r*) 或 *r*=g <sub>2</sub>(*s*)。 这显然并不意味着不存在参数 x 和函数 y <sub>s</sub> 和 y <sub>r</sub> 使得 *s*=y <sub>s</sub>(x) 和 *r*=y <sub>r</sub>(x)。
5. 可以证明 *r* 和 *s* 足以计算最佳重复间隔（参见公式（1）和（2））。 让我们首先假设在涉及记忆存储的系统中已知以下两个函数 f <sub>r</sub> 和 f <sub>s</sub>：*r* <sub>i</sub>=f <sub>r</sub>(*s* <sub>i</sub>) 和 *s* <sub>i</sub>=f <sub>s</sub>(*s* <sub>i-1</sub>)。 在我们的例子中，这些函数具有简单的形式 f <sub>r</sub>：*r* <sub>i</sub>= *s* <sub>i</sub> 和 f <sub>s</sub>：*s* <sub>i</sub>= *s* <sub>i-1</sub>×C <sub>2</sub>（其中 C <sub>2</sub> 是公式（2）中的常数）。 在这种情况下，变量 *r* 和 *s* 足以在最佳重复间隔的任何时刻 t 表示记忆。 以下是显示这是正确的重复间隔算法：
    1. 假设变量 *r* <sub>i</sub> 和 *s* <sub>i</sub> 描述第 i 次重复后的记忆状态
    2. 等时间经过 *r* <sub>i</sub>
    3. 进行重复
    4. 按照函数 f <sub>s</sub> 用 *s* <sub>i</sub> 计算 *s* <sub>i+1</sub> 的新值
    5. 按照函数 f <sub>r</sub> 用 *s* <sub>i+1</sub> 计算 *r* <sub>i+1</sub> 的新值
    6. i:=i+1
    7. 回到第 2 步

The above reasoning shows that variables *r* and *s* form a sufficient set of independent variables needed to compute the optimum spacing of repetitions. Obviously, using a set of transformation functions of the form *r*’’=Tr( *r*’) and *s*’’=Ts( *s*’), one can conceive an infinite family of variable pairs *r*– *s* that could describe the status of the memory system. A difficult choice remains to choose such a pair *r*– *s* that will most conveniently correspond with molecular phenomena occurring at the level of the synapse.

上述推理表明，变量 *r* 和 *s* 构成了一组充分的独立变量，用于计算最优重复间隔。显然，通过使用形式为 *r*’’=Tr( *r*’) 和 *s*’’=Ts( *s*’) 的一组变换函数，可以构想出无限多个变量对 *r*– *s* 来描述记忆系统的状态。但我们仍然需要面对一个困难的选择，即如何选择这样一个变量对 *r*– *s*，使其最方便地对应于突触水平发生的分子现象。

The following terminology and interpretation is proposed by the authors in a memory system involving the existence of the *r*– *s* pair of variables: the variable R, retrievability, determines the probability with which a given memory trace can be invoked at a given moment, while the variable S, stability of memory, determines the rate of decline of retrievability as a result of forgetting, and consequently the length of inter-repetition intervals in the optimum spacing of repetitions.

作者在涉及 *r*– *s* 变量对的记忆系统中提出了以下术语和解释：变量 R，即可检索性，决定了在给定时刻成功调用给定记忆痕迹的概率（即回忆起先前记忆的内容的概率），而变量 S，即记忆稳定性，决定了由于遗忘而导致的检索性下降率，从而决定了重复的最优间隔中的间隔时间。

Assuming the negatively exponential decrease of retrievability, and the interpretation of stability as a reciprocal of the retrievability decay constant, we might conveniently represent the relationship between R and S using the following formula (t denotes time):

> (3) R=e <sup>-t/S</sup>

假设可检索性呈负指数衰减，并将稳定性解释为可检索性衰减常数的倒数，我们可以方便地使用以下公式表示 R 和 S 之间的关系（t 表示时间）：

> (3) R=e <sup>-t/S</sup>

The transformation functions from the pair *r*– *s* used in Steps 1-5 of the reasoning, to the proposed interpretation R-S will look as follows (assuming the definition of the optimum inter-repetition interval as the interval that produces retention of knowledge K=0.95):

> (4) S=- *s*/ln(K)
> 
> (5) R=e <sup>-(&nbsp;<em>s</em>–&nbsp;<em>r</em>)/S</sup>

根据推理步骤 1-5 中使用的变量 *r*– *s* 的值，计算得到我们所提出的解释 R-S 的值的变换函数将如下所示（假设最优重复间隔的定义为使得知识保留率 K=0.95 的间隔）：

> (4) S=- *s*/ln(K)
> 
> (5) R=e <sup>-(&nbsp;<em>s</em>–&nbsp;<em>r</em>)/S</sup>

The relationship between the stability after the i-th repetition (S <sub>i</sub>) and the constants C <sub>1</sub> and C <sub>2</sub> determining the optimum spacing of repetitions as defined by Eqns. (1) and (2) can therefore be written as:

> (6) S <sub>i</sub>=-(C <sub>1</sub>×C <sub>2</sub> <sup>i-1</sup>)/ln(K)

因此，第 i 次重复后的稳定性（S <sub>i</sub>）与由公式 (1) 和 (2) 定义的确定重复最优间隔的常数 C <sub>1</sub> 和 C <sub>2</sub> 之间的关系可以写成：

> (6) S <sub>i</sub>=-(C <sub>1</sub>×C <sub>2</sub> <sup>i-1</sup>)/ln(K)

and finally, retrievability in the optimum spacing of repetitions can be expressed as:

> (7) R <sub>i</sub>(t)=exp <sup>(t×ln(K)/(C&nbsp;<sub>1</sub>×C&nbsp;<sub>2</sub>&nbsp;i-1))</sup>

最后，重复最优间隔中的检索性可以表示为：

> (7) R <sub>i</sub>(t)=exp <sup>(t×ln(K)/(C&nbsp;<sub>1</sub>×C&nbsp;<sub>2</sub>&nbsp;i-1))</sup>

where:

-   i – number of the repetition in question
-   t – time since the i-th repetition
-   R <sub>i</sub>(t) – retrievability after the time t passing since the i-th repetition in optimum spacing of repetitions
-   C <sub>1</sub> and C <sub>2</sub> – constants from Eqns. (1) and (2)
-   K – retention of knowledge equal to 0.95 (it is important to notice that the relationship expressed by Eqn. (7) may not be true for retention higher than 0.95 due to the spacing effect resulting from shorter intervals)

其中：

- i – 所讨论的重复次数
- t – 自第 i 次重复以来的时间
- R <sub>i</sub>(t) – 在最优重复间隔下，自第 i 次重复以来经过时间 t 后的检索性
- C <sub>1</sub> 和 C <sub>2</sub> – 来自公式 (1) 和 (2) 的常数
- K – 知识保留率，一般取等于 0.95（重要的是要注意，由于较短间隔产生的间隔效应，公式 (7) 所表达的关系可能不适用于高于 0.95 的保留率）

### SuperMemo 中记忆的两个组成部分（Two components of memory in SuperMemo）

SuperMemo has always been based on the two component model, which emerged in an increasingly explicit form over time. The constant C <sub>2</sub> in Eqn. (2) in Murakowski proof above represents stability increase. In 2018, stability increase is represented in SuperMemo as matrix *SInc[]*. C <sub>2</sub> says how much inter-repetition intervals should increase in learning to meet the criteria of admissible level of forgetting. In reality, C <sub>2</sub> is not a constant. It depends on a number of factors. Of these, the most important are:

-   item difficulty (D)(see: complexity): the more difficult the remembered piece of information the smaller the C <sub>2</sub> (i.e. difficult material must be reviewed more often)
-   memory stability (S): the more lasting/durable the memory, the smaller the C <sub>2</sub> value
-   probability of recall (retrievability) (R): the lower the probability of recall, the higher the C <sub>2</sub> value (i.e. due to the spacing effect, items are remembered better if reviewed with delay)

SuperMemo 一直基于记忆的二元模型，该模型随着时间的推移以越来越明确的形式出现。上述 Murakowski 证明中公式 (2) 中的常数 C <sub>2</sub> 代表稳定性增加。在 2018 年，稳定性增加在 SuperMemo 中表示为矩阵 *SInc[]*。C <sub>2</sub> 表示为了将遗忘水平限制在可接受的范围内，学习过程中重复间隔应该增长多少。实际上，C <sub>2</sub> 不是一个常数。它取决于许多因素。其中最重要的因素包括：

- 项目难度 (D)（参见：复杂性）：记忆的信息越难，C <sub>2</sub> 越小（即困难的材料必须更频繁地复习）
- 记忆稳定性 (S)：记忆越持久/耐用，C <sub>2</sub> 值越小
- 回忆概率（可检索性）（R）：重复时成功回忆的概率越低，C <sub>2</sub> 值越高（即由于间隔效应，如果延迟复习，项目记忆得更好）

Due to those multiple dependencies, the precise value of C <sub>2</sub> is not easily predictable. SuperMemo solves this and similar optimization problems by using multidimensional matrices to represent multi-argument functions and adjusting the value of those matrices on the basis of measurements made during an actual learning process. The initial values of those matrices are derived from a theoretical model or from previous measurements. The actually used values will, over time, differ slightly from those theoretically predicted or those derived from data of previous students.

由于这些多重依赖性，C <sub>2</sub> 的值不容易精准预测。SuperMemo 通过使用多维矩阵来表示多参数函数，并在实际学习过程中根据测量结果调整这些矩阵的值，从而解决了这个问题和类似的优化问题。这些矩阵的初始值来源于理论模型或先前的测量结果。实际使用值会随时间变得与理论预测值（或者从先前学生测试数据中得出的值）略有不同。

For example, if the value of C <sub>2</sub> for a given item of a given difficulty with a given memory status produces an inter-repetition interval that is longer than desired (i.e. producing lower than desired level of recall), the value of C <sub>2</sub> is reduced accordingly.

例如，如果对于给定难度和给定记忆状态的给定项目，C <sub>2</sub> 的值产生的重复间隔比期望的更长（即产生低于期望的回忆可能性），则相应地降低 C <sub>2</sub> 的值。

Here is the evolution of stability increase (constant C <sub>2</sub>) over years:

-   in the paper-and-pencil version of SuperMemo (1985), C <sub>2</sub> was indeed (almost) a constant. Set at the average of 1.75 (varying from 1.5 to 2.0 for rounding errors and simplicity), it did not consider material difficulty, stability or retrievability of memories, etc.
-   in early versions of SuperMemo for DOS (1987), C <sub>2</sub>, named E-Factor, reflected item difficulty for the first time. It was decreased for bad grades and increased for good grades
-   SuperMemo 4 (1989) did not use C <sub>2</sub>, but, to compute inter-repetition intervals, it employed optimization matrices for the first time
-   in SuperMemo 5 (1990), C <sub>2</sub>, named O-Factor was finally represented as a matrix and it included both the difficulty dimension as well as the stability dimension. Again, entries of the matrix would be subject to the measure-verify-correct cycle that would, starting with the initial value based on prior measurements, produce a convergence towards the value that would satisfy the learning criteria
-   in SuperMemo 6 (1991), C <sub>2</sub>, in the form of the O-Factor matrix would be derived from a three-dimensional matrix that would include the retrievability dimension. The important implication of the third dimension was that, for the first time, SuperMemo would make it possible to inspect forgetting curves for different levels of difficulty and memory stability
-   in SuperMemo 8 (1997) through SuperMemo 16, the representation of C <sub>2</sub> would not change much, however, the algorithm used to produce a quick and stable transition from the theoretical to the real set of data would gradually get more and more complex. Most importantly, new SuperMemos make a better use of the retrievability dimension of C <sub>2</sub>. Thus, independent of the spacing effect, the student can depart from the initial learning criteria, e.g. to cram before an exam, without introducing noise into the optimization procedure
-   in SuperMemo 17 (2016), C <sub>2</sub> finally took the form based on the original two-component model. It is taken from stability increase matrix (SInc) that has three dimensions that represent the three variables that determine the increase in stability: complexity, stability and retrievability. The SInc matrix is filled up with data during learning using a complex algorithm known as Algorithm SM-17. The stability increase matrix can be inspected in SuperMemo 17 with **Tools : Memory : 4D Graphs** ( **Stability** tab)

以下是多年来稳定性增加（常数 C <sub>2</sub>）的演变：

- 在纸笔版的 SuperMemo（1985 年）中，C <sub>2</sub> 确实（几乎）是一个常数。设置为 1.75 的平均值（由于舍入误差和简单性，在 1.5 到 2.0 之间变化），它没有考虑材料难度、记忆稳定性或可检索性等。
- 在早期的 SuperMemo for DOS（1987 年）版本中，C <sub>2</sub>（名为 E-Factor）首次反映了项目难度。回答质量糟糕时，它会降低，回答质量优秀时，它会增加。
- SuperMemo 4（1989 年）没有使用 C <sub>2</sub>，但为了计算重复间隔，它首次采用了优化矩阵。
- 在 SuperMemo 5（1990 年）中，C <sub>2</sub>（名为 O-Factor）最终被表示为一个矩阵，并且它包括了难度维度和稳定性维度。同样，矩阵的条目将受到测量-验证-校正循环的影响，该循环将从基于先前测量的初始值开始，向满足学习标准的值收敛。
- 在 SuperMemo 6（1991 年）中，C <sub>2</sub> 以 O-Factor 矩阵的形式，从包含可检索性维度的三维矩阵中得出。第三维的重要意义在于，SuperMemo 首次可以检查不同难度和记忆稳定性的遗忘曲线。
- 在 SuperMemo 8（1997 年）到 SuperMemo 16 中，C <sub>2</sub> 的表示没有太大变化，但是，用于从理论数据集到实际数据集快速稳定过渡的算法逐渐变得越来越复杂。最重要的是，新的 SuperMemos 更好地利用了 C <sub>2</sub> 的可检索性维度。因此，整个过程能独立于间隔效应，学生可以偏离初始学习标准，例如在考试前突击学习，而不会给优化过程引入干扰。
- 在 SuperMemo 17（2016 年），C <sub>2</sub> 最终采用了基于原始双因素模型的形式。它取自稳定性增加矩阵 (SInc)，该矩阵具有三个维度，代表决定稳定性增加的三个变量：复杂性（材料难度）、稳定性和可检索性。SInc 矩阵在学习过程中使用称为算法 SM-17 的复杂算法填充数据。可以在 SuperMemo 17 中使用 **工具→记忆 →4D 图表**（**稳定性**选项）检查稳定性增加矩阵。

## 1989年：SuperMemo 适应用户记忆（1989: SuperMemo adapts to user memory）

### 引入灵活的间隔函数（Introducing flexible interval function）

SuperMemo 2 was great. Its simple algorithm has survived in various mutations to this day in popular apps such as Anki or Mnemosyne. However, the algorithm was dumb in the sense that there was no way of modifying the function of optimum intervals. The findings of 1985 were set in stone. Memory complexity and stability increase were expressed by the same single number: E-factor. It is a bit like using a single lever in a bike to change gears and the direction of driving.

SuperMemo 2 非常出色。它的简单算法以各种变体形式存活至今，出现在流行的应用程序中，像是 Anki 和 Mnemosyne。然而，该算法是“愚蠢”的，因为无法修改最佳间隔函数。1985 年的研究结果被固定下来。记忆复杂性和稳定性增加由同一个数字表示：E-因子。这有点像在自行车上使用一个单一的杠杆来改变档位和行驶方向。

Individual items could adapt the spacing of review by changes to their estimated difficulty. Those changes could compensate for errors in the function of optimum intervals. Even if the algorithm was slow to converge on the optimum, in theory, it was convergent. The main flaw was that, in Algorithm SM-2, new items would not benefit from the experience of old items.

各个项目可以通过改变其难度估值来调整复习间隔。这些调整可以补偿最佳间隔函数中的误差。即使算法收敛到最优的速度很慢，理论上它至少也是收敛的。主要缺陷在于，在算法 SM-2 中，新项目不会从旧项目的经验中受益。

Algorithm SM-2 is not adaptable. New items do not benefit from the experience of old items.

算法 SM-2 不具备适应性。新项目不会从旧项目的经验中受益。

Algorithm SM-4 was the first attempt to arm SuperMemo with universal adaptability. It was completed in February 1989. In the end, adaptability was too slow to show up, but inspiration gathered with Algorithm SM-4 was essential for further progress, esp. in understanding the problem of stability-vs-accuracy in spaced repetition. In short, Algorithm SM-4 was too stable to be accurate. This was quickly remedied in Algorithm SM-5 just 7 months later. Here is an excerpt from my Master’s Thesis to explain the details:

算法 SM-4 是让 SuperMemo 具备通用适应性的首次尝试。它于 1989 年 2 月完成。最终，适应性表现得太慢以至于无法显现，但从算法 SM-4 中收集到的灵感对于进一步发展至关重要，尤其是在理解间隔重复中的稳定性与准确性问题方面。简而言之，算法 SM-4 因太稳定而无法做到准确。这个问题在 7 个月后的算法 SM-5 中很快得到了解决。以下是摘自我的硕士论文的详细说明：

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

The main fault of Algorithm SM-2 seems to have been the arbitrary shape of the function of optimal intervals. Although very effective in practice and confirmed by years of experimental repetitions, **this function could not claim scientifically proved validity**, nor could it detect the overall impact of few day variations of optimal intervals on the learning process. Bearing these flaws in mind I decided to employ routine SuperMemo repetitions in the validation of the function of optimal intervals!

算法 SM-2 的主要缺陷似乎在于最佳间隔函数的可变性。尽管在实践中非常有效并经过多年的实验重复证实，但**该函数不能声称其具有被科学证明的有效性**，也不能检测到最优间隔的几天变化对学习过程的总体影响。考虑到这些缺陷，我决定在验证最佳间隔函数时采用常规的 SuperMemo 重复。

Using optimization procedures like those applied in finding E-Factors I wanted the program to correct the initially proposed function whenever corrections appeared justified.

我使用了和查找 E-因子时类似的优化程序，希望只要修正表现的有道理，程序就能修正最初提出的函数。

To achieve this goal, I tabulated the function of optimal intervals.

为了实现这个目标，我将最佳间隔函数制成表格。

![[SuperMemo_The true history of spaced repetition_附件/Matrix_of_optimum_intervals_in_SuperMemo_5.jpg]]

> ***Figure:** Matrix of optimal intervals showed up in SuperMemo 4 in 1989 and survived to this day in SuperMemo 17 with few changes. The picture presents a matrix from SuperMemo 5 and shows a significant departure from original values of the matrix. In SuperMemo 4, adaptations proceeded at much slower pace*
> 
>***图**：最佳间隔矩阵最初于 1989 年出现在 SuperMemo 4 中，并几乎没有变化地被保留倒了现在的 SuperMemo 17 中。该图片展示了来自 SuperMemo 5 的一个矩阵，并显示了与原始矩阵值的显著偏离。在 SuperMemo 4 中，适应过程的速度要慢得多*。

Particular entries of the matrix of optimal intervals (later called the OI matrix) were initially taken from the formulas used in Algorithm SM-2.

最佳间隔矩阵（后来称为 OI 矩阵）的特定条目最初来自算法 SM-2 中使用的公式。

SuperMemo 4 (February 1989), in which the new solution was implemented, used the OI matrix to determine values of inter-repetition intervals:

I(n):=OI(n,EF)

where:

-   I(n) – the n-th inter-repetition interval of a given item (in days),
-   EF – E-Factor of the item,
-   OI(n,EF) – the entry of the OI matrix corresponding to the n-th repetition and the E-Factor EF.

采用了新解决方案的 SuperMemo 4（1989 年 2 月）使用 OI 矩阵来确定重复间隔的值：

I(n):=OI(n,EF)

其中：

- I(n) - 给定项目第 n 次重复间隔（天数）
- EF - 项目的 E-因子
- OI(n,EF) - OI 矩阵中对应第 n 次重复和数值为EF的 E-因子的条目

However, the OI matrix was not fixed once for all. In the course of repetitions, particular entries of the matrix were increased or decreased depending on the grades. For example, if the entry indicated the optimal interval to be X and the used interval was X+Y while the grade after this interval was not lower than four, then the new value of the entry would fall between X and X+Y.

然而，OI 矩阵并不是一成不变的。在重复过程中，根据回答质量得分，矩阵中相应条目的数值会增加或减少。例如，如果条目指示最佳间隔为 X，而使用的间隔为 X+Y，并且该间隔后的回答质量得分不低于 4，那么条目的新值将落在 X 和 X+Y 之间。

Thus the values of the OI entries in the equilibrium state should settle at the point where the stream of poor-retention items balances the stream of good-retention items in its influence on the matrix.As a consequence, SuperMemo 4 was intended to yield an ultimate definition of the function of optimal intervals.

因此，平衡状态下 OI 矩阵中条目的值应该稳定在保留率糟糕的项目流和保留率良好的项目流对矩阵影响平衡的点上。因此，SuperMemo 4 的目标是最终定义最佳间隔函数。

### 僵硬的 SuperMemo 4（Rigid SuperMemo 4）

It did not take me long to realize that the verification-correction cycle in the new algorithm was too long. It was not much different than running the 1985 eperiment on the computer. To determine decade-long intervals, I needed a decade to pass to test the outcomes of the review. This led to Algorithm SM-5 seven months later. Here is the problem with Algorithm SM-4 as described in my Master’s Thesis:

我没过多久就意识到，新算法中的验证-校正循环太长了。这与在计算机上运行 1985 年的实验没有什么不同。为了确定十年以上的间隔，我需要十年以上的时间来测试重复记忆的结果。这推动了七个月后的算法 SM-5 的诞生。以下是我的硕士论文中描述的算法 SM-4 的问题：

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

Algorithm SM-4 was implemented in SuperMemo 4 and was used between March 9, 1989 and October 17, 1989. Although the main concept of modifying the function of optimal intervals seemed to be a major step forward, the implementation of the algorithm was a failure. The basic insufficiency of the algorithm appeared to result from formulas applied in modification of the OI matrix.

算法 SM-4 被应用于 SuperMemo 4 中，并于 1989 年 3 月 9 日至 1989 年 10 月 17 日期间使用。尽管修改最佳间隔函数的主要概念似乎是一项巨大的进步，但该算法的实际应用却失败了。该算法的基本缺陷似乎源于修改 OI 矩阵时应用的公式。

There were two the most striking flaws:

-   modifications were too subtle to rearrange the OI matrix visibly in a reasonably short time,
-   for longer inter-repetition intervals, the effect of modification had to wait very long before being steadily fixed, i.e. it took quite a lot of time before the result of a modification of a few-month-long interval could be seen and corrected if necessary

以下是最明显的两个缺陷：

- 修改过于细微，无法在合理的时间内足够明显地重新排列 OI 矩阵。
- 对于较长的重复间隔，修正的影响需要很长时间才能稳定下来，即需要相当长的时间才能看到长度为几个月的间隔的修正结果，并在必要时进行纠正。

After seven months of using Algorithm SM-4, the OI matrices of particular databases did not look much different from their initial states. One could explain this fact by the correctness of my earlier predictions concerning the real values of the optimal inter-repetition intervals, however, as it was later proved by means of Algorithm SM-5, the actual reason of the stability of the matrices was the flaws in the optimization formulae. As far as acquisition rate and retention are concerned, there is no reliable evidence that Algorithm SM-4 brought any progress. Slight improvement could as well be related to general betterment of the software and improvement in item formulation principles

使用算法 SM-4 七个月后，特定数据库的 OI 矩阵看起来与初始状态没有太大区别。这一事实可以被解释为“我之前关于最佳重复间隔实际值的预测是正确的”，然而，正如算法 SM-5 后来证明的那样，矩阵稳定性的真正原因是优化公式中的缺陷。
在习得率和保留率方面，没有可靠的证据表明算法 SM-4 取得了任何进展。仅有的轻微改进也可能是与软件的整体改进和项目制定原则的改良有关。（*译注：这里的项目指的应该还是像不同语言词组配对那样的单词记忆项目*）

### 新版 SuperMemo 中的 SuperMemo 4 残余（Remnants of SuperMemo 4 in new SuperMemos）

Interestingly, you can still see the matrix of optimum intervals in newer versions of SuperMemo. The matrix is not used by the algorithm, however, it is displayed in SuperMemo statistics as it informs the user about the impact of complexity on the prospects of items in the learning process.

有趣的是，您仍然可以在新版本的 SuperMemo 中看到最佳间隔矩阵。该矩阵不被算法使用，但是它在 SuperMemo 统计信息中显示，因为它向用户展示了学习过程中复杂性对项目前景的影响。

If you compare a matrix produced by SuperMemo 5 in 8 months of use, you will notice significant similarity to a matrix produced in two decades of use of Algorithm SM-8:

如果您比较 SuperMemo 5 在 8 个月的使用中产生的矩阵和 SuperMemo 8 在 20 年的使用中产生的矩阵，您会注意到显着的相似性：

![[SuperMemo_The true history of spaced repetition_附件/OF_matrix_in_SuperMemo_17.jpg]]

> ***Figure:** Matrix of optimum intervals is no longer used in Algorithm SM-17. However, it can still be generated with procedures of Algorithm SM-15. The columns correspond with easiness of the material expressed as A-Factor. The rows correspond with memory stability expressed as repetition category*
> 
> _**图：**_ 最佳间隔矩阵不再用于算法 SM-17 。但是，它仍然可以使用算法 SM-15 的过程生成。矩阵的列对应于用 A-因子表示的材料的难易程度。行对应于用重复次数表示的记忆稳定性。

### SM-4 算法（Algorithm SM-4）

Here is the outline of Algorithm SM-4 as described in my Master’s Thesis:

以下是我的硕士论文中对算法 SM-4 的概述：

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

**Algorithm SM-4 used in SuperMemo 4.0**:

1.  Split the knowledge into smallest possible items
2.  With all items associate an E-Factor equal to 2.5
3.  Tabulate the OI matrix for various repetition numbers and E-Factor categories
4.  Use the following repetition spacing to obtain the initial OI matrix:
	- OI(1,EF):=1
	- OI(2,EF):=6
	- for n>2 OI(n,EF):=OI(n-1,EF)×EF where:
	    - OI(n,EF) – optimal inter-repetition interval after the n-th repetition (in days) for items with E-Factor equal EF,
5.  Use the OI matrix to determine inter-repetition intervals:
    - I(n,EF):=OI(n,EF) where:
	    - I(n,EF) – the n-th inter-repetition interval for an item whose E-Factor equals EF (in days),
	    - OI(n,EF) – the entry of the OI matrix corresponding to the n-th repetition and the E-Factor EF
6.  After each repetition estimate the quality of the repetition response in the 0-5 grade scale (see Algorithm SM-2).
7.  After each repetition modify the E-Factor of the recently repeated item according to the formula:EF’:=EF+(0.1-(5-q)×(0.08+(5-q)×0.02))where:
    - EF’ – new value of the E-Factor,
    - EF – old value of the E-Factor,
    - q – quality of the response in the 0-5 grade scale.If EF is less than 1.3 then let EF be 1.3.
8.  After each repetition modify the relevant entry of the OI matrix.
9.  An exemplary formula could look as follows (the actual formula used in SuperMemo 4 was more intricate):
	- OI’:=interval+interval×(1-1/EF)/2×(0.25×q-1)
	- OI* :=(1-fraction)×OI+fraction × OI’ where:
	    - OI* – new value of the OI entry,
	    - OI’ – auxiliary value of the OI entry used in calculations,
	    - OI – old value of the OI entry,
	    - interval – interval used before the considered repetition (i.e. the last used interval for the given item),
	    - fraction – any number between 0 and 1 (the greater it is the faster the changes of the OI matrix),
	    - EF – E-Factor of the repeated item,
	    - q – quality of the response in the 0-5 grade scale.
	    - Note that for q=4 the OI does not change and that for q=5 the OI increases 4 times less than it decreases for q=0. 
	    - Note also that the maximum change of the OI equals (I(n)-I(n-1))/2 in terms of the repetition spacing used in Algorithm SM-2 (i.e. (OI-OI/EF)/2).
10.  If the quality response was lower than 3 then start repetitions for the item from the beginning without changing the E-Factor.
11.  After each repetition session of a given day repeat again all the items that scored below four in the quality assessment. Continue the repetitions until all of these items score at least four.

SuperMemo 4.0 中所用的算法 SM-4：

1. 将知识分解为尽可能小的项目
2. 将所有项目的 E-因子 设为2.5
3. 根据不同的重复次数和 E-因子等级为 OI 矩阵制表
4. 使用以下重复间隔来获得初始 OI 矩阵：
	- OI(1,EF):=1
	- OI(2,EF):=6
	- 对于 n>2，OI(n,EF):=OI(n-1,EF)×EF
		- 其中： - OI(n,EF) - E-因子等于 EF 的项目第 n 次重复后的最佳重复间隔（天数）
5. 使用 OI 矩阵确定重复间隔：
	- I(n,EF):=OI(n,EF)其中：
		- I(n,EF) - E-因子等于 EF 的项目的第 n 次重复间隔（天数）
		- OI(n,EF) - OI 矩阵中对应第 n 次重复和 E-因子 EF 的条目
6. 在每次重复后，以 0-5 的等级评分估计重复响应的质量（参见算法 SM-2）。
7. 每次重复后，根据以下公式修改最近重复项目的 E-因子：
	- EF' := EF + (0.1 - (5-q) * (0.08 + (5-q) * 0.02))其中：
		- EF' - E-因子的新值 
		- EF - E-因子的旧值
		- q - 0-5 级评分对应的响应质量
		- 如果 EF 小于 1.3，则令 EF 为 1.3。
8. 每次重复后修改 OI 矩阵的相关条目。
9. 示例公式如下（SuperMemo 4 中使用的实际公式更复杂）：
	- OI' := interval + interval × (1-1/EF) / 2 × (0.25×q-1)
	- OI * := (1-fraction) × OI + fraction × OI'，其中：
		- OI * - OI 条目的新值
		- OI' - 计算中使用的 OI 条目的辅助值
		- OI - OI 条目的旧值
		- interval - 在考虑的重复之前使用的间隔（即给定项目的上次使用间隔）
		- fraction - 0 到 1 之间的任何数字（越大，OI 矩阵的变化越快）
		- EF - 重复项目的 E-因子
		- q - 0-5 级评分对应的响应质量
		- 注意，对于 q=4，OI 不变；对于 q=5，OI 的增加量是 q=0 时减少量的 1/4。 
		- 另请注意，OI 的最大变化等于 (I(n)-I(n-1))/2，以算法 SM-2 中使用的重复间隔表示（即 (OI-OI/EF)/2）。
10. 如果响应质量低于 3，则从头开始重复该项目，而不更改 E-因子。
11. 在给定日期的每次重复会话后，再次重复所有在质量评估中得分低于四的项目。继续重复，直到所有这些项目的得分至少为四为止。
### 间隔矩阵的问题（Problems with interval matrix）

In addition to slow convergence, Algorithm SM-4 showed that the use of matrix of intervals leads to several problems that could easily be solved by replacing intervals with O-factors. Those additional flaws led to a fast implementation of Algorithm SM-5 yet in 1989. Here is a short analysis that explained the flaws in the use of the matrix of optimum intervals:

除了收敛速度慢之外，算法 SM-4 表明使用间隔矩阵会导致几个问题，这些问题可以通过用 O-因子替换间隔来轻松解决。这些额外的缺陷促使我们在 1989 年快速实现了算法 SM-5。以下是解释使用最佳间隔矩阵的弊端的简短分析：

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

- In the course of repetition it may happen that one of the intervals will be calculated as shorter than the preceding one. This is certainly inconsistent with general assumptions leading to the SuperMemo method. Moreover, validity of such an outcome was refuted by the results of application of the Algorithm SM-5. This flaw could be prevented by disallowing intervals to increase or drop beyond certain values, but such an approach would tremendously slow down the optimization process interlinking optimal intervals by superfluous dependencies. The discussed case was indeed observed in one of the databases. The discrepancy was not eliminated by the end of the period in which the Algorithm SM-4 was used despite the fact that the intervals in question were only two weeks long
- E-Factors of particular items are constantly modified thus in the OI matrix an item can pass from one difficulty category to another. If the repetition number for that item is large enough, this will result in serious disturbances of the repetitory process of that item. Note that the higher the repetition number, the greater the difference between optimal intervals in neighboring E-Factor category columns. Thus if the E-Factor increases the optimal interval used for the item can be artificially long, while in the opposite situation the interval can be much too short

- 在重复过程中，可能会出现某个间隔计算结果比前一个间隔短的情况。这与产生 SuperMemo 方法的一般假设肯定是不一致的。此外，算法 SM-5 的应用结果也驳斥了这种结果的有效性。可以通过不允许间隔增加或下降超过特定值来防止这种缺陷，但这种方法会因过多的依赖性，极大地减慢使最佳间隔相互关联的优化过程。这里讨论的情况确实在一个数据库中被观察到。尽管所讨论的间隔只有两周长，但在使用算法 SM-4 的期间内，这种差异并未消除。
- 特定项目的 E-因子不断被修改，因此在 OI 矩阵中，项目可以从一个难度等级转移到另一个等级。如果该项目的重复次数足够大，这将导致该项目的重复过程发生严重干扰。请注意，重复次数越高，相邻 E-因子类别列中的最佳间隔差异就越大。因此，如果 E-因子增加，则用于该项目的最佳间隔可能会因人为因素变得过长，而在相反的情况下，间隔可能会太短。

The Algorithm SM-4 tried to interrelate the length of the optimal interval with the repetition number. This approach seems to be incorrect because the memory is much more likely to be sensitive to the length of the previously applied inter-repetition interval than to the number of the repetition.

算法 SM-4 试图将最佳间隔的长度与重复次数联系起来。这种方法似乎是不正确的，因为记忆对先前应用的重复间隔长度的敏感性，可能比对重复次数的敏感性要高得多。

### SuperMemo 5

The idea of the matrix of optimum intervals was born on Feb 11, 1989. On Mar 1, 1989, I started using SuperMemo 4 to learn Esperanto. Very early I noticed that the idea needs revision. The convergence of the algorithm was excruciatingly slow.

最佳间隔矩阵的想法诞生于1989年2月11日。1989年3月1日，我开始使用 SuperMemo 4学习世界语。我很快注意到这个想法需要修正。该算法的收敛速度极其缓慢。

By May 5, I had a new idea in my mind. This was, in essence, the birth of stability increase function, except, in the optimum review of SuperMemo there would be no retrievability dimension. The new algorithm would use the matrix of optimum factors. It would remember how much intervals need to increase depending on memory complexity and current memory stability. Slow convergence of Algorithm SM-4 also inspired the need to randomize intervals (May 20).

到5月5日，我心中有了新的想法。从本质上来说，这就是稳定性增加函数诞生的时刻，只是在 SuperMemo 的最佳复习方式中（最初的稳定性增加函数）尚未考虑到可检索性。新算法将使用最佳因子矩阵。它将记录根据记忆复杂性和当前记忆稳定性，间隔需要增加多少。算法 SM-4 的收敛速度缓慢也激发了随机化间隔的需求（5月20日）。

In the meantime, progress had to be delayed because of school obligations again. With Krzysztof Biedalak, we decided to write a program for developing school tests that could be used with SuperMemo. The project was again used to wriggle out from other obligations in classes with open-minded Dr Katulski who has become a supporter of all-things SuperMemo by now.

与此同时，由于学校的任务，进度不得不再次延迟。我和 Krzysztof Biedalak 决定编写一个用于开发学校测试的程序，该程序可以与 SuperMemo 一起使用。该项目再次被用来逃避具有开明思想的 Katulski 博士课堂上的其他任务，他现在已经成为所有 SuperMemo 事物的支持者。

I spent summer on practical training in the Netherlands when progress was slow due to various obligations. One of the chief reasons for slowness was extreme dieting that resulted from the need to save money to pay my PC 1512 debts. I also hoped to earn something extra to buy a hard disk for my computer. All my work was possible thanks to the courtesy of Peter Klijn of the University of Eindhoven. He just gave me his PC for my private use for the whole period of stay. He did not want my good work over SuperMemo to slow down. It was the first time I could keep all my files on a hard disk and it felt like a move from an old bike to Tesla Model S.

我在荷兰实习的夏天，由于各种义务，进展缓慢。缓慢的主要原因之一是极端的节食，这是由于需要省钱来偿还我的 PC 1512 债务。我还希望多赚点钱来为我的电脑买一块硬盘。多亏了埃因霍芬大学的 Peter Klijn 的好意，我的所有工作才得以实现。他在整个逗留期间慷慨地把他的电脑给我私人使用。他不希望我关于 SuperMemo 的良好工作放慢速度。这是我第一次可以将所有文件保存在硬盘上，感觉就像从一辆旧自行车换成了特斯拉 Model S。

Only on Oct 16, 1989, the new Algorithm SM-5 was completed and I started using SuperMemo 5. I remarked in my notes: ” *A great revolution is in the offing*“. The progress was tremendous indeed.

直到1989年10月16日，新的算法 SM-5 才完成，我开始使用 SuperMemo 5。我在笔记中写道：“_一场伟大的革命即将到来_”。进步确实巨大。

I had a couple of users of SuperMemo 2 that were ready to upgrade to SuperMemo 5. I demanded only one price: they will start with the matrix of optimum factors initialized to a specific value. This was to validate the algorithm and make sure it carries no preconceived prejudice. All preset optimization matrices would converge nicely and fast. This fact was then used to claim universal convergence and the algorithm was described as such in the first-ever publication about spaced repetition algorithms.

我有几个 SuperMemo 2 的用户准备升级到 SuperMemo 5。我只要求一个条件：他们将使用被初始化为特定值的最佳因子矩阵开始。这是为了验证算法并确保它不带有任何先入为主的偏见。所有预设的优化矩阵都很好地表现出了快速收敛。这一事实随后被用来声称算法具备普遍收敛性，并且在关于间隔重复算法的第一篇出版物中对该算法进行了这样的描述。

### SM-5 算法（Algorithm SM-5）

SuperMemo uses a simple principle: *“use, verify, and correct”*. After a repetition, a new interval is computed with the help of the OF matrix. The “relevant entry” to compute the interval depends on the repetition (category) and item difficulty. After the interval elapses, SuperMemo calls for the next repetition. The grade is used to tell SuperMemo how well the interval “performed”. If the grade is low, we have reasons to believe that the interval is too long and the OF matrix entry is too high. In such cases, we slightly reduce the OF entry. The relevant entry here is the one that was previously used in computing the interval (i.e. before the interval started). In other words, it is the entry that is (1) used to compute the interval (after n-th repetition) and then (2) used to correct the OF matrix (after the n+1 repetition).

SuperMemo 遵循一个简单的原则：“使用、验证、校正”。重复后，借助 OF 矩阵计算新的间隔。用于计算间隔的“相关条目”取决于重复次数和项目难度。间隔结束后，SuperMemo 要求进行下一次重复。响应质量用于告诉 SuperMemo 间隔“表现”如何。如果响应质量较低，我们有理由相信间隔太长，并且 OF 矩阵条目（对应的值）太高。在这种情况下，我们稍微降低 OF 条目（对应的值）。这里的相关条目是先前（即在间隔开始之前）用于计算间隔的条目。换句话说，它是（1）用于计算间隔（第 n 次重复后），然后（2）用于校正 OF 矩阵（第 n+1 次重复后）的条目。

Here is an outline of Algorithm SM-5 as presented in my Master’s Thesis:

以下是我的硕士论文中对算法 SM-5 的概述：

Archive warning: Why use literal archives?

存档警告：为什么我们应该用文字存档？

**The final formulation of the algorithm used in SuperMemo 5 is presented below (Algorithm SM-5):**

1. Split the knowledge into smallest possible items
2. With all items associate an E-Factor equal to 2.5
3. Tabulate the OF matrix for various repetition numbers and E-Factor categories. Use the following formula:
    - OF(1,EF):=4
    - for n>1 OF(n,EF):=EF, where:
	    - OF(n,EF) – optimal factor corresponding to the n-th repetition and the E-Factor EF
4. Use the OF matrix to determine inter-repetition intervals:
	- I(n,EF)=OF(n,EF)×I(n-1,EF)
	- I(1,EF)=OF(1,EF)where:
	    - I(n,EF) – the n-th inter-repetition interval for an item of a given E-Factor EF (in days)
	    - OF(n,EF) – the entry of the OF matrix corresponding to the n-th repetition and the E-Factor EF
5. After each repetition assess the quality of repetition responses in the 0-5 grade scale (cf. Algorithm SM-2)
6. After each repetition modify the E-Factor of the recently repeated item according to the formula:
	- EF’:=EF+(0.1-(5-q)×(0.08+(5-q)×0.02)), where:
	    - EF’ – new value of the E-Factor
	    - EF – old value of the E-Factor
	    - q – quality of the response in the 0-5 grade scaleIf EF is less than 1.3 then set EF to 1.3
7. After each repetition modify the relevant entry of the OF matrix. Exemplary formulas constructed arbitrarily and used in the modification could look like this:
	- OF’:=OF×(0.72+q×0.07)
	- OF*:=(1-fraction)×OF+fraction×OF’, where:
	    - OF* – new value of the OF entry
	    - OF’ – auxiliary value of the OF entry used in calculations
	    - OF – old value of the OF entry
	    - fraction – any number between 0 and 1 (the greater it is the faster the changes of the OF matrix)
	    - q – quality of the response in the 0-5 grade scaleNote that for q=4 the OF does not change. It increases for q>4 and decreases for q<4.
8. If the quality response was lower than 3 then start repetitions for the item from the beginning without changing the E-Factor
9. After each repetition session of a given day repeat again all items that scored below four in the quality assessment. Continue the repetitions until all of these items score at least four.

**以下是SuperMemo 5中使用的算法的最终表述（算法 SM-5）**：

1. 将知识分解为尽可能小的单元
2. 为所有单元分配一个初始 E 因子（容易程度因子），值为2.5
3. 为不同的重复次数和 E 因子类别构建最佳间隔因子（OF）矩阵。使用以下公式：
    - OF(1,EF) := 4
    - 对于 n > 1，OF(n,EF) := EF 其中：
        - OF(n,EF) 表示第 n 次重复和 E 因子值为 EF 时的最佳间隔因子
4. 使用OF矩阵确定两次重复之间的时间间隔：
    - I(n,EF) = OF(n,EF) × I(n-1,EF)
    - I(1,EF) = OF(1,EF) 其中：
        - I(n,EF) 表示给定 E 因子 EF 的单元的第 n 次重复间隔（单位：天）
        - OF(n,EF) 表示对应于第 n 次重复和 E 因子值为 EF 时的 OF 矩阵中的值
5. 每次重复后，对重复响应的质量进行0-5级的评估（参见算法SM-2）
6. 每次重复后，根据以下公式修改最近重复的单元的 E 因子：
    - EF' := EF + (0.1 - (5-q) × (0.08 + (5-q) × 0.02)) 其中：
        - EF' 表示 E 因子的新值
        - EF 表示 E 因子的旧值
        - q 表示0-5级评分中的响应质量，如果 EF 小于1.3，则将 EF 设置为1.3
7. 每次重复后，修改 OF 矩阵中的相关项。示例性公式（任意构建并用于修改）可能如下：
    - OF' := OF × (0.72 + q × 0.07)
    - OF* := (1 - fraction) × OF + fraction × OF' 其中：
        - OF* 表示 OF 项的新值
        - OF' 表示计算中使用的 OF 项的辅助值
        - OF 表示 OF 项的旧值
        - fraction 表示0到1之间的任意数值（数值越大，OF 矩阵的变化越快）
        - q 表示0-5级评分中的响应质量 注意：对于q=4，OF 不变。当q>4时，OF 增加；当q<4时，OF 减少。
8. 如果响应质量低于3，则从头开始重复该单元，而不改变E因子
9. 在给定日期的每次重复会话后，再次重复所有质量评估得分低于4的单元。继续重复，直到所有这些单元的得分至少为4

In accordance with the previous observations, the entries of the OF matrix were not allowed to drop below 1.2. In Algorithm SM-5, by definition, intervals cannot get shorter in subsequent repetitions. Intervals are at least 1.2 times as long as their predecessors. Changing the E-Factor category increases the next applied interval only as many times as it is required by the corresponding entry of the OF matrix.

根据之前的观察，OF 矩阵中的项不允许低于1.2。在算法 SM-5 中，根据定义，后续重复中的间隔不能缩短。后续间隔至少是前一次间隔的1.2倍。改变 E 因子数值只会增加下一次间隔，且增加的倍数不超过 OF 矩阵相应项所要求的倍数。

### 对算法SM-5的批评（Criticism of Algorithm SM-5）

Anki manual includes a passage that is surprisingly critical of Algorithm SM-5 (Apr 2018). The words are particularly surprising as Algorithm SM-5 has never been published in full (the version above is just a rough outline). Despite the fact that the words of criticism were clearly uttered in goodwill, they hint at the possibility that if Algorithm SM-2 was superior over Algorithm SM-5, perhaps it is also superior over Algorithm SM-17. If that was the case, I would have wasted the last 30 years of research and programming. To this day, Wikipedia “criticises” “SM3+”. “SM3+” is a label first used in Anki manual that has been used at dozens of sites on the web (esp. those that prefer to stick with the older algorithm for its simplicity). A comparison between Algorithm SM-2 and Algorithm SM-17 is presented here.

Anki 手册中有一段对算法 SM-5 的批评（2018年4月），令人惊讶。这些话尤其令人惊讶，是因为算法 SM-5 从未完整发表过（上面的版本只是一个粗略的概述）。尽管批评的话显然是出于善意，但它们暗示了这样一个可能性：如果算法 SM-2 优于算法 SM-5，那么它可能也优于算法 SM-17。如果真是这样，我岂不是浪费了30年时间在研究和编程上？直到今天，维基百科仍然“批评”“SM3+”。“SM3+”是Anki手册中首次使用的标签，已被网络上的数十个站点使用（尤其是那些出于其简单性而更喜欢坚持使用旧算法的站点）。本文将对算法 SM-2 和算法 SM-17 进行比较。

#### Anki 手册中的错误说法（Erroneous claim in Anki manual）

My Master’s Thesis published in excerpts in 1998 at supermemo.com included only a rough description of the Algorithm SM-5. For the sake of clarity, dozens of minor procedures were not published. Those procedures would require a lot of tinkering to ensure good convergence, stability, and accuracy. This type of tinkering requires months of learning combined with analysis. There has never been a *ready out-of-the box* version of Algorithm SM-5.

我 1998 年在 supermemo.com 上发表的硕士论文摘要中仅包含了 SM-5 算法的粗略描述。为了清晰起见，论文中省略了数十个微小的程序步骤。 这些程序需要大量调整才能确保良好的收敛性、稳定性和准确性。 这种调整需要结合分析，进行数月的学习。SM-5 从来没有一个开箱即用的算法版本。

The source code of Algorithm SM-5 has never been published or opened, and the original algorithm could only be tested by users of SuperMemo 5, in MS DOS. SuperMemo 5 became freeware in 1993. It is important to notice that random dispersal of intervals around the optimum value was essential for establishing convergence. Without the dispersal, the progression of the algorithm would be agonizingly slow. Similarly, matrix smoothing was necessary for consistent behavior independent of the richness of data collected for different levels of stability and item complexity.

SM-5 算法的源代码从未发布或公开过，原始算法只能由 MS-DOS 版的 SuperMemo 5用户测试。 SuperMemo 5在 1993 年变成了免费软件。 需要注意的是，在重复间隔的最佳值周围建立随机分布对取得收敛至关重要。如果没有这种分布，算法的进度将非常缓慢。同样，矩阵平滑对于算法的行为一致性是必要的，因为它（算法的行为一致性）需要独立于收集到的（对应不同记忆稳定性和内容复杂性的）数据的丰富度。

Multiple evaluations done in 1989, and since, have pointed to an unquestionable superiority of Algorithm SM-5 and later algorithms over Algorithm SM-2 in any metric studied. Algorithm SM-17 might actually be used to measure the efficiency of Algorithm SM-5 if we had volunteers to re-implement that ancient code for use with our universal metrics. We have done this for Algorithm SM-2 thus far for the implementation cost was insignificant. Needless to say, Algorithm SM-2 lags well behind in its predictive powers, esp. for suboptimum levels of retrievability.

1989 年以及之后的多次评估均表明，SM-5 算法及其后继算法在所有研究指标上都明显优于 SM-2 算法。 如果有志愿者重新编写出 SM-5 的代码以便我们用通用指标测试，则 SM-17 算法实际上可以用来衡量 SM-5 算法的效率。 我们已经对 SM-2 算法进行了这样的操作，因为实现成本微不足道。 不用说，SM-2 算法在预测能力方面远远落后，尤其是在次优检索水平上。

Even a basic understanding of the underlying model should make it clear that a good implementation would yield dramatic benefits. SuperMemo 5 would adapt its function of intervals to the user’s memory. SuperMemo 2 was set in stone. I am very proud that wild guesses made in 1985 and 1987 stood the test of time, but no algorithm should trust the judgment of a humble student with 2 years experience in the implementation of spaced repetition algorithms. Instead, SuperMemo 4 and all successive implementations made fewer and fewer guesses and provided better and faster adaptability. Of all those implementations, only SuperMemo 4 was slow to adapt and was replaced in 7 months by a superior implementation.

即使只对底层模型有基本的了解，也应该清楚，良好的实现方案将带来巨大的收益。 SuperMemo 5 在使其间隔功能适应用户的记忆上做出了努力。 SuperMemo 2 则是固定不变的。 我非常自豪 1985 年和 1987 年的猜测经受住了时间的考验，但任何算法都不应该轻信一个在实现间隔重复算法这件事上只有两年经验的学生的判断。 相反，SuperMemo 4 及其所有后续实现方案都减少了猜测成分，并提供了更好、更快的适应性。 在所有这些实现方案中，只有 SuperMemo 4 适应速度缓慢，并在 7 个月内就被更优的实现方案所取代。

There is no ill-will in Anki criticism but I would not be surprised if the author pushed for an implementation and speedy move to self-learning rather than spending time on tinkering with procedures that did not seem to work as he expected. In contrast, back in 1989, I knew Algorithm SM-2 was flawed, I knew Algorithm SM-5 was superior, and I would spare no time and effort in making sure the new concept was perfected to its maximum theoretical potential.

 Anki 中的批评并非出于恶意，如果作者只是急切地想要一个（关于记忆方法的）实现方案，并快速开始自学，而不是花时间修补那些似乎没有按照他预期工作的方法，我也不会感到惊讶。 但我做的恰恰相反，早在 1989 年，我就知道 SM-2 算法存在缺陷，也知道 SM-5 算法更优越，我将不遗余力地确保新概念达到其最大的理论潜力。

Excerpt from the Anki manual (April 2018):

Anki 手册的摘要（2018年4月）

Anki was originally based on the SuperMemo SM5 algorithm. However, Anki’s default behaviour of revealing the next interval before answering a card revealed some fundamental problems with the SM5 algorithm. The key difference between SM2 and later revisions of the algorithm is this:

-   SM2 uses your performance on a card to determine the next time to schedule that card
-   SM3+ use your performance on a card to determine the next time to schedule that card, and similar cards

Anki 最初是基于 SuperMemo SM5 算法的。 然而，Anki 默认的做法是在回答卡片之前显示下一个间隔，这揭示了 SM5 算法的一些根本问题。 SM2 原始算法与后续修订版之间的关键区别在于：

- SM2 根据你在卡片上的表现来安排该卡片下次出现的时间。
- SM3+ 根据你在卡片上的表现来安排该卡片以及**类似卡片**下次出现的时间。

The latter approach promises to choose more accurate intervals by factoring in not just a single card’s performance, but the performance as a group. If you are very consistent in your studies and all cards are of a very similar difficulty, this approach can work quite well. However, once inconsistencies are introduced into the equation (cards of varying difficulty, not studying at the same time every day), SM3+ is more prone to incorrect guesses at the next interval – resulting in cards being scheduled too often or too far in the future.

后一种方法通过不仅考虑单个卡片的表现，还考虑一组卡片的表现，有望选择更准确的间隔。 如果你在学习中的行为非常一致并且所有卡片的难度都非常相似，则这种方法可以很好地工作。 然而，一旦这些相同条件不再一致（卡片难度不同，每天学习时间不同），SM3+ 更容易对下一个间隔进行错误的猜测 - 这将导致卡片出现得太频繁或安排在太久之后。

Furthermore, as SM3+ dynamically adjusts the “optimum factors” table, a situation can often arise where answering “hard” on a card can result in a longer interval than answering “easy” would give. The next times are hidden from you in SuperMemo so the user is never aware of this. After evaluating the alternatives, the Anki author decided that near-optimum intervals yielded by an SM2 derivative are better than trying to obtain optimum intervals at the risk of incorrect guesses. An SM2 approach is predictable and intuitive to end users, whereas an SM3+ approach hides the details from the user and requires users to trust the system (even when the system may make mistakes in the scheduling).

此外，由于 SM3+ 动态调整“最佳因子”表，因此经常会出现回答“困难”比回答“容易”导致更长间隔的情况。 下次间隔时长在 SuperMemo 中对您隐藏，因此用户永远不会意识到这一点。 在评估了替代方案后，Anki 作者决定通过 SM2 算法得到的近似最佳间隔已经足够好，没必要冒着猜测错误风险进一步接近最佳间隔。 SM2 方法对终端用户来说是可预测且直观的，而 SM3+ 方法对用户隐藏了细节，并要求用户信任系统（即使系统可能在调度中犯错）。

Some details for anyone who cares:

-   the fact that SuperMemo 5 used past performance of all items to maximize performance on new items is an advantage, not a “problem”. Even more, that is the key to the power of adaptability
-   inconsistent grading has been a problem for all algorithms. On average, adaptability helps find out the average effect of misuse, esp. if inconsistencies are consistent (i.e. user keep committing similar offences in similar circumstances)
-   mixed difficulties are handled by SuperMemo 5 much better because while both difficulty and stability increase are coded by E-factor in SuperMemo 2, in SuperMemo 5 and later, those two properties of memory are separated
-   interval predictions have been proven superior in SuperMemo 5 and the claim “more prone to incorrect guesses” can only be explained by errors in implementation
-   lower grades could bring longer intervals if matrix smoothing is not implemented. That part of the algorithm has only been described verbally in my thesis
-   intervals and repetition dates have always been prominently displayed in SuperMemo, even in most simpler implementations (e.g. for handheld devices, smartphones, etc.). Nothing is hidden from the user. Most of all, forgetting index and burden statistics are in full view and make it possible to see if SuperMemo keeps its retention promise and at what cost to workload

对于那些关心这一问题的人，以下是一些细节：

- SuperMemo 5使用所有项目的过去表现，来最大化新项目上的表现，这是一个优势，而不是一个“问题”。 而且，这就是适应性力量的关键。
- 不一致的评分一直是所有算法都有的问题。 就平均结果而言，适应性有助于找出误用的平均影响，尤其是在前后问题相同情况下（即用户在类似情况下不断犯类似的错误）
- SuperMemo 5针对难度混淆的处理要好得多，因为在 SuperMemo 2中，难度和稳定性增加都由 E 因子编码，而在 SuperMemo 5及更高版本中，这两个记忆属性是分开的
- SuperMemo 5做出的间隔预测已被证明更优越，而“更容易猜错”的说法只能用实现方法错误来解释
- 如果未实现矩阵平滑，则较低的响应评分可能会带来更长的间隔。 算法的那部分仅在我的论文中进行了口头描述
- 间隔和重复日期始终在 SuperMemo 中显著显示，即使在大多数更简单的实现方案中也是如此（例如，用于手持设备、智能手机等）。 没有任何东西对用户隐藏。 最重要的是，遗忘指数和负担统计数据一目了然，可以查看 SuperMemo 是否兑现了其保留率承诺以及工作量成本是多少

Of all the above claims, only one might be true. SuperMemo 2 might indeed be more intuitive. This problem has plagued SuperMemo for years. Each version is more complex, and it is hard to hide some of that complexity from users. We will keep trying though.

在上述所有说法中，只有一个可能是正确的。 SuperMemo 2 确实可能更直观。 这个问题困扰了 SuperMemo 多年。 每个版本都更加复杂，而且其中的一些复杂性很难对用户隐藏。 不过，我们将继续尝试。

Our official response published at supermemopedia.com in 2011 seems pretty accurate today:

我们 2011 年在 supermemopedia.com 上发布的官方回复在今天看来仍然非常准确：

Archive warning: Why use literal archives?

下面是引用文档

It is great that Anki introduces its own innovations while still giving due credit to SuperMemo. It is true that SuperMemo’s Algorithm SM-2 works great as compared with, for example, Leitner system, or SuperMemo on paper. However, the superiority of Algorithm SM-5 over SM-2 is unquestionable. Both in practice and in theory. It is Algorithm SM-2 that has the intervals hard-wired and dependent only on item’s difficulty, which is approximated with a heuristic formula (i.e. a formula based on a guess derived from limited pre-1987 experience). It is true that you cannot “spoil” Algorithm SM-2 by feeding it with false data. It is so only because it is non-adaptable. You probably prefer your word processor with customizable fonts even though you can mess up the text by applying Wingdings.

Anki 在引入自己的创新时，仍然给予 SuperMemo 应有的肯定，这一点很棒。 事实上，与 Leitner 系统或纸质版 SuperMemo 相比，SuperMemo 的 SM-2 算法的效果确实很好。 但是，SM-5 算法相对于 SM-2 算法的优势在理论和实践上都是毋庸置疑的。 SM-2 算法得到的间隔是固定的，只取决于项目的难度，而难度则使通过启发式公式（一个 1987 年之前有限经验的猜测公式）得到的近似结果。 的确，您无法通过向 SM-2 算法输入错误数据来“破坏”它。 这仅仅是因为它不具备适应性。应用 Wingdings 字体也可能会搞乱文本，但您大概率还是更喜欢可自定义字体的文字处理软件吧？

Algorithm SM-2 simply crudely multiplies intervals by a so-called E-Factor which is a way of expressing item difficulty. In contrast, Algorithm SM-5 collects data about user’s performance and modifies the function of optimum intervals accordingly. In other words, it adapts to the student’s performance. Algorithm SM-6 goes even further and modifies the function of optimum intervals so that to achieve a desired level of knowledge retention. The superiority of those newer algorithms has been verified in more ways than one, for example, by measuring the decline in workload over time in fixed-size databases. In cases studied (small sample), the decline of workload with newer algorithms was nearly twice as fast as compared with older databases processed with Algorithm SM-2 (same type of material: English vocabulary).

SM-2 算法只是简单地将间隔乘以所谓的 E 因子，这里的 E 因子是一种项目难度的​​表示。 相比之下，SM-5 算法收集有关用户表现的数据，并相应地修改最佳间隔函数。 换句话说，它能适应学生的表现。 SM-6 算法则更进一步，修改了最佳间隔函数，以达到所需的知识保留水平。 这些新算法的优越性已通过多种方式得到验证，例如测量固定大小数据库中，工作量随时间的下降速度。 在（基于小样本的）研究案例中，与使用 SM-2 算法处理的旧数据库相比，使用新算法的数据库工作量下降速度几乎是原来的两倍（数据库中供人记忆的素材均为英语词汇）。

All SuperMemo algorithms group items into difficulty categories. Algorithm SM-2 gives each category a rigid set of intervals. Algorithm SM-5 gives each category the same set of intervals too, however, these are adapted on the basis of user’s performance, i.e. not set in stone.

所有 SuperMemo 算法都将项目按难度等级分类。 SM-2 算法为每个类别提供了一组固定的间隔。 SM-5 算法也为每个类别提供了相同的一组间隔，但是，这些间隔是根据用户的表现进行调整的，即间隔并不固定。

Consistency is indeed more important in Algorithm SM-5 than it is in Algorithm SM-2 as false data will result in “false adaptation”. However, it is always bad to give untrue/cheat grades in SuperMemo, whichever algorithm you use. With incomplete knowledge of memory, adaptability is always superior to rigid models. This is why it is still better to adapt to an imprecise average (as in Algorithm SM-5) than to base the intervals on an imprecise guess (as in Algorithm SM-2). Needless to say, the last word goes to Algorithm SM-8 and later, as it adapts to the measured average.

在 SM-5 算法中，一致性确实比在 SM-2 算法中更重要，因为错误的数据将导致“错误的适应”。 然而，无论您使用哪种算法，在 SuperMemo 中给出不真实/作弊的（响应）评分总是不好的。 在未能完全了解记忆的一切原理的情况下，适应性始终优于刚性模型。 这就是为什么让间隔适应于不精确的平均值（SM-5 算法）至少比将间隔基于不精确的猜测（SM-2 算法）更好。 更不用说，SM-8 及更高版本的算法还要更好，因为他们让间隔适应于测量得到的平均值。

#### SuperMemo 5 的评估（1989 年）（Evaluation of SuperMemo 5 (1989))

SuperMemo 5 was so obviously superior that I did not collect much data to prove my point. I made only a few comparisons for my Master’s Thesis and they left no doubt.

SuperMemo 5 的优越性如此明显，以至于我没有收集太多数据来证明我的观点。 我只在我的硕士论文中进行了一些比较，这些结论毫无疑问是对的。

Archive warning: Why use literal archives?

下面是引用文档

**3.8. Evaluation of the Algorithm SM-5**

The Algorithm SM-5 has been in use since October 17, 1989 and has surpassed all expectations in providing an efficient method of determining the desired function of optimal intervals, and in consequence, improving the acquisition rate (15,000 items learnt within 9 months). Fig. 3.5 indicates that the acquisition rate was at least twice as high as that indicated by combined application of the SM-2 and SM-4 algorithms!

SM-5 算法自 1989 年 10 月 17 日以来一直在被使用，并且在“提供一种有效的方法，来确定最佳间隔的期望函数以及因此提高获取率”方面超越了所有预期（9 个月内学习了 15,000 个项目）。 图 3.5 表明，（应用 SM-5 算法得到的记忆）获取率至少是联合应用 SM-2 和 SM-4 算法所得到的获取率的两倍！

![[SuperMemo_The true history of spaced repetition_附件/Burdern_SM2_vs_SM5.jpg]]

> ***Figure:** Changes of the work burden in databases supervised by SM-2 and SM-5 algorithms.*
> 
> ***图**：应用 SM-2 和 SM-5 算法的数据库中的工作负担变化*。

The knowledge retention increased to about 96% for 10-month-old databases. Below, some knowledge retention data in selected databases are listed to show the comparison between the SM-2 and SM-5 algorithms:

-   Date – date of the measurement,
-   Database – name of the database; ALL means all databases averaged
-   Interval – average current interval used by items in the database
-   Retention – knowledge retention in the database
-   Version – version of the algorithm applied to the database

| Date   | Database | Interval | Retention | Version             |
| ------ | -------- | -------- | --------- | ------------------- |
| Dec 88 | EVD      | 17 days  | 81%       | SM-2                |
| Dec 89 | EVG      | 19 days  | 82%       | SM-5                |
| Dec 88 | EVC      | 41 days  | 95%       | SM-2                |
| Dec 89 | EVF      | 47 days  | 95%       | SM-5                |
| Dec 88 | all      | 86 days  | 89%       | SM-2                |
| Dec 89 | all      | 190 days | 92%       | SM-2, SM-4 and SM-5 |

10 个月后的数据库的知识保留率提高到约 96%。 下面列出了所选数据库中的一些知识保留率数据，以显示 SM-2 和 SM-5 算法之间的对比：

- 日期 - 测量日期，
- 数据库 - 数据库名称； ALL 表示所有数据库的平均值
- 间隔 - 数据库中项目使用的平均当前间隔
- 知识保留率 - 数据库中的知识保留率
- 算法版本 - 应用于数据库的算法版本

| 日期     | 数据库 | 间隔   | 知识保留率 | 算法版本                |
| ------ | --- | ---- | ----- | ------------------- |
| Dec 88 | EVD | 17天  | 81%   | SM-2                |
| Dec 89 | EVG | 19天  | 82%   | SM-5                |
| Dec 88 | EVC | 41天  | 95%   | SM-2                |
| Dec 89 | EVF | 47天  | 95%   | SM-5                |
| Dec 88 | all | 86天  | 89%   | SM-2                |
| Dec 89 | all | 190天 | 92%   | SM-2, SM-4 and SM-5 |

In the process of repetition the following distribution of grades was recorded:

| Quality | Fraction |
| ------- | -------- |
| 0       | 0%       |
| 1       | 0%       |
| 2       | 11%      |
| 3       | 18%      |
| 4       | 26%      |
| 5       | 45%      |

在重复过程中，记录了以下（响应质量）等级分布：

| Quality | Fraction |
| ------- | -------- |
| 0       | 0%       |
| 1       | 0%       |
| 2       | 11%      |
| 3       | 18%      |
| 4       | 26%      |
| 5       | 45%      |

This distribution, in accordance to the assumptions underlying the Algorithm SM-5, yields the average response quality equal 4. The forgetting index equals 11% (items with quality lower than 3 are regarded as forgotten). Note, that the retention data indicate that only 4% of items in a database are not remembered. Therefore forgetting index exceeds the percentage of forgotten items 2.7 times. In a 7-month old database, it was found that 70% of items had not been forgotten even once in the course of repetitions preceding the measurement, while only 2% of items had been forgotten more than 3 times.

在使用 SM-5 算法的情况下，这个分布得出的平均反应质量为 4。遗忘指数等于 11%（响应质量低于 3 的条目视为被遗忘）。需要注意的是，保留率数据表明数据库中只有 4% 的项目没有被记住。因此，遗忘指数是被遗忘项目所占百分比的 2.7 倍。另外还发现，在一个使用了 7 个月的数据库中， 70% 的条目在测量之前的重复过程中从未被忘记过，而只有 2% 的条目被忘记了 3 次以上。
#### 新算法优越性的理论证明（Theoretic proof of superiority of newer algorithms）

Anki’s criticism of SuperMemo 5 calls for a simple proof in the light of modern spaced repetition theory. We can show that today’s model of memory can be mapped onto the models underlying both algorithms: Algorithm SM-2 and Algorithm SM-5, and the key difference between the two is the missing adaptability of the function of optimal intervals (represented in Algorithm SM-5 as Matrix OF).

Anki 对 SuperMemo 5 的批评要求（我们）根据现代间隔重复理论提供（关于SM-5 算法的优越性的）简单证明。 我们可以证明，今天的记忆模型可以映射到 SM-2 算法和 SM-5 算法的基础模型上，两者之间的关键区别在于最佳间隔函数的适应性缺失（在 SM-5 算法中表示为矩阵 OF）。

Let SInc=f(C,S,R) be a stability increase function that takes complexity C, stability S, and retrievability R as arguments. This function determines the progressive increase in review intervals in optimum learning.

令 SInc=f(C,S,R) 为稳定性增加函数，该函数以复杂度 C、稳定性 S 和可检索性 R 作为参数。 该函数决定了复习间隔在最佳学习中的渐进增加量。

Both Algorithms, SM-2 and SM-5 ignore the retrievability dimension. In theory, if both algorithms worked perfectly, we could assume they aim at R=0.9. As it can be measured in SuperMemo, both algorithms fail at that effort for they do not know relevant forgetting curves. They simply do not collect forgetting curve data. This function was introduced only in Algorithm SM-6 in 1991.

SM-2 和 SM-5 两种算法都忽略了可检索性维度。 理论上，如果两种算法都能完美运行，我们可以将它们的目标暂时设为 R=0.9。 但正如在 SuperMemo 中可以发现的那样，由于它们不知道相关的遗忘曲线，因此这两种算法都无法达到这一目标。 它们甚至根本不收集遗忘曲线数据。 该功能仅在 1991 年的 SM-6 算法中引入。

However, if we assume that 1985 and 1987 heuristics were perfect guesses, in theory, the algorithm could use SInc=F(C,S) with constant R of 90%.

然而，如果我们假设 1985 年和 1987 年受到的启发是完美正确的猜测，那么理论上，该算法可以使用 SInc=F(C,S) 且 R 为 90% 的常数。

Due to the fact that SM-2 uses the same number, EF for stability increase and for item complexity, for SM-2 we have SInc=f(C,S) equation represented by EF=f'(EF,interval), where it can be shown easily with data that f<>f’. Amazingly, the heuristic used in SM-2 made this function work by decoupling the actual link between the EF and item complexity. As data shows that SInc keeps decreasing with S, this means that in Algorithm SM-2, by definition, all items would need to gain on complexity with each review if EF was to represent item complexity. In practical terms, Algorithm SM-2 uses EF=f'(EF,interval), which translates to SInc(n)=f(SInc(n-1),interval).

由于 SM-2 算法使用数字 EF 来同时表示稳定性增加幅度和项目复杂度，因此对于 SM-2 算法，我们可以将 SInc=f(C,S) 方程表示为 EF=f'(EF,interval)，其中可以通过数据轻松地证明 f<>f'。 令人惊讶的是，促使 SM-2 算法诞生的启发过程，通过解耦 EF 和项目复杂度之间的实际联系使该函数起作用。 由于数据显示 SInc 随着 S 的增加而不断减小，这意味着在 SM-2 算法中，根据定义，如果 EF 要代表项目复杂度，则所有项目都需要在每次复习时增加复杂度。 在实践中，SM-2 算法使用 EF=f'(EF,interval)，这转化为 SInc(n)=f(SInc(n-1),interval)。

*译注：这一段需要一些解释，让我们先回想一下 Piotr Wozniak 教授在间隔重复实验的最早期（1985年）通过实践得到了什么结论？我来重复一下：除去最开始的两次重复，后续的最佳重复间隔（使保留率维持在90%的间隔）以固定比例增长，最佳重复间隔的增长比例就是钱文忠的“Slnc”，在教授年轻时研究得到的结论中，这个值是固定的，且仅与记忆内容的复杂度（即“C (complexity)” ，早期结论中被表示为难易度“EF(easiness factor)”）有关，没有考虑稳定性（即“S”，体现为最佳重复间隔的时长）的影响，然而事实是怎样的呢？对记忆者来说，实际上重复间隔的增长幅度是（Slnc）和记忆稳定性（S）成负相关的，同时和记忆内容的复杂度（C）成正相关，同时，随着重复记忆，对个人来说相同材料的复杂度（C）会下降，这也很好理解，我们生活中能很直观地感受到复习以前学过的内容总比从头开始学新东西容易，教授年轻时一开始忽视了稳定性（S）和增长幅度（Slnc）之间的相关性，而结果中记忆稳定性（S）的增加和复杂度（C）的下降形成了对冲，导致增长幅度（Slnc）的值在第二次以后的重复中相对稳定，进而导致了增长幅度（Slnc）至于复杂度（C）有关的初步结论。（这个结论确实和实验结果一致，但是片面了，忽视了记忆稳定性（S）的影响和复杂度（C）的下降，这两个被忽视的因素在一起形成了完美对冲，以至于在实践测试中没能显现）*

Let us assume that the EF=f(EF,interval) heuristic was an excellent guess as claimed by users of Algorithm SM-2. Let SInc be represented by O-factor in Algorithm SM-5. We might then represent SInc=f(C,S) as OF=f(EF,interval).

让我们假设 EF=f(EF,interval) 如 SM-2 算法的用户所声称的那样是一个很好的猜测。 让我们用 O 因子在 SM-5 算法中表示 SInc。 然后我们可以将 SInc=f(C,S) 表示为 OF=f(EF,interval)。

For Algorithm SM-2, OF would be constant and equal to EF, in Algorithm SM-5, OF is adaptable and can be modified depending on algorithm’s performance. It seems pretty obvious that penalizing the algorithm for bad performance by a drop to OF matrix entries and rewarding it by an increase in OF entries is superior to keeping OF constant.

在 SM-2 算法中，OF 将保持不变并等于 EF，而在 SM-5 算法中，OF 是可适应的，可以根据算法的实际表现进行修改。以响应质量为依据，增加或降低 OF 矩阵中相应的值，要优于保持 OF 不变始终不变，这一事实看起来相当明显。

On a funny twist, as much as supporters of Algorithm SM-2 claim it performs great, supporters of neural network SuperMemo kept accusing algebraic algorithms of: lack of adaptability. In reality, the adaptability of Algorithm SM-17 is best to-date as it is based on the most accurate model of memory.

有趣的是，尽管 SM-2 算法的支持者声称其表现出色，但神经网络 SuperMemo 的支持者一直指责代数算法缺乏适应性。 实际上，SM-17 算法的适应性是迄今为止最好的，因为它基于最准确的记忆模型。

It is conceivable that heuristics used in SM-2 were so accurate that the original guess on OF=f(EF,interval) needed no modification. However, as it has been shown in practical application, the matrix OF quickly evolves and converges onto values described in Wozniak, Gorzelańczyk 1994. They differ substantively from the assumption wired into Algorithm SM-2.

可以想象，作为 SM-2 基础的启发非常准确，因此不需要修改 OF=f(EF,interval) 的原始猜测。 然而，正如实际应用所示，矩阵 OF 迅速演变并收敛到 Wozniak, Gorzelańczyk 1994 年描述的值。 它们与内置于 SM-2 算法中的假设大不相同。

**Summary:**

-   today: SInc=f(C,S,R), 3 variables, f is adaptable
-   sm5: SInc=f(C,S,0.9), 2 variables, f is adaptable
-   sm2: SInc=f(SInc,S,0.9) – 1 variable, f is fixed

**摘要**：

- 今天：SInc=f(C,S,R)，3个变量，函数本身具备适应性
	- （即，最新算法中，记忆增长幅度（SInc）受材料复杂度（C），记忆稳定性（S）和记忆可检索性（R）影响，关系函数可以根据实践调整）
- sm5：SInc=f(C,S,0.9)，2个变量，函数本身具备适应性
	- （即，sm5 算法中，记忆增长幅度（SInc）受材料复杂度（C），记忆稳定性（S）影响，默认目标记忆可检索性（R）为0.9，关系函数可以根据实践调整）
- sm2：SInc=f(SInc,S,0.9)，1个变量，函数本身是固定的（不具备适应性）
	- （即，sm2 算法中，记忆增长幅度（SInc）与材料复杂度（C）一致，均用 Slnc 表示，受记忆稳定性（S）影响，默认目标记忆可检索性（R）为0.9，关系函数保持不变）

### 收敛性（Convergence）

Algorithm SM-5 showed fast convergence, which was quickly demonstrated by users who began with univalent OF matrices. It was quite a contrast with Algorithm SM-4.

SM-5 算法表现出快速的收敛性，这很快就被从单值 OF 矩阵开始的用户使用测试所证明。 这与 SM-4 算法形成了鲜明对比。

Archive warning: Why use literal archives?

下面是引用文档

**3.6. 优化最佳因子矩阵的预设值（3.6. Improving the predetermined matrix of optimal factors）**

The optimization procedures applied in transformations of the OF matrix appeared to be satisfactorily efficient resulting in fast convergence of the OF entries to their final values.

OF 矩阵的优化程序似乎具有令人满意的效率，能使 OF 数值快速收敛到其最终值。

However, in the period considered (Oct 17, 1989 – May 23, 1990) only those optimal factors which were characterized by short modification-verification cycles (less than 3-4 months) seem to have reached their equilibrial values.

然而，在实验期间内（1989 年 10 月 17 日 - 1990 年 5 月 23 日），只有那些修改-验证周期较短（不到 3-4 个月）的最佳因子似乎已经达到平衡值。

It will take few further years before more sound conclusions can be drawn regarding the ultimate shape of the OF matrix. The most interesting fact apparent after analyzing 7-month-old OF matrices is that the first inter-repetition interval should be as long as 5 days for E-Factor equal 2.5 and even 8 days for E-Factor equal 1.3! For the second interval the corresponding values were about 3 and 2 weeks respectively.

有关 OF 矩阵最终形式的更可靠的结论，还需要再多等几年才能得出。 分析7个月大的 OF 矩阵后发现的最有趣的事实是，对于 E 因子等于2.5的内容，第一次重复间隔应长达5天，而对于 E 因子等于1.3的内容，甚至应长达8天！ 而第二次重复间隔对应的值，则分别约为3周和2周。

The newly-obtained function of optimal intervals could be formulated as follows:

I(1)=8-(EF-1.3)/(2.5-1.3)×3

I(2)=13+(EF-1.3)/(2.5-1.3)×8

for i>2 I(i)=I(i-1)×(EF-0.1)

where:

-   I(i) – interval after the i-th repetition (in days)
-   EF – E-Factor of the considered item.

新获得的最佳间隔函数可以表述如下：

I(1)=8-(EF-1.3)/(2.5-1.3)×3

I(2)=13+(EF-1.3)/(2.5-1.3)×8

对于 i>2，I(i)=I(i-1)×(EF-0.1)

其中：

- I(i) - 第 i 次重复后的间隔（以天为单位）
- EF - 所考虑项目的 E 因子。

To accelerate the optimization process, this new function should be used to determine the initial state of the OF matrix (Step 3 of the SM-5 algorithm). Except for the first interval, this new function does not differ significantly from the one employed in Algorithms SM-0 through SM-5. One could attribute this fact to inefficiencies of the optimization procedures which, after all, are prejudiced by the fact of applying a predetermined OF matrix. To make sure that it is not the fact, I asked three of my colleagues to use experimental versions of the SuperMemo 5.3 in which univalent OF matrices were used (all entries equal to 1.5 in two experiments and 2.0 in the remaining experiment). Although the experimental databases have been in use for only 2-4 months, the OF matrices seem to slowly converge to the form obtained with the use of the predetermined OF matrix. However, the predetermined OF matrices inherit the artificial correlation between E-Factors and the values of OF entries in the relevant E-Factor category (i.e. for n>3 the value OF(n,EF) is close to EF). This phenomenon does not appear in univalent matrices which tend to adjust the OF matrices more closely to requirements posed by such arbitrarily chosen elements of the algorithm as initial value of E-Factors (always 2.5), function modifying E-Factors after repetitions etc.

为了加速优化过程，应使用此新函数来确定 OF 矩阵的初始状态（SM-5 算法的第 3 步）。 除了第一个间隔之外，此新函数得到的间隔结果与从 SM-0 到 SM-5 这些算法得出的结果没有显著差异。 可以将这一事实归因于优化程序的低效率（译注：即，因为优化效率太低，向着最优值收敛的趋势还没来得及显现，所以结果看起来和原来一样），毕竟这些程序事实上会受到其中应用的 OF 矩阵的初始值的影响。 为了确保这（优化程序的低效率）不是（新函数的结果与 SM5 以及更早的算法的结果没有显著差异的）真正的原因，我要求三位同事使用 SuperMemo 5.3 的实验版本，其中使用了单值 OF 矩阵（所有项目在两个实验中都等于1.5，在其余实验中都等于2.0）。实验数据库仅使用了2-4个月后，OF 矩阵就表现出了“缓慢地敛到与使用 OF 预测矩阵获得的结果一致”的趋势。 然而，有预设值的 OF 矩阵会继承 E 因子与“相应 E 因子取值下的 OF 项目”之间的人为相关性（即对于 n>3，OF(n,EF) 的值接近预设的 EF），这种现象不会出现在单值矩阵中。单值矩阵倾向于更密切地调整 OF 矩阵，以满足算法中任意选择的元素提出的要求，例如 E 因子的初始值（始终为 2.5）、重复后修改 E 因子的函数等。

### 矩阵平滑（Matrix smoothing）

Some of the criticism from the author of Anki might have been a result of not employing matrix smoothing that was an important component of the algorithm and is still used in Algorithm SM-17.

Anki 作者的一些批评可能源于（他们使用 Supermemo 算法时）没有采用矩阵平滑技术，而矩阵平滑是该算法的重要组成部分，并且仍然在 SM-17 算法中使用。

Archive warning: Why use literal archives?

下面是引用文档

**3.7. 优化因子矩阵中变化的传播（Propagation of changes across the matrix of optimal factors）**

Having noticed the earlier mentioned regularities in relationships between entries of the OF matrix I decided to accelerate the optimization process by propagation of modifications across the matrix. If an optimal factor increases or decreases then we could conclude that the OF factor that corresponds to the higher repetition number should also increase.

注意到 OF 矩阵的项目之间存在上述规律后，我决定通过使修改能够在矩阵中向周围项传播，来加速优化过程。如果一个优化因子增加或减少，则可以得出结论，对应于更高重复次数的优化因子也应该增加。

This follows from the relationship OF(i,EF)=OF(i+1,EF), which is roughly valid for all E-Factors and i>2. Similarly, we can consider desirable changes of factors if we remember that for i>2 we have OF(i,EF’)=OF(i,EF*)×EF’/EF* (esp. if EF’ and EF* are close enough). I used the propagation of changes only across the OF matrix that had not yet been modified by repetition feed-back. This proved particularly successful in case of univalent OF matrices applied in the experimental versions of SuperMemo mentioned in the previous paragraph.*

这是从以下关系进一步得出的：OF(i,EF)=OF(i+1,EF)，该关系对于 i>2 时所有 E-因子取值的情况都粗略有效。类似地，如果我们记住对于 i>2，我们有 OF(i,EF’)=OF(i,EF*)×EF’/EF*（尤其当 EF’ 和 EF* 足够接近时），我们就可以考虑因子的期望变化。我只在尚未被重复反馈修改的 OF 矩阵中传播变化。这在上述段落中提到在实验版本的 SuperMemo 中应用单值 OF 矩阵的实验下，被证明尤其成功。

The proposed propagation scheme can be summarized as this:

1.  After executing Step 7 of the Algorithm SM-5 locate all neighboring entries of the OF matrix that has not yet been modified in the course of repetitions, i.e. entries that did not enter the modification-verification cycle. Neighboring entries are understood here as those that correspond to the repetition number +/- 1 and the E-Factor category +/- 1 (i.e. E-Factor +/- 0.1)
2.  Modify the neighboring entries whenever one of the following relations does not hold:
    -   for i>2 OF(i,EF)=OF(i+1,EF) for all EFs
    -   for i>2 OF(i,EF’)=OF(i,EF*)×EF’/EF*
    -   for i=1 OF(i,EF’)=OF(i,EF*)×The selected relation should hold as the result of the modification
3.  For all the entries modified in Step 2 repeat the whole procedure locating their yet unmodified neighbors.

我所提出的变化传播方案可以总结如下：

1. 执行算法 SM-5 的第 7 步后，定位所有尚未在重复过程中修改的 OF 矩阵中的相邻项，（即未进入修改验证循环的条目）。这里的相邻项是指对应于重复次数 +/- 1 和 E-因子等级 +/- 1（即 E-因子取值 +/- 0.1）的项。
2. 每当以下关系之一不成立时，修改相邻条目：
    - 对于 i>2，OF(i,EF)=OF(i+1,EF) 适用于所有 EF。
    - 对于 i>2，OF(i,EF’)=OF(i,EF*)×EF’/EF*。
    - 对于 i=1，OF(i,EF’)=OF(i,EF*)×修改的结果应使所选关系成立。
3. 对于在步骤 2 中修改的所有条目，重复整个过程，定位其尚未修改的相邻项。

Propagation of changes seems to be inevitable if one remembers that the function of optimal intervals depends on such parameters as:

-   student’s capacity
-   student’s self-assessment habits (the response quality is given according to the student’s subjective opinion)
-   character of the memorized knowledge etc.

如果我们记得最佳间隔函数取决于以下参数，就会发现变化的传播似乎是不可避免的：

- 学生的能力
- 学生的自评习惯（根据学生的主观判断给出的响应质量）
- 被记忆的知识的特征等

Therefore it is impossible to provide an ideal, predetermined OF matrix that would dispense with the use of the modification-verification process and, to a lesser degree, propagation schemes.

因此，不可能提供一个理想的、预设值都已确定的 OF 矩阵，从而无需使用修改验证过程，或者无需使用变化传播方案。

### 间隔的随机分散（Random dispersal of intervals）

One of the key improvements in Algorithm SM-5 was random dispersal of intervals. On one hand, it dramatically accelerated the optimization process, on the other, it caused a great deal of confusion in users of nearly all future versions of SuperMemo: “why do the same items with the same grade use a different interval at each try?”. Minor deviations are precious. This was laid bare when “naked” Algorithm SM-17 was released in early SuperMemo 17. It could be seen that users who keep a lot of leeches in their collections would easily hit “local minima” from which they could never get out. The random dispersion was restored with some delay. The period of “nakedness” was needed for accurate observations of the algorithm, esp. in multi-decade learning process like my own.

SM-5 算法的一项关键改进是间隔的随机分散。一方面，它极大地加速了优化过程，另一方面，它在几乎所有未来版本的 SuperMemo 的用户中引起了极大的困惑：“为什么具有相同等级的相同项目在每次尝试时使用不同的间隔？”微小的差异是宝贵的。当“裸露的” SM-17 算法在早期 SuperMemo 17 中发布时，这一点就变得非常明显。可以看出，在收藏夹中保存大量“寄生虫”的用户很容易陷入“局部最小值”，而无法从中摆脱。随机分散经过一段时间后得以恢复。“裸露”期对于准确观察算法是必要的，尤其是在像我自己的这种长达数十年的学习过程中。

Archive warning: Why use literal archives?

下面是引用文档

**3.5. 最佳间隔的随机分散（Random dispersal of optimal intervals）**

To improve the optimization process further, a mechanism was introduced that may seem to contradict the principle of optimal repetition spacing. Let us reconsider a significant fault of the Algorithm SM-5: A modification of an optimal factor can be verified for its correctness only after the following conditions are met:

-   the modified factor is used in calculation of an inter-repetition interval
-   the calculated interval elapses and a repetition is done yielding the response quality which possibly indicates the need to increase or decrease the optimal factor

为了进一步改进优化过程，我们引入了一种似乎与最佳重复间隔相矛盾的机制。让我们重新考虑算法 SM-5 的一个重大缺陷：只有在满足以下条件后，才能验证对优化因子的修改的正确性：

- 修改后的因子用于计算两次重复之间的间隔
- 计算的间隔过去，并进行了重复，产生了可能表明需要增加或减少优化因子的响应质量

This means that even a great number of instances used in modification of an optimal factor will not change it significantly until the newly calculated value is used in determination of new intervals and verified after their elapse.

这意味着，即使在修改优化因子已经时使用了大量实例，在使用新计算的值来确定新间隔，并在间隔过去后进行验证之前，它也不会发生显着变化。

The process of verification of modified optimal factors after the period necessary to apply them in repetitions will later be called the modification-verification cycle. The greater the repetition number the longer the modification-verification cycle and the greater the slow-down in the optimization process.

修改后的优化因子在应用于重复所需时间之后进行验证的过程，稍后将称为修改验证循环。重复次数越大，修改验证循环越长，优化过程的减速就越大。

To illustrate the problem of modification constraint let us consider calculations from Fig. 3.4.

为了说明修改约束的问题，让我们考虑图 3.4 中的计算。

One can easily conclude that for the variable INTERVAL_USED greater than 20 the value of MOD5 will be equal 1.05 if the QUALITY equals 5. As the QUALITY=5, the MODIFIER will equal MOD5, i.e. 1.05. Hence the newly proposed value of the optimal factor (NEW_OF) can only be 5% greater than the previous one (NEW_OF:=USED_OF×MODIFIER). Therefore the modified optimal factor will never reach beyond the 5% limit unless the USED_OF increases, which is equivalent to applying the modified optimal factor in calculation of inter-repetition intervals.

可以很容易地得出结论，对于大于 20 的变量 INTERVAL_USED，如果 QUALITY 等于 5，则 MOD5 的值将等于 1.05。由于 QUALITY=5，MODIFIER 将等于 MOD5，即 1.05。因此，新提出的最佳因子值 (NEW_OF) 只能比前一个值 (NEW_OF:=USED_OF×MODIFIER) 大 5%。因此，除非 USED_OF 增加，否则修改后的最佳因子将永远不会超过 5% 的限制，这相当于在计算两次重复之间的间隔内应用修改后的最佳因子。

Bearing these facts in mind I decided to let inter-repetition intervals differ from the optimal ones in certain cases to circumvent the constraint imposed by a modification-verification cycle.

考虑到这些事实，我决定在某些情况下让两次重复之间的间隔与最佳间隔不同，以规避修改验证循环施加的约束。

I will call the process of random modification of optimal intervals dispersal.

我将随机修改最佳间隔的过程称为分散。

If a little fraction of intervals is allowed to be shorter or longer than it should follow from the OF matrix then these deviant intervals can accelerate the changes of optimal factors by letting them drop or increase beyond the limits of the mechanism presented in Fig. 3.4. In other words, when the value of an optimal factor is much different from the desired one then its accidental change caused by deviant intervals shall not be leveled by the stream of standard repetitions because the response qualities will rather promote the change than act against it.

如果允许一小部分间隔，比它本该遵循的根据 OF 矩阵指示的间隔更短或更长，那么这些偏差间隔可以通过让它们超出图 3.4 中所示机制的限制而加速最佳因子的优化。换句话说，当最佳因子的值与期望值相差很大时，由间隔随机分布引起的偶然变化将不会被标准的重复过程所抵消，因为响应质量将促进变化而不是反抗变化。

Another advantage of using intervals distributed round the optimal ones is elimination of a problem which often was a matter of complaints voiced by SuperMemo users – the lumpiness of repetition schedule. By the lumpiness of repetition schedule I mean accumulation of repetitory work in certain days while neighboring days remain relatively unburdened. This is caused by the fact that students often memorize a great number of items in a single session and these items tend to stick together in the following months being separated only on the base of their E-Factors.

使用随机分散的间隔的另一个优点是消除了一个问题，这个问题也是 SuperMemo 用户经常抱怨的问题——重复计划的粘连。所谓重复计划的粘连，是指在某些日子里积累了大量的重复工作，而邻近的日子则相对轻松。这是因为学生经常在一次会话中记忆大量项目，而如果只能根据它们的 E-因子进行分离，这些项目往往在接下来的几个月里都将粘在一起。

Dispersal of intervals round the optimal ones eliminates the problem of lumpiness. Let us now consider formulas that were applied by the latest SuperMemo software in dispersal of intervals in proximity of the optimal value. Inter-repetition intervals that are slightly different from those which are considered optimal (according to the OF matrix) will be called near-optimal intervals. The near-optimal intervals will be calculated according to the following formula:

NOI=PI+(OI-PI)×(1+m)

where:

-   NOI – near-optimal interval
-   PI – previous interval used
-   OI – optimal interval calculated from the OF matrix (cf. Algorithm SM-5)
-   m – a number belonging to the range <-0.5,0.5> (see below)

or using the OF value:

NOI=PI*(1+(OF-1)×(1+m))

The modifier m will determine the degree of deviation from the optimal interval (maximum deviation for m=-0.5 or m=0.5 values and no deviation at all for m=0).

随机分散的间隔消除了重复计划粘连的问题。现在让我们考虑最新 SuperMemo 软件在最佳值附近分散间隔时应用的公式。与 OF 矩阵中的最佳间隔略有不同的间隔将被称为近似最佳间隔。近似最佳间隔将根据以下公式计算：

NOI=PI+(OI-PI)×(1+m)

其中：

- NOI – 近似最佳间隔
- PI – 上次使用的间隔
- OI – 根据 OF 矩阵计算的最佳间隔（参见算法 SM-5）
- m – 属于范围 <-0.5,0.5> 的数字（见下文）

或者使用 OF 值：

NOI=PI*(1+(OF-1)×(1+m))

数值 m 将决定与最佳间隔的偏差程度（m=-0.5 或 m=0.5 时，与最佳间隔的偏差值最大， m=0 时则根本没有偏差）。

In order to find a compromise between accelerated optimization and elimination of lumpiness on one hand (both require strongly dispersed repetition spacing) and the high retention on the other (strict application of optimal intervals required) the modifier m should have a near-zero value in most cases.

为了在加速优化并消除粘连（两者都需要强烈分散的重复间隔），与保证高保留率（需要严格应用最佳间隔）之间找到折衷方案，修饰符 m 在大多数情况下应该具有接近零的值。

The following formulas were used to determine the distribution function of the modifier m:

-   the probability of choosing a modifier in the range <0,0.5> should equal 0.5: integral from 0 to 0.5 of f(x)dx=0.5
-   the probability of choosing a modifier m=0 was assumed to be hundred times greater than the probability of choosing m=0.5:f(0)/f(0.5)=100
-   the probability density function was assumed to have a negative exponential form with parameters a and b to be found on the base of the two previous equations:f=a×exp(-b×x)

为了确定 m 的分布函数，采用了以下公式：

- m 取值范围在 <0,0.5> 内的概率应等于 0.5，即从 0 到 0.5 的积分 f(x)dx=0.5
- 假设选择 m=0 的概率是选择 m=0.5 的概率的 100 倍：f(0)/f(0.5)=100
- 假设概率密度函数具有负指数形式，参数 a 和 b 根据前两个方程确定：f=a×exp(-b×x)

The above formulas yield values a=0.04652 and b=0.09210 for m expressed in percent.

由上述公式得出，m 表示百分比的情况下，a=0.04652，b=0.09210。

From the distribution function

> integral from -m to m of a×exp(-b×abs(x))dx = P (P denotes probability)

we can obtain the value of the modifier m (for m>=0):

> m=-ln(1-b/a×P)/b

根据给定分布函数：

>分布函数从 -m 到 m 的积分：a×exp(-b×abs(x))dx = P （P 表示概率）

P 值已知的情况下，我们可以根据 P 得到 m 的值（对于 m>=0）：

> m=-ln(1-b/a×P)/b

Thus the final procedure to calculate the near-optimal interval looks like this:

a:=0.047;
b:=0.092;
p:=random-0.5;
m:=-1/b×ln(1-b/a×abs(p));
m:=m×sgn(p);
NOI:=PI×(1+(OF-1)×(100+m)/100);

where:
-   random – function yielding values from the range <0,1) with a uniform distribution of probability
-   NOI – near-optimal interval
-   PI – previously used interval
-   OF – pertinent entry of the OF matrix

因此，计算近似最佳间隔的最终过程如下：

a:=0.047;
b:=0.092;
p:=random-0.5;
m:=-1/b×ln(1-b/a×abs(p));
m:=m×sgn(p); 
NOI:=PI×(1+(OF-1)×(100+m)/100);

其中：
- random – 生成范围在 <0,1) 内且概率分布均匀的值的函数
- NOI – 近似最佳间隔
- PI – 上次使用的间隔
- OF – OF 矩阵的相关条目

## 1990年：记忆的普适公式（1990: Universal formula for memory）

### 最优复习 vs. 间歇性复习（Optimum review vs. intermittent review）

By 1990, I had no doubt. I had a major discovery at hands. I cracked the problem of forgetting. I knew the optimum timing of review for simple memories. Once I secured the permission to describe my findings in my Master’s Thesis, my appetite for discovery kept growing. I hoped I might find a universal formula for long-term memory. A formula that would help me track the behavior of memory for any pattern of exposure or retrieval.

到 1990 年，我毫不怀疑。我手上有一个重大发现。我破解了遗忘问题。也知道了简单记忆的最佳复习时间。但在我获得了许可，在硕士论文中描述我的发现后，我对探索的渴望依然不断增长。我希望我能找到长期记忆的普适公式。一个可以帮助我跟踪任何记忆行为的公式，不论他们遵循什么样的记忆曝光模式，或者记忆检索模式。

I already had a collection of data that might help me find the formula. Before discovering the optimum spacing of repetitions in 1985, I used pages of questions for review of knowledge. The review was chaotic and determined by the availability of time, the need, or the mood. I called that ”*intermittent learning*“. I had recall data for individual pages and for each review. That was the ideal kind of data that did not have the periodicity of SuperMemo. The exact kind of data needed to solve the problem of memory. However, I had that data on paper only.

我已经收集到了一些可能有助于我找到该公式的数据。在 1985 年发现最佳重复间隔之前，我使用了一页页纸记录问题来复习知识。复习安排是混乱的，由可支配时间、眼前的需要或心情决定。我称之为“_间歇性学习_”。我保留了每个页面每次复习的回忆数据。这是理想的数据类型，没有 SuperMemo 的周期性。正是解决记忆问题所需的确切数据类型。然而，我只有纸质数据。

In Spring 1990, I recruited my sister to do the typing. No. I do not have a younger sister who would do that eagerly. My sister was 17 years my senior. Being a bit inconsiderate for her time, I used her love to make her do the donkey work. I feel guilty about it. She died just two years later. I never had a chance to repay her contribution to the theory of spaced repetition, which she never even had a chance to understand. Starting on May 1, 1990, she used my time away from the computer to transfer the data from paper to the computer. It took her many days of slow typing. It was worth it.

1990年春天，我招募了我的姐姐来打字。我姐姐比我大17岁。这对她来说有点不体贴，她并非因年轻而对此事有热情，只是我利用她对我的爱让她做苦工。我对此感到内疚。她两年后就去世了。我从未有机会报答她对间隔重复理论的贡献，她甚至连理解自己贡献的机会都没有。从1990年5月1日开始，她利用我远离计算机的时间将数据从纸张转移到计算机上。她花了许多天的时间慢慢打字。这一切都是值得的。

### 间歇学习模型（Model of intermittent learning）

Throughout the summer of 1990, instead of focusing on my Master’s Thesis, I worked on the ” *model of intermittent learning*“. It was not unusual for me to work for 10 hours straight, or go to sleep at 7 am empty-handed, or leave the computer churning the numbers overnight.

整个 1990 年夏天，我没有专注于我的硕士论文，而是把精力放在了研究“*间歇性学习模型*”上。对那时的我来说，连续工作 10 个小时，或凌晨 7 点空手睡觉，或让计算机通宵运转，都是家常便饭。

Persistence and tinkering pay. Only teens can afford it and should be given the space and the freedom. Despite being 28 years old, I was being tolerated at home pretty well. Like an immature teen. I lived at my sister’s apartment where I could leech on her kindness. Long hours at the computer were excused as ” *working on my Master’s Thesis*“. The truth was nobody asked me to do it, nobody demanded it, it did not even push SuperMemo much ahead. It was a sheer case of scientific curiosity. I just wanted to know how memory works.

坚持和改善是有回报的。只有青少年才能负担得起，应该给予他们空间和自由。尽管已经 28 岁了，但我依然相当受家里的包容。像个不成熟的青少年一样。我住在姐姐的公寓里，可以依赖她的善良。“*忙于硕士论文的工作*”是我长时间赖在电脑前的借口。事实是没有人告诉我这样做，没有人要求我这样做，它甚至没有推动 SuperMemo 发展太多。这纯粹是出于科学的好奇心。我只是想知道记忆是如何工作的。

I had dozens of pages of questions and their repetition history. I tried to predict “memory lapses per page”. I used root-mean-square deviation for lapse prediction (denoted below as Dev). By Jul 10, 1990, Tuesday, I reached Dev<3 and felt like the problem was almost “solved.” On Jul 12, 1990, I improved to Dev=2.877 (incidentally, my Thesis speaks of 2.887241). However, by Aug 27, 1990, I declared the problem unsolvable. My notes from that day say:

我有了很多记载着问题的纸页以及对应的重复历史记录。我试图预测“每页记忆间隔”。我使用均方根偏差 (下面表示为 Dev) 进行遗忘预测。到1990年7月10日星期二，Dev 降到了 3 以下，我觉得问题几乎“解决”了。 1990年7月12日，我将 Dev 进一步降低到 2.877（顺便说一句，我论文里的数字是 2.887241）。然而，到1990年8月27日，我宣布该问题无法解决。那天我的笔记上写着：

Personal anecdote. Why use anecdotes?

下面是个人轶事。

Aug 27, 1990: ***I solved the problem** of intermittent learning **showing that it is unsolvable**! One parameter is not able to describe the strength of memory related to the whole page of items. This shows that **there are no optimal intervals for items with low E-factors*** !

1990 年 8 月 27 日：***我解决了**间隔学习的问题，但是是通过**表明它无法解决**的方式！一个参数不足以描述与整页项目相关的记忆强度。这表明具有低 E 因素的项目没有最佳间隔！

On Aug 30 1990, I decribed the model for my Master’s Thesis. The text covered 15 pages that don’t make for a good reading. I bet nobody has ever had the patience to read this all. That chapter has not even been published at supermemo.com when my Master’s Thesis was put on-line in excerpts in the late 1990s.

1990年8月30日，我描述了硕士论文中用到的模型。正文涵盖了15页内容，读起来并不流畅。我敢打赌没有人有耐心读完所有内容。该章节甚至没有在超级记忆法网站上发布，而是在1990年代后期以摘录的形式放在我的硕士论文网上的。

However, the conclusions drawn on the basis of the model had a profound effect on my thinking about memory in the decades that followed. The whole idea behind the model is actually reminiscent of the optimizations used to deliver Algorithm SM-17 (2014-2016).

然而，基于该模型得出的结论对我在随后的几十年中对记忆的思考产生了深远的影响。该模型背后的整个想法实际上已经能让人联想到用于交付算法 SM-17 (2014-2016) 的优化方法。

When I declared the problem unsolvable, I meant that I could not accurately describe the memory of “difficult pages” as heterogenous materials require more complex models. However, Aug 31, 1990 notes sound far more optimistic:

当我宣布该问题无法解决时，我的意思是无法准确地描述“困难页面”的记忆，因为异质材料需要更复杂的模型。然而，1990年8月31日的笔记看起来要更加乐观：

Personal anecdote. Why use anecdotes?

下面是个人轶事。

Aug 31, 1990: *Non-stop work on the intermittent learning model. By night, the computer did not manage to get me closer to the solution. However, I had a great idea to calculate optimal intervals using the record-breaking function of the IL model. When I saw the results on the screen I could not believe my [bleep] eyes. These were exactly the same intervals, which I found in 1985 while trying to formulate the SuperMemo method. I was happy like a dog with two tails jumping around the house. So I can say that I really solved the IL problem (compare August 27, 1990). But this success was not everything I was given to discover today. I found that*:

-   *optimal factors decrease with successive intervals (previously I had an intuition that it is so)*,
-   *for the forgetting index equal 10% the retention is 94% (as in the EVF database)*
-   *retention is in a linear relation to the forgetting index* [comment 2018: in a small range for heterogeneous material] *(this could not be calculated from my simulation experiments carried in January)*
-   *the model says that the desirable value of the forgetting index is 5-10% (workload-retention trade-off)*
-   *strength of memory increases most if the interval is twice as long as the optimal one!!!*
-   *the strength of memory increases most if the forgetting index is 20%*.

[…] *my formulas work only when intervals are not much shorter than the previous strength*.

1990年8月31日：*不停地研究间歇学习模型。到了晚上，计算机并没有让我更接近解决方案。然而，我有一个绝妙的想法，可以使用 IL 模型的纪录突破功能来计算最佳间隔。当我看到屏幕上的结果时，我简直~~他妈的~~不敢相信自己的眼睛。这些间隔与我在 1985 年试图制定 SuperMemo 方法时发现的间隔完全相同。我高兴得像一条有两条尾巴的狗在房子里跳来跳去。所以我可以说我真的解决了 IL 问题（参见1990年8月27日）。但我今天被赋予的成功发现还不止这一项。我发现：*

- *最佳（间隔增长）因子随着间隔持续而减少（之前我有一种直觉是这样）*
- *遗忘指数等于10%的情况下，保留率为 94%（如 EVF 数据库中）*
- *保留率与遗忘指数呈线性关系* [2018 年评论：对于异质材料来说，变动范围很小] *（这无法从我在1月份进行的模拟实验中计算出来）*
- *该模型表明遗忘指数的理想值为 5-10%（在权衡工作量和保留率的前提下）* 
- *如果间隔是最佳间隔的两倍，记忆强度会增加最多！！！*
- *如果遗忘指数为 20%，记忆强度会增加最多。*

[…] _只有当间隔不比之前的强度短得多时，我的公式才有效_。

### 过去（1990）vs. 现在（2018）（Past (1990) vs. Present (2018)）

Conclusions at the end of the chapter and the procedure itself are reminiscent of the methodology I used in 2005 when looking for the universal formula for memory stability increase and then, in 2014, when Algorithm SM-17 was based on a far more accurate mathematical description of memory. Like the newest SuperMemo algorithm, the model made it possible to compute retention for any repetition schedule. Naturally, it was far less accurate as it was based on inferior data. Moreover, what SuperMemo 17 does in real time, it took many hours of computations back in 1990.

本章结尾的结论和过程本身，让我想起自己在2005年和2014年使用过的方法，2005年，这一方法被我用于寻找“描述记忆稳定性增加的通用公式”。2014年，算法 SM-17 已经采用了“准确度比原先好得多的”关于记忆的数学描述。与最新的 SuperMemo 算法一样，该模型（90年的模型）可以计算任何重复计划的保留率。当然，它的准确性要低得多，因为它基于较差的数据。此外，SuperMemo 17 中能实时进行的操作，在 1990 年可能要需要花费数小时的计算。

This old seemingly boring portion of my Master’s Thesis has then grown in importance by now. I dare say that only inferior data separated that work from Algorithm SM-17 that emerged long 25 years later. I quote the text with minor notational and stylistic improvements without the chapter on forgetting curves that was erroneous due to highly heterogeneous material used in computations:

现在，我硕士论文中这一看似无聊的部分变得越来越重要。我敢说，研究时所用到的劣质数据，是导致当时的工作成果与（耗费25年才得到的）算法 SM-17 之间差距的唯一原因。下面我将引用当时的文章，只做了少许标点和语法修正，并且删去了与遗忘曲线有关的章节（删去的这部分内容中，因为计算所用到的原始数据存在高度异质性，现在看来错误百出）

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

**Experiment intended to approximate the length of optimum inter-repetition intervals** (Feb 25, 1985 – Aug 24, 1985):

**旨在接近最佳重复间隔长度的实验** （1985年2月25日–1985年8月24日）

**Model of intermittent learning**

**间歇性学习模型**

The SuperMemo model provides a basis for the calculation of optimal intervals that should separate repetitions in the process of time optimal learning.

SuperMemo 模型为计算时间最优学习过程中重复之间的最佳间隔提供了基础。

However, it does not allow to predict the changes of memory variables if repetitions are done in irregular intervals.

但是，它无法预测，以不规则间隔进行重复的情况下，记忆数据的变化。

Below I present an attempt to augment the SuperMemo model so that it can be used in the description of the process of intermittent learning.

下面我将尝试扩展 SuperMemo 模型，以使其能够用于描述间歇学习过程。

In Chapter 3, I mentioned the way in which I had learnt English and biology before the SM-0 algorithm was developed.

在第3章中，我提到了在开发 SM-0 算法之前，我学习英语和生物学的方法。

Data collected during that time (1982-1984) provide an excellent basis for the construction of the model of intermittent learning. Items, formulated in compliance with the minimum information principle (usually having the form of pairs of words) were grouped in pages subject to the irregular repetitory process.The collected data, available in the computer readable form, include the description of repetitions of 71 pages, and in addition, 80 similar pages participating in a process supervised by the SM-0 schedule.

在此期间（1982-1984 年）收集的数据为构建间歇学习模型提供了极好的基础。符合最小信息原则的项目（通常以单词对的形式呈现）被分组为页面，以不规则间隔进行重复。收集的数据能通过计算机读取，包括71页的重复过程记录，此外，还有80页类似的遵循 SM-0 算法的重复过程记录。

### 与算法 SM-17 的相似性（Similarity to Algorithm SM-17）

Note that the formulation of the problem is reminiscent of the procedure used to compute the stability increase matrix (SInc[]) in Algorithm SM-17. Memory stability was rescaled to make it possible to interpret it as an interval. Even the symbols are similar: S and deviation D, and page lapses substituting for R.

请注意，这一问题的表述让人想起在算法 SM-17 中用于计算稳定性增加矩阵 (SInc[]) 的过程。记忆稳定性被重新调整比例，以便可以将其计算为间隔。甚至符号也很相似：S 和偏差 D，以及页面遗忘比例 R。

I loved playing with various optimization algorithms. You can still visually observe in SuperMemo 17 how the algorithm runs surface fitting optimizations (see picture). Doing it with 12 variables might have been a bit inefficient, but I never cared about the method as long as I got interesting results that provided new insights into how memory works.

我喜欢玩各种优化算法。您在超级记忆法 17 中仍然可以直观地观察到算法如何进行曲面拟合优化（请参见图片）。用 12 个变量来做这事可能有点低效，但只要我得到有趣的结果，能够为记忆的工作原理提供新见解，我就从不在乎方法。

For those familiar with Algorithm SM-17, we changed the notation in the text below. In addition, symbols such as In and Ln in print could easily be misread as logarithms.

<small>The list of changes:</small>
-   <small>Ln -&gt; Laps&nbsp;<sub>n</sub></small>
-   <small>In -&gt; Int&nbsp;<sub>n</sub></small>
-   <small>Dn -&gt; Dev&nbsp;<sub>n</sub></small>
-   <small>R -&gt; RepNo</small>

对于熟悉算法 SM-17 的人来说，我们更改了以下文本中的符号。此外，印刷品中的 In 和 Ln 符号很容易被误读为对数。

<small>改动列表：</small>
- <small>Ln -&gt; Laps&nbsp;<sub>n</sub></small> 
- <small>In -&gt; Int&nbsp;<sub>n</sub></small> 
- <small>Dn -&gt; Dev&nbsp;<sub>n</sub></small> 
- <small>R -&gt; RepNo</small>

### 间歇学习问题的表述（Formulation of the problem of intermittent learning）

Archive warning: Why use literal archives?

下面是引用文档

**11.1. Formulation of the problem of intermittent learning**

1.  There are 161 pages.
2.  Each page contains about 40 items.
3.  For each page, the description of the learning process (collected during experimental repetitions) has the following form:
4.  Int <sub>i</sub> – inter-repetition interval used before the i-th repetition (it ranges from 1 to 800),
5.  Laps <sub>i</sub> – number of lapses of memory during the i-th repetition (it ranges from 0 to 40),
6.  n – total number of repetitions (it ranges from 3 to 20).
7.  Find the functions f and g described by the formulas:
8.  S(n) – any variable corresponding to the strength of memory after the n-th repetition (compare Chapter 10),
9.  Int <sub>n</sub> – interval used before the n-th repetition; taken from data collected during intermittent learning,
10.  Laps <sub>n</sub> – number of memory lapses in the n-th repetition; taken from data collected during intermittent learning,
11.  Laps(n) – estimation of the number of memory lapses in the n-th repetition (it should correspond with Laps <sub>n</sub>)
12.  S1 – a constant,
13.  Dev – function that describes the difference between values yielded by the functions f and g, and values collected during intermittent learning (it reflects the difference between experimental and theoretically predicted data)
14.  RepNo – total number of repetitions recorded on all pages
15.  Dev <sub>i</sub> – component of the function Dev describing the deviation for the i-th page,
16.  Laps(j) – number of lapses calculated for the i-th page and j-th repetition using the functions f and g,
17.  Laps <sub>j</sub> – number of lapses of memory for the i-th page and j-th repetition; taken from data collected during intermittent learning,
18.  sqrt(x) – square root of x,
19.  sqr(x) – second power of x.

**11.1. 间歇学习问题的表述**

1. 共有 161 页。
2. 每个页面包含约 40 个项目。
3. 对于每个页面，学习过程的描述（在实验重复期间收集）具有以下形式：
4. Int <sub>i</sub> – 第 i 次重复之前使用的重复间隔（范围从 1 到 800）， 
5. Laps <sub>i</sub> – 第 i 次重复期间的记忆遗忘次数（范围从 0 到 40），
6. n – 总重复次数（范围从 3 到 20）。
7. 找到由以下公式描述的函数 f 和 g：
8. S(n) – 第 n 次重复后记忆强度对应的任何变量（参见第 10 章），
9. Int <sub>n</sub> – 第 n 次重复之前使用的间隔；取自间歇学习期间收集的数据，
10. Laps <sub>n</sub> – 第 n 次重复中的记忆遗忘次数；取自间歇学习期间收集的数据，
11. Laps(n) – 第 n 次重复中记忆遗忘次数的估计值（应与 Laps <sub>n</sub> 对应）
12. S1 – 常数，
13. Dev – 函数，描述了函数 f 和 g 所产生的值，与间歇学习期间收集的值之间的差异（它反映了实验数据与理论预测数据之间的差异） 
14. RepNo – 在所有页面上记录的总重复次数
15. Dev <sub>i</sub> – 描述第 i 页偏差的函数 Dev 的组成部分，
16. Laps(j) – 第 i 页和第 j 次重复时的记忆遗忘次数；使用函数 f 和 g 计算得到，
17. Laps <sub>j</sub> – 第 i 页和第 j 次重复时的记忆遗忘次数；取自间歇学习期间收集的数据，
18. sqrt(x) – x 的平方根，
19. sqr(x) – x 的二次方。

Note that functions f and g will provide a basis for valuable biological considerations only if they are simple and defined by a limited number of parameters (e.g. a×ln()+b or a×exp()+b etc.). Otherwise, one could always construct a gigantic, meaningless formula to automatically put Dev to zero.

请注意，只有当函数 f 和 g 足够简单且由有限数量的参数定义（例如 a×ln()+b 或 a×exp()+b 等）时，它们才能为有价值的生物学研究提供基础。否则，人们总是可以构建一个巨大的、毫无意义的公式来自动将 Dev 置零。

### 间歇学习问题的解决（Solution to the problem of intermittent learning）

Archive warning: Why use literal archives?

下面是引用文档

**11.2. Solution to the problem of intermittent learning**

In the search for functions f and g that minimize the value of Dev I used a numerical minimization procedure described in Wozniak, 1988b [ <small><em>A new algorithm for finding local maxima of a function within the feasible region. Credit paper</em>&nbsp;</small> ].

在寻找使 Dev 值最小化的函数 f 和 g 时，我使用了 Wozniak, 1988b 在[<small><em>A new algorithm for finding local maxima of a function within the feasible region. Credit paper</em>&nbsp;</small>] 中描述的数值最小化程序。

Exemplary functions used in the search could look as follows:

S(1)=x[1]
S(n)=x[2] × Int <sub>n</sub> × exp(-Laps <sub>n</sub> × x[3])+x[4])
Laps(n)=x[5] × (1-exp(-Int <sub>n</sub>/S(n-1)))
  
where:
-   x[i] – variables that are computed by the minimization procedure,
-   S(n), Laps(n), Laps <sub>n</sub> and Int <sub>n</sub> – as defined in 11.1.

搜索中使用的函数，示例之一如下所示：

S(1)=x[1]
S(n)=x[2] × Int <sub>n</sub> × exp(-Laps <sub>n</sub> × x[3])+x[4])
Laps(n)=x[5] × (1-exp(-Int <sub>n</sub>/S(n-1)))

其中：
- x[i] – 由最小化过程计算的变量，
- S(n)、Laps(n)、Laps <sub>n</sub> 和 Int <sub>n</sub> – 如 11.1 中所定义。

Note, that the function f describing S(n) does not use S(n-1) as its argument (the formulation of the problem allows, but does not require, that the new strength be calculated on the base of the previous strength).

请注意，描述 S(n) 的函数 f 不使用 S(n-1) 作为其参数（问题的表述允许但不一定要求在先前强度的基础上计算新强度）。

In order to retain simplicity and save time, I set a limit of 12 variables used in the process of minimization.

为了保持简单并节省时间，我把在最小化过程中使用的变量数量限制为 12 个。

I tested a great gamut of mathematical functions constructed in accordance with obvious intuitions concerning memory (e.g. that with time passing by, the number of lapses of memory will increase).

我测试了大量数学函数，都是根据有关记忆的明显直觉构建的（例如，随着时间的推移，记忆遗忘的数量会增加）。

These included exponential, logarithmic, power, hyperbolic, sigmoidal, bell-shaped, polynomial and reasonable combinations thereof.

这些包括指数、对数、幂、双曲线、S 型、钟形、多项式以及它们的合理组合。

In most cases, the minimization procedure reduced the value of Dev to less than 3, and functions f and g assumed similar shape independent of their nature.

在大多数情况下，最小化过程将 Dev 的值降低到 3 以下，并且函数 f 和 g 的形状相似（f 和 g 形状相似这一现象和它们的性质无关）。

The lowest value of Dev obtained with the use of fewer than 12 variables was 2.887241.

使用少于 12 个变量获得的 Dev 的最低值为 2.887241。

The functions f and g were as follows:

对应的函数 f 和 g 如下所示：

```
constant S(1)=0.2104031;

function Sn(Intn,Lapsn,S(n-1));
begin
   <strong>S(n):=0.4584914*(Intn+1.47)*exp(-0.1549229*Lapsn-0.5854939)+0.35;</strong>
   if Lapsn=0 then
       if S(n-1)&gt;In then
           S(n):=S(n-1)*0.724994
       else
           S(n):=Intn*1.1428571;
end;

function Lapsn(Intn,S(n-1));
var quot;
begin
   quot:=(Intn-0.16)/(S(n-1)-0.02)+1.652668;
   Lapsn:=-0.0005408*quot*quot+0.2196902*quot+0.311335;
end;
```

Without significantly changing the value of Dev, these functions can be easily converted to the following form:

> S(1)=1
> for Int <sub>n</sub>>S(n-1): S(n)=1.5×Int <sub>n</sub>×exp(-0.15×Laps <sub>n</sub>)+1
> Laps(n)=Int <sub>n</sub>/S(n-1)

无需显着改变 Dev 的值，就可以轻松将这些函数转换为以下形式：

> S(1)=1
> 对于 Int <sub>n</sub>>S(n-1)：S(n)=1.5×Int <sub>n</sub>×exp(-0.15×Laps <sub>n</sub>)+1
> Laps(n)=Int <sub>n</sub>/S(n-1)

Note that:
-  particular elements of the function where dropped or rounded whenever the operation did not considerably affect the value of Dev,
-  strength was rescaled to allow it to be interpreted as an interval for which the number of lapses equals 1 and the forgetting index equals 2.5% (there are 40 items on a page and 1/40=2.5%),
-  the formula for strength can only be valid if Int <sub>n</sub> is not much less than S(n-1). This is because of the fact that the value S(n-1) must be used in calculation of S(n) if the number of lapses is low, e.g. for Int <sub>n</sub><=S(n-1): S(n)=S(n-1)×(1+0.5/(1-exp(S(n-1))×(1-exp(-Int <sub>n</sub>)))
-  The function g intentionally did not involve S(n-1) to avoid recursive accumulation of errors in calculations for successive repetitions (note, that the formula used does not consider the history of the process),
-  the formulas cannot be used to describe any process in which intervals are manifold longer than the optimal ones. This is because of the fact that for Int <sub>n</sub>->? the value of Laps(n) exceeds 100%,
-  the formulas describe learning of collective items characterized by more or less uniform distribution of E-Factors. Therefore it cannot be used universally for items of variable difficulty.

请注意：
- 只要操作不会显着影响 Dev 的值，就可以删除或舍弃函数的特定元素，
- 强度已重新调整比例，以便可以将其计算为遗忘次数等于 1 且遗忘指数等于 2.5% 时对应的间隔（一页上有 40 个项目，1/40=2.5%），
- 只有当 Int <sub>n</sub> 不比 S(n-1) 小得多时，强度公式才有效。这是因为如果遗忘次数较低，则必须在计算 S(n) 时使用 S(n-1) 的值，例如对于 Int <sub>n</sub><=S(n-1)：S(n)=S(n-1)×(1+0.5/(1-exp(S(n-1))×(1-exp(-Int <sub>n</sub>)))
- 函数 g 故意不涉及 S(n-1)，以避免在连续重复的计算中递归累积误差（请注意，使用的公式没有考虑过程的历史）
- 这两个公式不能用于描述任何间隔比最佳间隔长得多的过程。这是因为 Int <sub>n</sub>->? Laps(n) 的值会超过 100%
- 这两个公式描述了集体项目的学习，这些集体项目中的 E 因子或多或少是均匀分布的。因此，它不能普遍适用于各种难度的项目。

As for now, the above formulas make up the best description of the process of intermittent learning, and will later be referred to as the model of intermittent learning (IL model for short).

目前，上述公式构成了对间歇学习过程的最佳描述，并将在以后被称为间歇学习模型（简称 IL 模型）。

### 基于间歇学习模型的模拟（Simulations based on the model of intermittent learning）

With the formula found above, I could run a whole series of simulation experiments that would help me answer many hypothetical scenarios on the behavior of memory in various circumstances. Those simulations shaped the progress of SuperMemo for many years to follow. In particular, the trade-off between workload and retention played a major role in optimization of learning as of SuperMemo 6 (1991). Until this day, it is the forgetting index (or retrievability) that provide the guiding criterion in learning, not the intuitively natural increase in memory stability that may occur at lower levels of recall. Set level of memory lapses played the role of the forgetting index below.

通过上述公式，我可以进行一系列的模拟实验，以帮助我解答许多记忆行为在各种不同情况下的设想。这些模拟塑造了随后的多年来 SuperMemo 的发展进程。特别是，工作量和记忆保留率之间的权衡在 SuperMemo 6（1991年）的学习优化中发挥了重要作用。直到今天，指导学习的标准仍然是遗忘指数（或可检索性），而非我们凭直觉认为的记忆稳定性的自然增加（在较低水平的回忆中可能出现的）。在下面的内容中，设定的记忆遗忘水平扮演了遗忘指数的角色。

Archive warning: Why use literal archives?

下面是引用文档

**11.4. 间歇学习模型的验证（Verification of the model of intermittent learning）**

To verify the consistency of the model of intermittent learning with the SuperMemo theory, let us try to calculate optimal intervals that should separate repetitions.

为了验证间歇学习模型与 SuperMemo 理论的一致性，让我们尝试计算两次重复之间的最优间隔。

The optimal interval will be determined by the moment at which the number of lapses reaches a selected value Laps <sub>o</sub>.

最优间隔将由遗忘次数达到选定值 Laps<sub>o</sub> 的时刻决定。

The algorithm proceeds as follows:

1.  i:=1
2.  S(i):=1
3.  Find Int(i+1) such that Laps(i+1) equals Laps <sub>o</sub>. Use the formula:  
    Int(n)=Laps <sub>o</sub>×S(n-1) (taken from IL model)  
    where:Int(n) denotes the n-1 optimal interval.
4.  i:=i+1
5.  S(i):=1.5×Int(i)×exp(-0.15×Laps<sub>o</sub>)+1 (taken from the IL model)
6.  goto 3

1. i:=1 
2. S(i):=1
3. 查找 Int(i+1) 使得 Laps(i+1) 等于Laps<sub>o</sub>。使用以下公式：     
	-  Int(n)=Laps <sub>o</sub>×S(n-1) （取自 IL 模型）     
	-  其中：Int(n)表示第 n-1个最优间隔。
4. i:=i+1
5. S(i):=1.5×Int(i)×exp(-0.15×Laps<sub>o</sub>)+1 （取自IL模型）
6. 转到步骤3

If Laps <sub>o</sub> equals 2.5 ( forgetting index 6.25%) and the exact variant of the model of intermittent learning is used then an amazing correspondence can be observed (compare the experiment presented on page 16, Chapter 3.1):

-   Rep – number of the repetition
-   Interval – optimal interval preceding the repetition, determined by Laps <sub>o</sub>=2.5 on the base of the IL model,
-   Factor – optimal factor equal to the quotient of the optimal interval and previously used optimal interval,
-   SM-0 – optimal interval calculated on the base of experiments leading to the algorithm SM-0

如果Laps<sub>o</sub>等于2.5（遗忘指数6.25%）并且使用了间歇学习模型的精确变体，则可以观察到惊人的对应关系（和第3.1章第16页的实验进行对比）：

- Rep – 重复次数
- Interval – 由Laps<sub>o</sub>=2.5在 IL 模型的基础上确定的、在重复之前最优的时间间隔，
- Factor – 最优因子，等于最优时间间隔与先前使用的最优时间间隔的商，
- SM-0 – 基于导致算法SM-0的实验计算出的最优时间间隔

| Rep | Interval | Factor | SM-0 |
| --- | -------- | ------ | ---- |
| 2   | 1.8      |        | 1    |
| 3   | 7.8      | 4.36   | 7    |
| 4   | 16.8     | 2.15   | 16   |
| 5   | 30.4     | 1.80   | 35   |
| 6   | 50.4     | 1.66   |      |
| 7   | 80.2     | 1.59   |      |
| 8   | 124      | 1.55   |      |
| 9   | 190      | 1.53   |      |
| 10  | 288      | 1.52   |      |
| 11  | 436      | 1.51   |      |
| 12  | 654      | 1.50   |      |
| 13  | 981      | 1.50   |      |
| 14  | 1462     | 1.49   |      |
| 15  | 2179     | 1.49   |      |
| 16  | 3247     | 1.49   |      |
| 17  | 4838     | 1.49   |      |
| 18  | 7209     | 1.49   |      |

Obviously, the exact correspondence, to some extent, is a coincidence because the experiment leading to the formulation of the algorithm SM-0 was not that sensitive.

显然，在某种程度上，完全一致是一种巧合，因为导致算法 SM-0 的实验并不那么敏感。

It is worth noticing, that **optimal factors tend to decrease gradually!** This fact seems to confirm recent observations based on the analysis of the matrix of optimal factors used in the algorithm SM-5.

值得注意的是，**最优因子倾向于逐渐减小**！这一事实似乎证实了最近对算法 SM-5 中使用的最优因子矩阵进行分析得到的观察结果。

If Laps<sub>o</sub> equals 4 ( forgetting index 10%, as in the algorithm SM-5) then the sequence of optimal factors resembles a column of the OF matrix in the algorithm SM-5. Also the knowledge retention matches almost ideally the one found in SM-5 databases.

如果 Laps<sub>o</sub> 等于4（遗忘指数10%，和算法SM-5中的前提一致），则最优因子的序列类似于算法 SM-5 中 OF 矩阵的一列。此外，知识保留率也几乎完美匹配在 SM-5 数据库中的对应数据。

The value of retention was obtained by averaging its value calculated for each day of the optimal process:

R=(R(1)+R(2)+…+R(n))/n

R(d)=100-2.5×Laps(d-dlr)

where:
-   R – average retention
-   R(d) – retention on the d-th day of the process
-   Laps(Int) – expected number of lapses after the interval I
-   dlr – day of the process on which the last repetition was scheduled

保留率的值是通过对（最优过程中）每天计算出的保留率进行平均而获得的：

R=(R(1)+R(2)+…+R(n))/n

R(d)=100-2.5×Laps(d-dlr)

其中：
- R – 平均保留率 
- R(d) – 过程中第 d 天的保留率
- Laps(Int) – 间隔 I 之后预期的遗忘次数
- dlr – 安排最后一次重复的日期

### 工作量与保留率的权衡（Workload vs. Retention trade-off）

Despite the inaccuracies coming from heterogeneous material, solid conclusion could be drawn about the impact of the forgetting index on the amount of time needed to invest in learning. Those observations survived the test of time:

尽管异质性材料带来了不准确性，但仍可得出关于遗忘指数对学习所需时间影响的可靠结论。这些观察结果经受住了时间的考验：

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

Very interesting conclusions may be drawn by comparison of retention and workload data calculated by means of the model of intermittent learning:

-   Index – forgetting index (Laps <sub>o</sub>×2.5) determining optimal intervals in the process of time optimal learning scheduled with the use of the IL model
-   Retention – overall retention obtained while using the given forgetting index (calculated upon elapse of 10,000 days)
-   Repetitions – number of repetitions scheduled in the first 10,000 days of the process when using the given forgetting index,
-   Factor – asymptotic value of the optimal factor (taken from the 10,000-th day of the process)

通过比较使用间歇学习模型记忆得到的保留率和工作量数据，可以得出非常有趣的结论：

- **指数（Index）** - 遗忘指数（Laps <sub>o</sub>×2.5），用于确定使用 IL 模型安排的时间优化学习过程中最佳间隔。
- **保留率** - 使用给定遗忘指数时获得的总体保留率（在经过 10,000 天后计算）。
- **重复次数** - 使用给定遗忘指数时，在过程的前 10,000 天内安排的重复次数。
- **因子** - 最佳因子的渐近值（取自过程的第 10,000 天）。

Figure 11.2 demonstrates that the forgetting index used in determination of optimal intervals should fall into the range 5 to 10%.

图11.2表明，用于确定最佳间隔的遗忘指数应落在5%到10%的范围内。

![[Workload-retention_tradeoff.jpg]]

> ***Fig. 11.2. Workload-retention trade-off:*** *On one hand, if forgetting index is lower than 5%, then the workload increases dramatically without substantially affecting the retention. On the other, above forgetting index of 10%, workload hardly changes while retention steadily falls down. Obviously, the workload-retention trade-off corresponds directly to the compromise between the acquisition rate and retention. By increasing the availability of time X times (by decreasing the workload X times), one can increase the acquisition rate X times (compare Chapter 5). Note, that the relation of the forgetting index and retention in this model is almost linear.* <small>(source:&nbsp;<a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>:&nbsp;<em><a href="http://supermemo.guru/wiki/Search_for_a_universal_memory_formula" rel="noreferrer noopener" target="_blank">Model of intermittent learning</a>&nbsp;</em>,&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>, 1990)</small>
> 
> ***图 11.2. 工作量-保留率权衡***：*一方面，如果遗忘指数低于 5%，则工作量会急剧增加，而对保留率的影响却不大。另一方面，如果遗忘指数高于 10%，工作量几乎不变，而保留率则稳步下降。显然，工作量-保留率权衡直接对应于（记忆）获取速度和保留率之间的折衷。通过将可用时间增加 X 倍（通过将工作量减少 X 倍），可以将获取率增加 X 倍（参见第 5 章）。请注意，在本模型中，遗忘指数与保留率之间的关系几乎是线性的*
。<small>(来源：<a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>：<em><a href="http://supermemo.guru/wiki/Search_for_a_universal_memory_formula" rel="noreferrer noopener" target="_blank">间隔学习模型</a></em>，<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>，1990)</small>

Another important observation comes from the calculation of the forgetting index for which the increase of strength is the greatest.

另一个重要的观察结果来自计算遗忘指数，它为我们指明了记忆增长幅度最大的点。

From the model of intermittent learning it follows that

> S(n)=1.5×Laps(n)×S(n-1)×exp(-0.15×Laps(n))+1

Upon differentiation for the variable Laps(n) we arrive at:

> S'(n)=1.5×S(n-1)×exp(-0.15×Laps(n))×(1-0.15×Laps(n))

Finally, after equating with zero, we obtain:

> Laps(n)=7.8

根据间歇学习模型，可得：

> S(n)=1.5×Laps(n)×S(n-1)×exp(-0.15×Laps(n))+1

对变量Laps(n)进行微分，得到：

> S'(n)=1.5×S(n-1)×exp(-0.15×Laps(n))×(1-0.15×Laps(n))

最后，令其等于零，得到：

> Laps(n)=7.8

which corresponds to the forgetting index equal to 20%! Such a forgetting index is equivalent to intervals 2 times longer than the optimal ones determined by the index equal 10% (as in the Algorithm SM-5). However, it must not be forgotten that it is the knowledge retention and not the strength of memory that is the only factor traded for workload. Therefore the above finding does not abolish the validity of the Algorithm SM-5.

这正好对应于20%的遗忘指数！这样的遗忘指数对应的间隔，相当于由10%的遗忘指数（通过算法 SM-5）确定的最佳间隔的两倍。但是，必须记住，知识保留率而非记忆强度才是决定工作量的唯一因素。因此，上述发现并不废除算法SM-5的有效性。

### 间歇性学习模型的结论（Conclusions: model of intermittent learning）

The ultimate conclusions drawn at the end of the chapter stood the test of 3 decades. Only the claim on non-exponential shape of forgetting curves is inaccurate. As the entire model was based on heterogeneous data, the exponential nature of forgetting could not have been revealed.

本章末尾得出的最终结论经受住了30年的考验。只有关于遗忘曲线非指数形状的主张是不准确的。由于整个模型都是基于异质性数据，因此无法揭示遗忘的指数性质。

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

**Interim summary**

-   The model of intermittent learning was constructed making it possible to estimate knowledge retention upon different repetition schedules
-   The model strongly indicates that the forgetting curve is not exponential [ wrong: see Exponential nature of forgetting]
-   The model satisfactorily corresponds to experimental data
-   With a striking accuracy, the model approximates optimal intervals and knowledge retention implied by the SuperMemo model
-   The model indicates that optimal factors decrease in successive repetitions and asymptotically approach the ultimate value
-   The model indicates that the desirable value of the forgetting index used in time optimal learning should fall into the range 5% to 10%
-   The model indicates an almost linear relation of the forgetting index and knowledge retention
-   The model shows that the greatest increase of the strength of memory occurs when intervals are approximately 2 times longer than that used in the SuperMemo method. This is equivalent to the forgetting index equal to 20%

**阶段性总结**

- 间歇学习模型的构建使得估算不同重复计划下的知识保留率成为可能。
- 该模型强烈表明遗忘曲线不是指数型的 [本条结论是错误的：参见遗忘的指数性质]
- 该模型与实验数据令人满意地吻合。
- 该模型所指示的最优间隔和知识保留率与 SuperMemo 模型惊人地一致。
- 该模型表明，最优（间隔增长）因子在连续重复中逐渐减小并渐近地接近最终值。
- 该模型表明，为了使学习的耗时最优，遗忘指数的理想值应落在5%到10%的范围内。
- 该模型表明遗忘指数与知识保留率之间几乎呈线性关系。
- 该模型表明，当间隔比超级记忆法中使用的间隔长约2倍时，记忆强度的增加最大。这相当于遗忘指数稳定在大约20%时的情况。

## 1991年：运用遗忘曲线（1991: Employing forgetting curves）

### SuperMemo World 的艰难诞生（1991年）（Painful birth of SuperMemo World (1991)）

1991 was the most important year since the birth of SuperMemo. It was a year of big decisions, stress, drama, discovery and hard work. At the start of the year, there were three greatest believers in SuperMemo: Biedalak, Murakowski and myself. We were all in the same spot in our lives: transitioning from the years of unconcern in university to the uncertainty of independent adulthood. By default, we all dreamt of big science in the US: Biedalak dreamt of artificial intelligence, Murakowski of quantum physics, and I wanted to crack the secrets of molecular memory. In retrospect, graduate students from Eastern Bloc with good transcripts, exam results and rock-solid recommendations are pretty welcome in the US. Things get more complex if they demand full financial support. I did not have a penny. Moreover, eager Easterners were often treated as dutiful labor. Zeal for their own projects and great ideas might have been less welcome. I will never know. The three believers had all different visions for SuperMemo.

1991年是自超级记忆诞生以来最重要的一年。这一年充满了重大决策、压力、戏剧性事件、发现和辛勤工作。在年初，有三位对 SuperMemo 抱有最坚定信心的人：Biedalak、Murakowski 和我。我们在生活中都处于相同的位置：从大学无忧无虑的岁月过渡到独立成年后的不确定性。最初，我们都梦想着在美国进行伟大的科学研究：Biedalak 梦想着人工智能，Murakowski 梦想着量子物理学，而我则想揭示记忆在分子层面的秘密。回想起来，来自东欧地区的履历优秀、成绩出色且受到可靠举荐的研究生在美国还是非常受欢迎的。但如果他们要求全额经济资助，事情就会变得更加复杂。不巧我没有一分钱。此外，渴望学习的东欧人往往被视为尽职的劳动力。但他们对自己的项目和伟大想法的热情就未必如此受欢迎了。我永远不会想到。三位信徒对 SuperMemo 的愿景如此不同。

On Jan 3, 1991, I started the implementation of the new spaced repetition algorithm for SuperMemo 6. On the same day, Murakowski left for London where he would pursue his educational dreams while trying to sell SuperMemo 2. He would not sell via a distribution channel or in a shop. He would need to go from person to person, explain the merits of the program and hopefully collect a few bucks to keep the hope going.

1991年1月3日，我开始试用为 SuperMemo 6 准备的新间隔重复算法。同一天，Murakowski 前往伦敦，在那里他将追求自己的教育梦想，同时尝试销售 SuperMemo 2。他暂时还没法通过分销渠道或商店进行销售。只能逐门逐户地推销，解释该程序的优点，并希望赚到一些钱来维持希望。

In the meantime, Biedalak and I met regularly for a 10 km jogging that would be combined with winter swimming and a brainstorming session on the way back home. We mostly spoke of studying in the US and selling SuperMemo. More and more frequently, the idea of our own company started coming up.

与此同时，Biedalak 和我定期进行10公里慢跑，然后一起冬泳，并在回家的路上进行头脑风暴。我们主要讨论在美国的学习和 SuperMemo 的销售。越来越频繁地，我们自己的公司这个想法开始浮现。

I started my work over the new spaced repetition algorithm with some ideas that would change SuperMemo forever. Algorithm SM-6 used in SuperMemo 6 was a breakthrough that would power further development over the next 25 years. It would re-employ the simple experimental procedure that led to spaced repetition in 1985 but would do it in an automated manner. It would collect performance data and choose the best time for review: it would plot the user’s forgetting curve. This would also mean that the user would be able to decide the acceptable probability of forgetting for every single item (i.e. the optimum level of retention-workload tradeoff).

我开始着手开发新的间隔重复算法，其中包含一些将永远改变 SuperMemo 的想法。SuperMemo 中使用的算法 SM-6 是一项突破，将在未来25年推动进一步发展。它将重新采用1985年帮我们发现了间隔重复的简单实验程序，但会以自动化的方式进行。它将收集（用户）表现数据并选择最佳复习时间：它将绘制用户的遗忘曲线。这也意味着用户将能够为每个（记忆）项目决定可接受的遗忘概率（同时也确定了保留率-工作量的最佳平衡点）。

At that time, I was still bound to 360 kB diskettes. For that reason, SuperMemo still could not keep all repetition histories that would fully replicate the 1985 approach on a massive scale. However, on Jan 6, 1990, I had a simple idea. I could just collect data about the forgetting curves for classes of items of different difficulty and stability. Instead of the full record, I would only update the approximation of how many items in a given class are retained in memory at a given time (i.e. at a given level of retrievability). That idea survives at the core of SuperMemo to this day. Even with the full record of repetition histories today, SuperMemo still instantly knows the expected retrievability of items in a given class.

当时，我仍然受限于360 KB 的软盘。因此，如果在更大规模上完全复制1985年的方法，SuperMemo 将无法保留所有重复历史。然而，在1990年1月6日，我了有一个简单的主意。我可以只针对不同难度和稳定性的项目类别收集遗忘曲线的​​数据。与其保留完整记录，我不如更新近似值，即对各个特定类别，在给定的时间后（即在给定的可检索性水平上）有多少项目保留在记忆中。这个想法至今仍是 SuperMemo 的核心。即使我们现在已经能轻松保存完整的重复历史记录， SuperMemo 仍然可以立即确定特定类别中项目的预期可检索性。

At the crossroads in life, I was finally free from school. There is a powerful emotion that millions of teens and young adults face in their lives: a traumatic move from a slave called “pupil” or “student”, to the freedom of becoming an “unemployed adult”. The psychological shakeup can be even more dramatic if one turns from “good student” to “unemployed 28-year-old living with his mom”. Like a lightswitch: the whole world seems to change from cheerful support to a gloomy-faced condemnation mixed up with pity.

在人生的十字路口，我终于摆脱了学校的束缚。数百万青年一生中早晚会面临一种强烈的感情：从被称为“学生”或“学徒”的奴隶生涯，到成为“失业成年人”的自由人生的痛苦转变。如果一个人突然从“好学生”变成“与母亲同住的28岁失业者”，心理上的震动可能会更加剧烈。就像按下了一个电灯开关，整个世界的态度似乎都从快乐的支持变成了忧郁的谴责，还夹杂着怜悯。

I kept learning and worked on new ideas for SuperMemo in the atmosphere of freedom mixed up with uncertainty. For me, uncertainty is an energizer. However, on Feb 12, 1991, I learned that my mom was diagnosed with terminal cancer. To the mix of freedom and uncertainty, it added the sense of gloom. For me again, gloom can also be an energizer. I tripled my learning about cancer as if in hope of finding out some magic therapy on my own. This shows how unreasonable optimism can be a key to productivity, and surviving hard times. By working harder I could dispel the gloom. High productivity is a sure anti-depressant. My hard work left no room for dark thoughts. I was confident, I would cure my mom!

我继续学习，并在自由与不确定性交织的气氛中研究 SuperMemo 的新想法。对我来说，不确定性是一种激励因素。然而，1991年2月12日，我得知母亲被诊断出患有晚期癌症。这一消息在自由和不确定性的基础上，还额外增添了忧郁。对我来说，忧郁也可以是一种激励因素。我三倍努力地学习癌症知识，仿佛希望自己能找到一些神奇的疗法。这表明不合理的乐观主义有时也能成为提高生产力和度过难关的关键。通过更加努力地工作，我得以暂时驱散忧郁。忙于生产是一种可靠的抗抑郁药。努力工作让我没有时间被坏念头困扰。我很有信心，我会治愈母亲！

Incidentally, at the moment of mom’s diagnosis, I was also writing a program to simulate the optimum behavior of memory in response to the environment; a way to prove what math would make the two component model of memory optimum. At the diagnosis, I threw that effort out of my schedule to learn about cancer. I never completed that program and that idea still lives in limbo pushed away by other projects.

巧合的是，在我母亲被诊断出患有癌症的那一刻，我也在编写一个程序来模拟记忆对环境的最优响应行为；试图证明使要记忆的二元模型达到最佳状态，需要满足什么数学条件。收到诊断结果后，我放弃了这项工作，开始学习癌症知识。我从未完成过那个程序，那个想法仍然处于搁置状态，被其他项目推迟了。

On Mar 6, 1991, during one of our jogging-cum-brainstorming days with Biedalak, someone tossed the name SuperMemo World. Little did we know that four months later that would be the name of our company that has survived 27 years today.

1991年3月6日，在我和 Biedalak 一同慢跑兼进行头脑风暴的日子里，有人提出了“SuperMemo World”这个名字。我们当时并不知道，四个月后，这将成为我们公司27年来一直沿用的名称。

On Mar 12, 1991, I made my first repetitions with the new algorithm in SuperMemo 6 while my mom rested on her deathbed. A week later, she died peacefully in sleep at the young age of 70. In similar circumstances, the usual picture involves family meetings, mourning, funeral, and a whole host of traditions with roots in religion that I could never accept as rational. Instead, 9 hours after my mom’s death, I worked on a better method for a fast approximation of the OF matrix. In that work, I capitalized on the job I once did for ZX Spectrum. I would employ linear regression along the difficulty columns and negative exponential regression along the repetition rows. Years later, I found that power regression is more appropriate for the latter. Only Algorithm SM-8 developed four years later would make a full use of those ideas. However, I mention it mostly to illustrate how hard work and productivity can work great as a remedy against gloom and possible depression. At that time I discovered that the impact of an emotional trauma follows a circadian curve. I would work hard in the morning, but the gloom would keep creeping back to my mind in the evening. Sleep would be the liberation and the best anti-depression. From those early days I am a firm believer in the idea that sleep and learning carry a solution to the problem of depression, however, I never truly had a chance to work on it. It would help if I suffered a bit myself, but either I have some good resilience endowment, or, more likely, I instinctively employ the tools of good sleep and high productivity at hard times. Ever since Sapolsky called depression the “worst disease in the world”, I wanted to find a formula for preventing depression. I sense there is a simple formula. Perhaps that naive childlike optimism itself is part of the solution?

1991年3月12日，当我的母亲躺在病床上休息时，我用 SuperMemo 6进行了新的算法的第一次重复。一周后，她在睡梦中安详地去世了，享年70岁。一般像这种情况，后续会包括家庭聚会、哀悼、葬礼以及一系列根植于宗教的传统（我永远不会认为这些传统是理性的）。但相反，在我母亲去世9小时后，我致力于寻找一种更好的方法来快速逼近 OF 矩阵。在那项工作中，我利用了我曾经为 ZX Spectrum 做过的工作。我对难度（列）采用线性回归，对重复次数（行）采用负指数回归。几年后，我发现幂回归更适合后者。四年后开发的算法 SM-8 才最终充分利用了这些想法。然而，我之所以提到它，主要是为了说明努力工作和高生产力作为对抗忧郁和抑郁症的良药何其有效。那时我发现情绪创伤的影响同样遵循昼夜节律。我会早上努力工作，但忧郁会在晚上慢慢回到我的脑海中。睡眠将是解放和最好的抗抑郁药。从那时起，我坚信睡眠和学习可以解决抑郁症的问题，但是，我从来没有真正有机会去研究它。如果我自己也受一点苦，那会有所帮助，但要么我有一些良好的韧性天赋，要么，更可能的是，我在艰难时期本能地使用了良好睡眠和高生产力作为治疗手段。自从 Sapolsky 称抑郁症为“世界上最严重的疾病”以来，我一直想找到预防抑郁症的公式。我感觉到有一个简单的公式。也许那种天真的童心般的乐观主义本身就是解决方案的一部分？

On Apr 13, 1991, we decided that SuperMemo 2 should be released as freeware. We hoped it might educate potential users abroad about the power of spaced repetition. However, initially, we had to send out diskettes with free SuperMemo at our own cost. Only in 1993, we uploaded SuperMemo to a local BBS called “Onkonet”. It would take some more years before we could upload future versions to Simtel and freeware sites. That freeware idea had an interesting side effect: by the end of the year, it was clear: people would start using the program and then give up. This was a hint of an inherent problem with spaced repetition: poor motivation resulting from poor skills would produce a high drop out rate. We also heard that others would try to sell SuperMemo 2 as if this was a commercial product.

1991年4月13日，我们决定将 SuperMemo 2作为免费软件发布。希望它可以向国外的潜在用户宣传间隔重复的强大功能。然而，最初，我们不得不自费寄出带有免费 SuperMemo 的软盘。直到1993年，我们才将 SuperMemo 上传到名为“Onkonet”的本地 BBS。又过了几年之后，我们才能将后续版本上传到 Simtel 和免费软件站点。这个免费软件的想法有一个有趣的副作用，到年底时已经很明显了：人们会使用该程序，然后放弃。这是间隔重复固有问题的一个暗示：由于（用户）技能不足导致的（用户使用）动力不足，最终以高流失率为结果。我们还听说其他人会尝试出售 SuperMemo 2，就好像这是一款商业产品一样。

On May 2, 1991, I implemented the option for setting the requested forgetting index in SuperMemo 6. On July 5, 1991, SuperMemo World was born. One of the first investment was a PC with a hard disk that would finally help me move away from the slow era of floppy disks.

1991年5月2日，我在 SuperMemo 6中实现了设置所需遗忘指数的功能。1991年7月5日，SuperMemo World 诞生了。第一笔投资之一是一台带有硬盘的PC，这将最终帮助我摆脱缓慢的软盘时代。

On Nov 23, 1991: SuperMemo was announced as the finalist of Software for Europe competition. This saved SuperMemo World.

1991年11月23日： SuperMemo 被宣布为“欧洲软件”竞赛的决赛入围者。这拯救了 SuperMemo World。

### SuperMemo 商业化的缓慢起步（Slow start of commercial SuperMemo）

When we set up SuperMemo World with Krzysztof Biedalak on Jul 5, 1991, the future looked so bright we needed to buy shades. The earth is populated with the highly intelligent population that all need to learn things. This whole population is our market. The only problem was how to convince all those smart people that two poor students educated behind the Iron Curtain got anything of value to offer. We could not have used the web for that job. SuperMemo is older than the web itself. We could not afford advertising for lack of capital. There was no venture capital culture in Poland in 1991. All we could do is put the first few copies of SuperMemo in file folders and place them on shelves of nearby computer shops. As we aimed at global domination, we did not even have a manual in Polish. Instead of first sales, we had a long summer of silence and creeping doubts.

1991年7月5日，当我和 Krzysztof Biedalak 成立 SuperMemo World 时，未来看起来如此光明，以至于我们需要戴上墨镜。地球上到处居住着高度智慧的人口，他们都需要学习东西。所有这些人口都是我们的市场。唯一的问题是如何说服所有这些聪明人，两个在铁幕后受过教育的贫穷学生能提供有价值的事物。我们不能用网络进行这项工作。SuperMemo 本身比网络还要古老。我们也负担不起广告费用，因为资金不足。1991年的波兰更没有风险投资文化。我们所能做的就是将前几份 SuperMemo 放入文件夹中，然后将它们放在附近计算机商店的货架上。由于我们的目标是全球销售，我们甚至没有波兰语手册。在首次销售之前，我们经历了一个漫长夏天的沉默，只有迷茫逐渐增长。

![[SuperMemo_The true history of spaced repetition_附件/SuperMemo-5-for-DOS-box.png]]

> ***Figure:** In 1991, we delivered the first copies of SuperMemo 5 for DOS to shops in Poznan (Poland) in pink folders with a sticker. The manual did not include a translation to Polish. Amazingly, we found a few buyers. The first sale took place some time between September 9 and 11, 1991 (computer shop Axe Prim)  
> <small>(reconstructed on the basis of original folders and stickers)</small>*
> 
> ***图**：1991年，我们将第一批 DOS 版 SuperMemo 5装在粉红色的文件夹中，并贴上标签，交付给波兹南（波兰）的商店。该手册不包含波兰语翻译。令人惊讶的是，我们找到了一些买家。第一次销售发生在1991年9月9日至11日之间（Axe Prim计算机商店）*
> <small>(根据原始文件夹和标签重建)</small>

Why was it hard to sell the first copy? I can reconstruct the scenario from the words of one of our first customers who actually visited a shop and had a look at the first SuperMemo displayed in public. On a shelf with computer programs, along with shiny boxes from Microsoft, he noticed a shabby folder with enticing words: ” ***Your breakthrough speed-learning software*** “. He picked up the folder and opened a manual, which was a stack of poorly xeroxed pages in English. With lofty words, he read a story that defied belief. It was all too good to be true. Faster learning, great retention, new scientific method, a little cost in time, etc. He did not contemplate an investment, the package was pretty costly (around $100, which was a lot in Poland 1991), however, he approached the salesperson to find out who the people behind SuperMemo were. The owner of the shop knew SuperMemo pretty well and explained. The story started looking credible. The customer never forgot the episode. A few months later, he heard of SuperMemo from some local journal and became one of the first paying customers. His registration coupon arrived in January 1992, and the history of his upgrades says he stayed with SuperMemo for decades and now his son is one of the regular customers.

为什么卖出第一份产品很难？我可以从我们的一位第一位客户的话中重建场景，他实实在在地参观了一家商店，并查看了公开展示的第一份 SuperMemo 。在摆放计算机程序的货架上，除了微软的闪亮盒子之外，他还注意到一个破旧的文件夹，上面写着诱人的字样：“***您的突破性快速学习软件***”。他拿起文件夹，打开了一本手册，那是一叠用复印机粗略复印的英文页面。然后他读到了一个用自信语言描绘的离奇故事。这一切简直太好了，好得令人不敢相信。更快的学习，更高的知识保留率，基于新的科学方法，花费时间很少，等等。他没有考虑直接付钱，这个软件包的价格非常高（在1991年的波兰，大约100美元不是个小数目），但是，他找到了销售人员想要了解 SuperMemo 背后的人是谁。商店的老板非常了解 SuperMemo 并进行了解释。这让整个故事开始变得可信。这位客户永远忘不了这件事。几个月后，他从一些当地杂志上听说了 SuperMemo ，并成为第一批付费客户。他的注册券于1992年1月被使用，升级历史表明他使用超级记忆已有数十年之久，现在他的儿子同样是固定用户。

However, back in summer 1991, we had no sales and by fall, everyone except for myself started having serious doubts. Not about SuperMemo, but about the viability of the business.

然而，在1991年夏天，我们没有达成任何销售。到秋天，除了我之外，每个人都开始产生严重的怀疑。不是关于超级记忆，而是关于业务的可行性。

It should help to know how we have met. With Biedalak, we were friends since forever. I attended a school with his brother, we lived 200 meters apart and qualified for the same year of computer science in university. I cannot say how I convinced Biedalak that SuperMemo is great. We have just been too close and he has always been in the circle. This part was easy. Tomek Kuehn was one of the first great believers in SuperMemo. He was also a great programmer, a great inspiration, and he grasped the idea instantly. He wrote two versions of SuperMemo himself: for Atari 800 in 1988, and for Atari ST in 1989. In January 1989, he even sold 10 copies of SuperMemo 2 using an advert in one of the computer journals: Komputer. I presume, he did not recover the invested money. Upon graduation, he already had his own business: a computer shop. This shop was also one of the first to present SuperMemo to its customers. His partner and friend was Marczello Georgiew who did not need much convincing either. Last but not least, I met Janusz Murakowski during GRE exams in Budapest in 1990. A great mathematical mind, he might be the fastest convert to SuperMemo ever. During our train trip back to Poland, I mentioned SuperMemo. He was instantly captivated. A few days later, he was already an enthusiastic user of SuperMemo 2 (as of Jun 13, 1990). In our company rap anthem, we sang ” *we are the guys who sell SuperMemo*“. It was very hard to convince people that SuperMemo works, but the guys on the team have always been enthusiastic.

了解我们是如何相遇的应该会有帮助。我和 Biedalak 从小就是朋友。我和他哥哥在同一所学校上学，我们的住处仅相距200米，并在同一年获得了进入大学计算机专业的资格。我很难说我是如何说服 Biedalak“SuperMemo 很棒”的。似乎只是因为我们走得太近了，他一直都在（我身边的）圈子里。于是这自然而然就发生了。Tomek Kuehn 是最早相信 SuperMemo 的人之一。他也是一位伟大的程序员，一个伟大的启发者，并且他立即理解了这个想法。他编写了两个他自己版本的 SuperMemo：1988年的 Atari 800和1989年的 Atari ST。在1989年1月，他甚至利用计算机杂志“Komputer”上的广告卖出了10份 SuperMemo 2。我猜这还不够他收回广告费。毕业后，他已经有了自己的生意：一家电脑商店。这家商店也是最早向客户展示 SuperMemo 的商店之一。他的合伙人兼朋友 Marczello Georgiew 也很容易就被说服了。最后一位成员同样关键，我在1990年在布达佩斯参加 GRE 考试时遇到了 Janusz Murakowski。作为一名伟大的数学家，他可能是 SuperMemo 有史以来最快的皈依者。在回波兰的火车旅行中，我提到了 SuperMemo 。他立刻被吸引了。几天后（1990年6月13日），他已经成为 SuperMemo 2的热情用户。在我们公司的说唱国歌中，我们唱道“*我们是销售 SuperMemo 的人*”。说服人们相信 SuperMemo 有效非常困难，但团队中的每个人一直都热情高涨。

By November 1991, the enthusiasm was thawing. If we continued without success, we would have gradually lost the team in proportion to their involvement and passion. With a few more months, the company might have died. SuperMemo would not have died. I would certainly look for a buyer, or continue one way or another. I was too tied to the product. I used it myself and all my knowledge was invested in my databases. I might have thought of returning to the idea of a PhD in the US. In the same way as I was able to combine work at the university in Holland in 1989 with programming “after hours”, I would probably continue until some breakthrough, e.g. on the web. Perhaps it would be an open source product? Luckily, Dr Wojciech Makałowski of the Department of Biolpolymer Biochemistry suggested we submit SuperMemo for Software for Europe competition. By some miraculous stroke of good luck, we qualified for the final and this was instantly noticed by the Polish media, esp. computer journals. As of that point, SuperMemo had an easy ride with the Polish press that became more and more intrigued. Andrzej Horodeński was first, and Pawel Wimmer was second and most faithful to this very day. Wimmer actually used SuperMemo 2, which he probably received from Tomasz Kuehn at the time of his KOMPUTER journal advert in 1989.

到1991年11月，热情开始消退。如果我们继续缺乏成功，我们将逐渐失去成员们的参与和热情，最终彻底失去团队。再过几个月，公司可能就会倒闭。SuperMemo 不会死。我肯定会继续寻找买家，或者以其他某种方式继续下去。我已经为这个产品付出了太多。我自己使用它，并且我的所有知识都投资在我的数据库中。我可能想过回到美国攻读博士学位。就像我在1989年能够将荷兰大学的工作与“下班后”的编程相结合一样。我可能会继续下去，直到取得一些突破，例如在网络上。也许它会是一个开源产品？幸运的是，聚合物生物化学系的 Wojciech Makałowski 博士建议我们将 SuperMemo 提交给欧洲软件竞赛。由于某种不可思议的好运，我们取得了决赛资格，这立即引起了波兰媒体，尤其是计算机期刊的注意。从那时起，超级记忆在波兰媒体上畅通无阻，引起了越来越多的兴趣。Andrzej Horodeński 是第一个，Pawel Wimmer 是第二个，并且至今仍最忠诚。实际上  Wimmer 真的用过 SuperMemo 2，他可能是通过1989年 Tomasz Kuehn 在 KOMPUTER 期刊上做的广告买了该软件。

1.5 years after its birth, SuperMemo World had finally become profitable. Not bad.

在诞生 1.5 年后， SuperMemo World 终于实现了盈利。真不错。

SuperMemo World was a fantastic set up from the getgo. We had no injection of venture capital in Poland in 1991, so we had to pull ourselves by our own bootstraps by selling, what others considered to be “snake oil”. We might have easily failed, but we survived by the sheer power of passion, belief, and a big stroke of good luck.

SuperMemo World 从一开始就是个了不起的创举。1991年，我们在波兰没法获得风险投资，因此我们不得不靠自己的力量，销售着其他人认为是“蛇油”的东西。我们很可能轻易失败，但我们凭借纯粹的热情、信念和巨大的运气而最终幸存下来。

### SM-6 算法的起源（Origins of Algorithm SM-6）

Algorithm SM-6 was first used in SuperMemo 6 (1991), however, it kept evolving in SuperMemo 7 (1992). There has never been the SM-7 version despite multiple changes. Most notably, as of 1994, the exponential function was used to approximate forgetting curves in SuperMemo 7 for Windows. OF matrix approximations have also been improved over time.

SM-6 算法最初用于 SuperMemo 6（1991年），但它在 SuperMemo 7（1992年）中不断发展。尽管进行了多次更改，但从未有过 SM-7 版本（*译注：前面提到过，SuperMemo 的算法随软件版本命名，由于 SuperMemo 7沿用了 SM-6 的算法，因此就不存在专门的 SM-7 算法了*）。最值得注意的是，从1994年开始，指数函数在Windows 版 SuperMemo 7中被用于给遗忘曲线做近似。OF 矩阵近似值也随着时间的推移而得到改进。

![[SuperMemo_The true history of spaced repetition_附件/Forgetting_curve_in_SuperMemo_7.png]]

> ***Figure:** SuperMemo 7 for Windows (1992) displaying a forgetting curve based on averages.*
> 
> ***图**：Windows 上的 SuperMemo 7(1992年) 显示基于平均值的遗忘曲线*。

![[Forgetting_curve_1994-1.png]]

> ***Figure:** SuperMemo 7 for Windows (1994) displaying a forgetting curve approximated with an exponential function. Vertical axis represents recall in percent. Horizontal axis corresponds with time represented by U-Factor*
> 
> ***图**：Windows 上的 SuperMemo 7（1994年）显示用指数函数近似的遗忘曲线。纵轴对应回忆率（百分比）。横轴对应以U因子表示的时间*。

The most important component of Algorithm SM-6 was to collect data on the rate of forgetting. Forgetting curves make it easy to accurately determine optimum intervals. This eliminated the need for a slow and inaccurate bang-bang approach of Algorithm SM-5:

算法 SM-6 最重要的组成部分是针对遗忘率的数据收集。遗忘曲线使得精准确定最佳复习间隔变得简单。这消除了算法 SM-5 中对缓慢且不准确的“开-关式”方法的需求。

（*注：起停式控制（bang-bang control），也称为砰砰控制、bang-bang控制、开关控制、继电器式控制或磁滞控制，是会让控制输出在两种状态之间切换的回授控制器，起停式控制会使控制输出在某个状态停留一段时间，再跳到另一个状态。起停式控制可以用有迟滞功能的元件实作。*）

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Economics_of_Learning" rel="noreferrer noopener" target="_blank">Economics of Learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1995)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Economics_of_Learning" rel="noreferrer noopener" target="_blank">学习经济学</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1995)撰写</small>

In Algorithm SM-5, the process of determining the value of a single entry of the matrix of optimal factors looked as follows (see before):

1.  Set the initial value to an average optimal factor value (OF) obtained in previous experiments
2.  If the grade produced by the entry in question was (1) greater than the desired value then increase the value of OF, (2) less than the desired value then decrease OF, or (3) equal the desired value then do not change OF

在算法SM-5中，确定最优因子矩阵中单个项目值的过程如下（见前文）：

1. 将初始值设置为先前实验中获得的平均最优因子值（OF）。
2. 如果该条目产生的成绩:
	1. 大于期望值，则增加 OF 的值；
	2. 小于期望值，则减少 OF 的值；
	3. 等于期望值，则不改变 OF。

The above approach shows that the optimum value of OF could be reached only after a great number of repetitions, and what is worst, the greater the ordinal number of a repetition, the longer it would take to execute the modification-verification cycle (i.e. the cycle in which an OF entry is changed, and verified upon scheduling another repetition with a correspondingly long interval).

使用上述方法，得到的结果显示，只有经过大量的重复，才能达到 OF 的最优值。更糟糕的是，重复的序数越大，执行修改-验证循环所需的时间就越长（修改-验证循环，即更改 OF 条目，并通过安排另一次间隔时长也（按重复序数）相应延长的重复来验证的循环）。

**引入遗忘指数的概念（Introducing the concept of the forgetting index）**

The novelty of Algorithm SM-6 is to approximate the slope of the forgetting curve corresponding to a given entry of the matrix of optimal factors, and compute the new value of the relevant optimal factor directly from the approximated curve. In other words, no modification-verification cycle is necessary in Algorithm SM-6 because of establishing the deterministic relationship between the forgetting curve and the optimum inter-repetition interval. The modification of the optimal factor occurs immediately after a repetition upon approximating the new forgetting curve derived from data that include the grade provided in the recent response. This modification not only made it possible to greatly accelerate the process of determining the optimum values of the matrix of optimal factors, but also provided a means for establishing the desired level of knowledge retention that will be reached in the course of the learning process (see an exemplary forgetting curve).

算法 SM-6 的新颖之处在于，它能够近似地估计（与最优因子矩阵中某一项的值相对应的）遗忘曲线的斜率，并直接从近似的曲线中计算相关最优因子的新值。换句话说，由于建立了遗忘曲线与最佳复习间隔之间的确定性关系，算法 SM-6 不需要修改-验证循环。在一次重复之后，根据最近一次回答中提供的成绩得出的新遗忘曲线后，立即就能对最优因子进行修改。这种修改不仅可以大大加快确定最优因子矩阵的最优值的过程，而且提供了一种方法来确定在学习过程中期望达到的知识保留水平（参见示例性遗忘曲线）。

The desired level of knowledge retention is determined by the proportion of items that are not remembered at repetitions. This proportion is called the forgetting index (items are classified as remembered or forgotten on the basis of grades provided by the student in self-assessment of his or her progress).

期望的知识保留水平由在重复时未记住的项目的比例决定。这个比例称为遗忘指数（根据学生对自己回忆的响应评分，将项目分为记住或遗忘）。

![[SuperMemo_The true history of spaced repetition_附件/Forgetting_curve_in_SuperMemo_8.jpg]]

> **Figure:** An exemplary forgetting curve plotted in the course of repetitions (over 40,000 repetition cases recorded).
> 
> **图：** 在重复过程中绘制的示例性遗忘曲线（根据超过40,000个被记录的重复案例绘制）。

In the figure presented above, the lapse of time is represented by the interval in days. The vertical axis represents knowledge retention stated as percentage. The horizontal line located at the retention level of 90% determines the requested forgetting index, i.e. the desired proportion of items that should be forgotten at the moment of repetition. The optimum interval will then naturally come at the cross-section of the requested forgetting index line with the forgetting curve. In the example above, the optimum interval equals seven days. The presented forgetting curve has been plotted on the basis of 40489 recorded repetition cases. See later in the text for explanation of the values R-Factor (RF), O-Factor (OF), etc.

在上述图中，横轴表示时间间隔，以天为单位表示。纵轴表示知识保留率，以百分比表示。90%保留率对应的水平线决定了理想的遗忘指数，即在重复时被遗忘的项目所占百分比的理想值。然后，最优间隔将自然地出现在理想的遗忘指数线与遗忘曲线的交点处。在上面的示例中，最优间隔等于七天。所呈现的遗忘曲线是根据记录的40489个重复案例绘制的。有关 R 因子（RF）、O 因子（OF）等值的解释，请参见后面的文本。

Because of the highly irregular nature of the matrix of optimal factors computed directly from forgetting curves, in Algorithm SM-6, the matrix used in spacing repetitions represents a smoothed version of the so-called matrix of retention factors (matrix RF), which is derived directly from forgetting curves corresponding to particular entries of the matrix OF. In other words, forgetting curves determine the value of entries of the matrix RF, and only the smoothed equivalent of the latter, the matrix OF is used in computing optimum intervals.

由于直接从遗忘曲线计算出的最优因子矩阵具有高度的不规则性，因此在算法 SM-6 中，用于计算重复间隔的矩阵换成了被称作“保留因子矩阵（矩阵 RF）”的矩阵的平滑版本，该矩阵直接根据矩阵 OF 中各项所对应的遗忘曲线得出。换句话说，遗忘曲线决定了矩阵 RF 中项目的值，并且仅有矩阵 OF （矩阵 RF 的等效平滑矩阵）被用于计算最优间隔。

### SM-6 算法（Algorithm SM-6）

The description of the algorithm below is taken with some clarifications from my PhD Thesis, and refers to the status quo for 1994:

以下对算法的描述摘自我的博士论文，并做了一些澄清，反映了1994年的状况：

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Economics_of_Learning" rel="noreferrer noopener" target="_blank">Economics of Learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1995)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Economics_of_Learning" rel="noreferrer noopener" target="_blank">学习经济学</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1995)撰写</small>

1.  The learned knowledge is split into smallest possible pieces called items
2.  Items are formulated in the question-answer form
3.  Items are memorized by means of a self-paced drop-out technique, i.e., by responding to the asked questions as long as it takes to provide all correct answers
4.  After memorizing an item, the first repetition is scheduled after an interval that is the same for all of the items. Its value is determined by the desired level of knowledge retention, which in turn can be converted into an interval by using an average forgetting curve taken from an average database of an average student ( Wozniak 1994a). The desired retention is specified by means of the so-called forgetting index, which corresponds to the proportion of items forgotten at repetitions (to learn how to compute retention from the forgetting index, and vice versa). Note, that the first interval may be randomly shortened or lengthened for the sake of speeding up the optimization process (varying intervals increase the accuracy of approximating the forgetting curve).
5.  The first interval is computed as for an average student and an average database. However, as soon as the recorded value of the forgetting index deviates from the requested level, the length of the first interval is modified accordingly. The new value of the interval is derived from the approximation of the negatively exponential forgetting curve plotted in the course of repetition. With each repetition score recorded, the plot becomes more and more accurate and the used value of the optimum inter-repetition interval settles at the point that ensures the selected level of knowledge retention. After each repetition, the student produces a grade, which determines the accuracy and easiness of reproducing the correct answer.
6.  On the basis of the grades, items are classified into difficulty categories. Their difficulty is reestimated in each successive repetition. The difficulty of each item is characterized by the earlier mentioned E-factors (E stands for “easiness”). E-factors are equal to 2.5 for all items on the entry to the learning process, and modified after subsequent repetitions. For example, grades above four result in slightly increasing the E-factor (good grades indicate easy items), while grades below four reduce the E-factor. Historically, E-factors were used to determine how many times intervals should increase in successive repetitions of items of a given difficulty. At present, E-factors are only used to index the matrices of optimal factors and retention factors, and may bear little relevance to the actual interval increase.
7.  Different optimal intervals are applied to items of different difficulty.
8.  Different intervals are applied to items that have been repeated a different number of times.
9.  The function of optimal intervals is constantly modified in order to produce the desired knowledge retention determined by the forgetting index. In other words, the algorithm will detect how well the student copes with repetitions and adjust the length of inter-repetition intervals accordingly.
10.  The function of optimal intervals is represented as the matrix of optimal factors, OF-matrix in short, defined as follows:for n=1: I(n,EF)=OF(n,EF)for n>1: I(n,EF)=I(n-1,EF)*OF(n,EF)where:
    -   I(n,EF) – n-th interval for difficulty EF
    -   OF(n,EF) – optimal factor for the n-th repetition and the difficulty EFThe entries of the matrix of optimal factors are modified in the course of repetitions to ensure the desired level of knowledge retention
11.  Matrix of optimal factors is produced by smoothing the so-called **matrix of retention factors**, RF matrix in short. Matrix of retention factors is defined in the same way as the matrix of optimal factors.
12.  Entries of the matrix of retention factors are intended to estimate the values of the entries of the matrix of optimal factors. Each optimal factor corresponds to an optimal interval that produces the desired retention at repetition (determined by the requested forgetting index). Each entry of the matrix of retention factors corresponds to a different value of E-factor and repetition number
13.  Entries of the matrix of retention factors, called **R-factors** , are computed from forgetting curves whose shape is sketched on the basis of the history of repetitions
14.  The lapse of time on the forgetting curve graph is measured by the so-called **U-factor** , which is the ratio of the current and the previous interval, except for the first repetition where U-factor equals the interval in days (as in Figure). The record of repetitions makes it possible to compute retention for different values of U-factor. The graph of the retention plotted versus the lapse of time (U-factor) represents a forgetting curve. The cross-section of the forgetting curve with the desired retention level determines the optimum R-factor, which, upon smoothing the matrix of retention factors, yields the optimum O-factor
15.  Each difficulty category and repetition number has its own record of repetitions used to sketch a separate forgetting curve. In other words, different intervals will be used for items of different difficulty, and for items repeated a different number of times.
16.  Intervals used in learning, including the first interval, are slightly dispersed round the optimal value in order to increase the accuracy of forgetting curve sketching, and consequently, to increase the convergence rate of the optimization procedure. By slightly dispersing intervals, the approximation of the forgetting curve will use a more scattered set of points on the graph

1. 学习的知识被拆分成最小的单元，称为“项目”。
2. 项目以“问题-答案”的形式呈现。
3. 通过“依据遗忘自我调节”的手段记忆项目，即在正确回答所有问题之前持续回答问题。
4. 记忆一个项目后，第一次复习的时间间隔对所有条目相同。其值由期望的知识保留水平决定，而期望的保留水平又可以通过使用根据普通学生的表现得到的平均遗忘曲线转换为时间间隔（Wozniak 1994a）。 期望的保留率由所谓的遗忘指数指定，该指数对应于在重复时遗忘的项目比例（学习如何从遗忘指数计算保留率，反之亦然）。 请注意，为了加快优化过程，第一个间隔可以随机缩短或延长（变化的间隔提高了近似遗忘曲线的准确性）。
5. 第一个间隔是根据普通学生的表现和平均数据库计算的。然而，一旦记录的遗忘指数值偏离了期望水平，第一个间隔的长度就会相应地修改。 新的间隔值源自对在重复过程中绘制的负指数遗忘曲线的近似。 随着越来越多次重复被记录，曲线变得越来越准确，并且使用的最佳重复间隔值稳定在确保所选知识保留率的点上。 每次重复后，学生都会进行一次评级（*译注：即前几代算法中的根据响应质量评分*），该评级以再现正确答案的准确性和容易程度为参照。
6. 根据评级，将项目分为不同的难度类别。它们的难度在每次后续重复中都会重新估计。 每个条目的难度由前面提到的 E 因子（E 代表“容易程度”）来表征。 学习过程开始时，所有项目的 E 因子都等于2.5，并在后续重复后进行修改。 例如，高于4的评分会导致 E 因子略微增加（好成绩表明项目容易），而低于4的评分会导致 E 因子降低。 在前几代算法中，E 因子用于确定给定难度项目的后续重复间隔应以多大幅度增长。 但目前，E 因子仅用于索引最优因子矩阵和保留因子矩阵，并且可能与间隔的实际增长幅度几乎无关。
7. 对不同难度的项目应用不同的最佳间隔。
8. 对已重复不同次数的项目应用不同的间隔。
9. 不断修改最佳间隔函数，以达到（由遗忘指数确定的）期望的知识保留率。换句话说，该算法将检测学生应对重复的表现，并相应地调整重复间隔的长度。
10. 最优间隔的函数表示为最优因子矩阵，简称 OF 矩阵，定义如下：
    - 对于n=1：I(n,EF)=OF(n,EF)
    - 对于n>1：I(n,EF)=I(n-1,EF)×OF(n,EF)，其中：
        - I(n,EF) – 难度为 EF 的第 n 次重复对应的间隔
        - OF(n,EF) – 难度为 EF 的第 n 次重复对应的最优因子，最优因子矩阵中的项目在重复过程中进行修改，以确保期望的知识保留水平。
11. 最优因子矩阵是通过平滑所谓的“保留因子矩阵”（简称 RF 矩阵）生成的。保留因子矩阵的定义与最优因子矩阵相同。
12. 保留因子矩阵的项目被用于估计最优因子矩阵的项目值。每个最优因子对应于在重复时产生期望保留率的最优间隔（由期望达到的遗忘指数确定）。 保留因子矩阵的每个项目对应于不同的 E 因子值和重复次数。
13. 保留因子矩阵中的项目，称为 R 因子，是根据按照重复历史绘制的遗忘曲线计算得出的。
14. 遗忘曲线图上的时间间隔由所谓的 U 因子测量，它是当前间隔与前一个间隔的比值（除了第一次重复，第一次重复的 U 因子等于天数（如图所示））。重复记录使得计算不同 U 因子值对应的保留率成为可能。 时间间隔（U 因子）-保留率关系对应图中展示了遗忘曲线。 遗忘曲线与期望保留率的交点决定了最优 R 因子，该因子在对保留因子矩阵平滑处理之后，产生最优 O 因子。
15. 每个难度类别和重复次数都有自己的重复记录，用于绘制单独的遗忘曲线。换句话说，将对不同难度以及不同重复次数的项目使用不同的间隔。
16. 用于学习的间隔，包括第一个间隔，在最优值周围略有分散，以提高遗忘曲线绘制的准确性，从而提高优化过程的收敛速度。通过稍微分散间隔，遗忘曲线的近似过程将使用在图上更分散的点集。

## 1994年：遗忘的指数性质（1994: Exponential nature of forgetting）

### 遗忘曲线：幂函数还是指数函数？（Forgetting curve: power or exponential）

The shape of the forgetting curve is vital for understanding memory. The math behind the curve may even weigh in on the understanding of the role of sleep (see later). When Ebbinghaus first determined the rate of forgetting, he got a pretty nice set of data with a good fit to the power function. However, today we know forgetting is exponential. The discrepancy is explained here.

遗忘曲线的形状对于理解记忆至关重要。曲线背后的数学原理甚至可能有助于理解睡眠的作用（详见后文）。 当艾宾浩斯首次确定遗忘率时，他获得了一组相当不错的数据，非常符合幂函数。然而，今天我们知道遗忘是指数性的。 本文将解释这种差异。

Forgetting curve adapted from Hermann Ebbinghaus (1885). The curve has been rendered from original tabular data published by Ebbinghaus (Piotr Wozniak, 2017)

遗忘曲线改编自赫尔曼·艾宾浩斯（Hermann Ebbinghaus） (1885)。该曲线是根据艾宾浩斯发表的原始表格数据绘制的（Piotr Wozniak，2017）。

### 错误的前期思考帮助了间隔重复诞生（Wrong thinking helped spaced repetition）

For many years, the actual shape of the curve did not play much of a role in spaced repetition. My early intuitions were all over the place depending on the context. Back in 1982, I was thinking that the evolution has designed forgetting for the brain to make sure we do not run out of memory space. The optimum time for forgetting would be determined by the statistical properties of the environment. Decay would be programmed to maximize survival. Once the review did not take place, the memory would get deleted to provide space for new learning.

多年来，曲线的实际形状在间隔重复中并没有发挥太大作用。我早期的直觉在各种不同背景的影响下非常混乱。早在1982年，我就认为进化已经为大脑设计了遗忘机制，以确保我们不会耗尽记忆空间。 遗忘的最佳时间将由环境的统计特性决定。 记忆衰减被编程至最大化适应生存的形态。 一旦没有进行复习，记忆就会被删除以腾出空间用于新的学习。

I was wrong thinking that there might be an optimum time for forgetting and this error was actually helpful for inventing spaced repetition. That “optimum time” intuition helped the first experiment in 1985. The optimum time for forgetting would imply sigmoidal forgetting curve with a clear inflection point that determines optimality. Before the review, forgetting would be minimal. A delayed review would result in rapid forgetting. This is why finding the optimum interval seemed so critical. When data started pouring in later on, with my confirmation bias, I still could not see my error. I wrote in my Master’s Thesis about sigmoidal forgetting: ” *this follows directly from the observation that before the elapse of the optimal interval, the number of memory lapses is negligible*“. I must have forgotten my own forgetting curve plot produced in late 1984.

我错误地认为可能存在遗忘的最佳时间，而这个错误实际上有助于发明间隔重复。 那个“最佳时间”的直觉帮助了1985年的第一次实验。 遗忘的最佳时间将意味着，遗忘曲线是具有明确拐点的S形，该拐点决定了最佳复习点。 在复习之前，遗忘将是最小的。 延迟复习会导致快速遗忘。 这就是为什么找到最佳间隔似乎如此关键。 当后来开始涌入数据时，由于我的先入为主，我仍然看不到自己的错误。 在我的硕士论文中，关于S型遗忘曲线，我写道：“_这直接来自以下观察：在最佳间隔过去之前，记忆缺失的数量可以忽略不计_”。 我一定忘记了我自己在1984年底制作的遗忘曲线图。

Today this seems preposterous, but even my model of intermittent learning provided some support for the theory. Exponential approximation yielded particularly high deviation error for data collected in my work on the model of intermittent learning, and the superposition of sigmoid curves for different E-Factors could easily mimic early linearity. Linear approximation seemed to excellently fit the model of intermittent learning within the recall range in the available data. No wonder, with whole pages of heterogeneous material, exponential nature of forgetting remained well hidden.

今天这似乎荒谬可笑，但即使是我间歇学习模型也为该理论提供了一些支持。 基于在我的间歇学习模型相关工作中收集的数据，指数近似产生了特别高的偏差误差，并且不同 E 因子的 S 形曲线的叠加可以很容易地模拟早期线性。 在收集到的数据范围内，线性近似似乎非常适合间歇学习模型。 这也难怪，由于原始数据的异质性，遗忘的指数性质仍然很好地隐藏着。

### 矛盾的模型（Contradictory models）

I did not ponder forgetting curves much. However, my biological model dating back to 1988 spoke of exponential decay in retrievability. Apparently, in those days, the forgetting curve and retrievability could exist in my head as independent entities.

我并没有过多地思考遗忘曲线。然而，我自1988年以来建立的生物学模型提到了可检索性呈指数衰减。显然，在那个时候，遗忘曲线和可检索性在我的脑海中还是作为相互独立的实体存在。

In my credit paper for a class in computer simulation (Dr Katulski, Jan 1988), my figures clearly show exponential forgetting curves:

在我1988年1月为卡图尔斯基博士（Dr Katulski）的计算机模拟课程撰写的论文中，我的图表清楚地显示了指数遗忘曲线：

![[SuperMemo_The true history of spaced repetition_附件/Hypothetical_mechanism_of_optimal_learning-1.jpg]]

> ***Figure:** Hypothetical mechanism involved in the process of optimal learning. (A) Molecular phenomena (B) Quantitative changes in the synapse.
> 
> ***图**： 最优学习过程中涉及的机制假设。（A）分子现象 （B）突触中的定量变化。*

By that time I might have picked the better idea from literature. In the years 1986-1987, I spent a lot of time in the university library looking for some good research on spaced repetition. I found none. I might have already been familiar with Ebbinghaus’s forgetting curve. It is mentioned in my Master’s Thesis.

在那之前，我可能已经从文献中了解到了更好的想法。在1986-1987年间，我在大学图书馆花费了大量时间寻找有关间隔重复的优秀研究，但一无所获。我可能已经熟悉艾宾浩斯的遗忘曲线，在我的硕士论文中对它有所提及。

### 收集数据（Collecting data）

I collected data for my first forgetting curve plot in late 1984. As all the learning was done for learning’s sake over the course of 11 months, and the cost of the graph was minimal, I forgot about that graph and it lay unused for 34 years in my archives:

我于1984年底收集了绘制第一条遗忘曲线所需的数据。由于在过去的11个月里，所有学习都是为了学习本身，并且绘制该图表的成本极低，我忘记了这个图表，它在我的档案中闲置了34年：

![[SuperMemo_The true history of spaced repetition_附件/Forgetting_curve_for_retention_1984.jpg]]

> ***Figure:** My very first forgetting curve for the retention of English vocabulary plotted back in 1984, i.e. a few months before designing SuperMemo on paper. This graph was not part of the experiment. It was simply a cumulative assessment of the results of intermittent learning of English vocabulary. The graph was soon forgotten. It was re-discovered 34 years later. After memorization, 49 pages of ~40 word pairs of English were reviewed at different intervals and the number of recall errors was recorded. After rejecting outliers and averaging, the curve appears to be far less steep that the curve obtained by Ebbinghaus (1885), in which he used nonsense syllables and a different measure of forgetting: saving on re-learning*
> 
> ***图：** 我于1984年（即在纸上设计 SuperMemo 之前的几个月）绘制的第一条英语词汇记忆遗忘曲线。该图不是实验的一部分，而只是对英语词汇间歇学习结果的累积评估。很快，我就忘记了这张图。34年后，它被重新发现。记忆后，对49页左右的约40个英语单词对进行了不同间隔的复习，并记录了回忆错误的数量。在剔除异常值并取平均值后，该曲线似乎比艾宾浩斯（1885年）使用无意义音节和不同遗忘程度衡量标准（再学习节省量）得到的曲线平缓得多*。

My 1985 experiment could also be considered as a noisy attempt to collect forgetting curve data. However, first SuperMemos did not care about the forgetting curve. The optimization was bang-bang in nature, even though today, collecting retention data seems such an obvious solution (as in 1985).

我的1985年实验也可以被视为收集遗忘曲线数据的粗略尝试。然而，早期的 SuperMemo 并不关心遗忘曲线。优化本质上是“开-关”式的，即使在今天看来，收集保留率数据似乎是一个显而易见的解决方案（就像1985年一样）。

（*注：起停式控制（bang-bang control），也称为砰砰控制、bang-bang控制、开关控制、继电器式控制或磁滞控制，是会让控制输出在两种状态之间切换的回授控制器，起停式控制会使控制输出在某个状态停留一段时间，再跳到另一个状态。起停式控制可以用有迟滞功能的元件实作。*）

Until I started collecting data with SuperMemo software, where each item could be scrutinized independently, I could not fully recover from early erroneous notions about forgetting.

直到我开始使用 SuperMemo 软件收集数据，其中每个项目都可以独立审查，我才能够完全摆脱早期关于遗忘的错误观念。

SuperMemo 1 for DOS (1987) collected full repetition histories that would make it possible to determine the nature of forgetting. However, within 10 days (on Dec 23, 1987), I had to ditch the full record of repetitions. At that time, my disk space was 360KB. That’s correct. I would run SuperMemo from old type 5.25in diskettes. Full repetition history record returned to SuperMemo only 8 long years later (Feb 15, 1996) after the hectic effort from Dr Janusz Murakowski who considered every ticking minute a waste of valuable data that could power future algorithms and memory research. Two decades later, we have more data that we can effectively process.

DOS 上的 SuperMemo 1（1987年）收集了完整的重复历史记录，这使得确定遗忘的性质成为可能。然而，在10天之内（1987年12月23日），我不得不放弃完整的重复记录。当时，我的磁盘空间只有360 KB。没错，我用老式的5.25英寸软盘运行 SuperMemo。完整的重复历史记录直到8年后的1996年2月15日才重新回到 SuperMemo中，这要归功于 Janusz Murakowski 博士的不懈努力，他认为每一秒的数据缺失都是对未来算法和记忆研究的高价值材料的浪费。二十年后，我们拥有了更多可以有效处理的数据。

Without repetition history, I could still investigate forgetting with a help of the forgetting curve data collected independently. On Jan 6, 1991, I figured out how to record forgetting curves in a small file that would not bloat the size of the database (i.e. without the full record of repetition history).

即使没有重复历史记录，我仍然可以借助独立收集的遗忘曲线数据来研究遗忘。1991年1月6日，我想出了如何在一个小文件中记录遗忘曲线，而不会使数据库的大小膨胀（即不保存完整的重复历史记录）。

Only SuperMemo 6 then, in 1991, started collecting forgetting curve data to determine optimum intervals. It was doing the same thing as my first experiment, except it did it automatically, on a massive scale, and for memories separated into individual questions (this solved the heterogeneity problem). SuperMemo 6 initially used a binary chop to find the best moment corresponding with the forgetting index. A good fit approximation was still 3 years into the future.

直到1991年的 SuperMemo 6，我们才开始收集遗忘曲线数据来确定最佳间隔。它所做的事情与我的第一个实验相同，只是现在的实验自动进行，规模更大，并且将记忆分割到单个问题（这解决了研究材料的异质性问题）。SuperMemo 6最初使用二分法来查找与遗忘指数相对应的最佳时刻。一个很好的近似拟合方案还需要3年的时间才能实现。

### 最早的遗忘曲线数据（First forgetting curve data）

By May 1991, I had some first data to peek at, and this was a major disappointment. I predicted I would need a year to see any regularity. However, every couple of months, I kept noting down my disappointment with minimum progress. The progress in collecting data was agonizingly slow and the wait was excruciating. A year later, I was no closer to the goal. If Ebbinghaus was able to plot a good curve with nonsense syllables, his pain of non-coherence must have been worth it. With meaningful data, the truth was very slow to emerge. Even with the convenience of having it all done by a computer while having fun with learning.

到1991年5月，我才有了第一批可以观察的数据，这让我非常失望。我预计需要一年的时间才能看到任何规律。然而，每隔几个月，我都会注意到自己对进展缓慢的失望。收集数据的进展缓慢得令人痛苦，等待的过程也令人难以忍受。一年后，我离目标仍然遥遥无期。如果艾宾浩斯能够用无意义音节（的记忆过程）绘制出一条良好的曲线，那么他所承受的不连贯性的痛苦一定是有价值的。对于有意义的数据，真相的出现非常缓慢。即使这一切都能由计算机方便地完成，并且学习过程也不乏乐趣，等待的难熬依然不减。

On Sep 3, 1992, SuperMemo 7 for Windows made it possible to have a first nice peek at a real forgetting curve. The view was mesmerizing:

1992年9月3日，Windows 上的 SuperMemo 7的问世让我们得以首次近距离观察真实的遗忘曲线。这一景象令人着迷：

![[SuperMemo_The true history of spaced repetition_附件/Forgetting_curve_in_SuperMemo_7-1.png]]

> ***Figure:** SuperMemo 7 for Windows was written in 1992. As of Sep 03, 1992, it was able to display user’s forgetting curve graph. The horizontal axis labeled U-Factor corresponded with days in this particular graph. The kinks between days 14 and 20 were one of the reasons it was difficult to determine the nature of forgetting. Old erroneous hypotheses were hard to falsify. Until the day 13, forgetting seemed nearly linear and might also provide a good exponential fit. It took two more years of data collecting to find answers (source: SuperMemo 7: User’s Guide)*
> 
> ***图：** Windows 上的 SuperMemo 7 于1992年编写完成。在1992年9月3日，该软件已经能够显示用户的遗忘曲线图。在这个特定的图表中，横轴标注为“U-因子”，对应于天数。14天到20天之间曲线的转折点是难以确定遗忘性质的原因之一。旧有的错误假设难以证伪。在第13天之前，遗忘似乎近乎线性，也可能具有良好的指数拟合。需要再收集两年的数据才能找到答案（来源：SuperMemo 7：用户指南）*

### 遗忘曲线的近似估计（Forgetting curve approximations）

By 1994, I still was not sure about the nature of forgetting. I took data collected in the previous 3 years (1991-1994) and set out to figure out the curve once and for all. I focused on my own data from over 200,000 repetitions. However, it was not easy. If SuperMemo schedules a repetition at R=0.9, you can draw a straight line from R=1.0 to R=0.9 and do great with noisy data:

到1994年，我对遗忘的本质仍然不确定。我使用了之前三年（1991-1994年）收集的数据，决心彻底弄清楚这条曲线。我重点关注了自己超过20万次复习的数据。然而，这并不容易。如果 SuperMemo 将复习间隔安排在 R=0.9，你可以从 R=1.0 画一条直线到 R=0.9（*译注：即用线性拟合*），并且在数据有干扰的情况下仍然取得很好的效果：

![[SuperMemo_The true history of spaced repetition_附件/Forgetting_curve_approximation_difficulty.png]]

> ***Figure:** Difficulty approximating forgetting curve. Back in 1994, it was difficult to understand the nature of forgetting in SuperMemo because most of the data used to be collected in high recall range.*
> 
> ***图：** 近似估计遗忘曲线时遭遇的困难。早在1994年，由于大多数数据都是在高回忆率范围内收集的，因此难以理解SuperMemo中的遗忘性质。

My notes from May 6, 1994 illustrate the degree of uncertainty:

我在1994年5月6日的笔记中描述了这种不确定性的程度。

Personal anecdote. Why use anecdotes?

下面是个人轶事。

May 6, 1994: *All day of crazy attempts to better approximate forgetting curves. First I tried R=1-i <sub>n</sub>/(H <sub>n</sub>+i <sub>n</sub>) where i – interval, H – memory half-life, and n – cooperativity factor. Late in the evening, I had it work quite slowly, but … it appeared that r=exp(-a×i) works not much worse! Even the old linear approximation was not very much worse (sigmoid: D=8.6%, exponential D=8.8%, and linear D=10.8%). Perhaps, forgetting curves are indeed exponential? Going to sleep at 2:50*

1994年5月6日：*整天都在疯狂尝试更好地近似遗忘曲线。首先，我尝试了R=1-i <sub>n</sub>/(H <sub>n</sub>+i <sub>n</sub>) 的公式，其中 i 代表间隔，H 代表记忆半衰期，n 代表协同因子。深夜时分，我发现这个公式运行得相当缓慢，但是……似乎 r=exp(-a×i) 的效果也并没有比它差多少！甚至古老的线性近似也并没有差太多（S 型曲线：D=8.6%，指数曲线：D=8.8%，线性曲线：D=10.8%）。也许，遗忘曲线确实是指数性的？凌晨2:50睡觉*

It was not easy to separate linear, power, exponential, Zipf, Hill, and other functions. Exponential, power and even linear approximations brought pretty good outcomes depending on circumstances that were hard to separate. Only when looking at forgetting curves well sorted for complexity at higher levels of stability, despite those graphs being data poor, could I see the exponential nature of forgetting more clearly.

很难将线性函数、幂函数、指数函数、齐普夫分布、希尔函数和其他函数区分开来。由于难以区分的情况，指数、幂函数甚至线性近似都呈现出相当不错的结果。只有当遗忘曲线在更高的稳定性水平上按复杂性进行良好排序后，再行进观察时，我才能更清楚地看到遗忘的指数性质（尽管这些图表数据较少）。

One of the red herrings in 1994 was that, naturally, I had most data collected for the first review. New items at the entry to the process still provide a heterogeneous group that obeys the power law of forgetting.

1994年的一个误导因素是，我想当然地收集了大部分第一次复习的数据并用于分析。刚进入学习过程的新项目（从它们所遵循的遗忘的幂律来看）仍然是一个异质群体。

The first review forgetting curve for newly learned knowledge collected with SuperMemo.

使用 SuperMemo 收集的新知识第一次学习后的遗忘曲线。

Later on, when they are sorted by complexity and stability, they start becoming exponential. In Algorithm SM-6, complexity and stability were imperfectly expressed by E-Factors and repetition number respectively. This resulted in algorithmic imperfections that made for imperfect sorting. In addition, SuperMemo stays within the area of high retention when forgetting is nearly linear.

随后，当它们（遗忘曲线数据）按复杂性和稳定性被分类后，（遗忘曲线）开始呈现指数性。在算法 SM-6 中，复杂性和稳定性分别由 E-因子和重复次数不完美地表达。这导致了算法的缺陷，从而导致了不完美的分类。此外，当遗忘近似线性时，SuperMemo 保持在高保留率范围内。

By May 1994, the main first-review curve in my Advanced English database collected 18,000 data points and seemed like the best analytical material. However, that curve encompasses all the learning material that enters the process independent of its difficulty. Little did I know that this curve is covered by the power law. My best deviation was 2.0.

到1994年5月，我高级英语数据库中的主要第一次复习曲线已经收集了18,000个数据点，这看起来似乎是最理想的分析材料。然而，这条曲线涵盖了进入学习过程的所有学习材料，而没有按难度分类。当时我并不知道这条曲线遵循幂律。我的最佳偏差值为2.0。

For a similar curve from 2018 see:

在2018年也有类似的曲线，请看：

![[SuperMemo_The true history of spaced repetition_附件/400px-Forgetting_curve_A-Factor3.9.png.png]]

> ***Figure:** Forgetting curve obtained in 2018 with SuperMemo 17 for average difficulty (A-Factor=3.9). At 19,315 repetitions and least squares deviation of 2.319, it is pretty similar to the curve from 1994, except it is best approximated with an exponential function (for the power function example see: forgetting curve).*
> ***图：** 使用 SuperMemo 17在2018年获得的平均难度（A-因子=3.9）的遗忘曲线。在19,315次复习和最小二乘偏差为2.319的情况下，它与1994年的曲线非常相似，只是用指数函数来近似的结果最佳（有关幂函数示例，请参见：遗忘曲线）*

### 指数遗忘占主导地位（Exponential forgetting prevails）

By summer 1994, I was reasonably sure of the exponential nature of forgetting. By 1995, we published “2 components of memory” with the formula R=exp(-t/S). Our publication remains largely ignored by mainstream science but is all over the web when forgetting curves are discussed.

到1994年夏天，我对于遗忘的指数性质已经相当确信。1995年，我们发表了“记忆的两个组成部分”，并附上了公式 R=exp(-t/S)。我们的出版物在主流科学界基本上被忽视，但在遗忘曲线相关的讨论中却遍布全网。

Interestingly, in 1966, Nobel Prize winner Herbert Simon had a peek at Jost’s Law derived from Ebbinghaus work in 1897. Simon noticed that the exponential nature of forgetting necessitates the existence of a memory property that today we call memory stability. Simon wrote a short paper and moved on to hundreds of other projects he was busy with. His text was largely forgotten, however, it was prophetic. In 1988, similar reasoning led to the idea of the two component model of long-term memory.

有趣的是，1966年，诺贝尔奖得主赫伯特·西蒙（Herbert Simon）瞥了一眼1897年艾宾浩斯（Ebbinghaus）的工作得出的乔斯特定律（Jost's Law）。西蒙注意到，遗忘的指数性质指出必然存在一种记忆属性，今天我们称之为记忆稳定性。西蒙写了一篇短文，然后转向了他忙碌的其他数百个项目。然而，他的文字在很大程度上被遗忘了，但它是具有预见性的。1988年，类似的推理成为了“长期记忆的二元模型”的灵感来源。

Today we can add one more implication: If forgetting is exponential, it implies a constant probability of forgetting in unit time, which implies neural network interference, which implies that sleep might build stability not by strengthening memories, but by simply removing the cause of interference: unnecessary synapses. Giulio Tononi might then be right about the net loss of synapses in sleep. However, he believes that loss is homeostatic. Exponential forgetting indicates that this could be much more. It might be a form of ” intelligent forgetting” of things that interfere with key memories reinforced in waking.

今天，我们可以再多添加一个含义：如果遗忘是指数性的，则意味着单位时间内遗忘的概率是恒定的，从而意味着神经网络中存在干扰，从而意味着睡眠可能不是通过加强记忆来建立稳定性，而仅仅是消除了干扰的来源：不必要的神经突触。朱利奥·托诺尼（Giulio Tononi）提出的睡眠中突触的净损失可能是正确的。只不过，他认为这种损失是稳态的。而指数遗忘则表明损失实际上可能多得多。这可能像是一种“智能遗忘”，即在睡眠中清除那些对重要记忆造成干扰的内容。

### 负指数遗忘曲线（Negatively exponential forgetting curve）

Only in 2005, we wrote more extensively about the exponential nature of forgetting. In a paper presented by Dr Gorzelańczyk in a modelling conference in Poland, we wrote:

直到2005年，我们才更广泛地撰写了关于遗忘的指数性质的文章。在波兰的一次建模会议上，由 Gorzelańczyk 博士发表了一篇论文，其中写道：

Archive warning: Why use literal archives?

Although it has always been suspected that forgetting is exponential in nature, proving this fact has never been simple. Exponential decay appears standardly in biological and physical systems from radioactive decay to drying wood. It occurs anywhere where expected decay rate is proportional to the size of the sample, and where the probability of a single particle decay is constant. The following problems have hampered the effort of modeling forgetting since the years of Ebbinghaus (Ebbinghaus, 1885):

-   small sample size
-   sample heterogeneity
-   confusion between forgetting curves, re-learning curves, practise curves, savings curves, trials to learn curves, error curves, and others in the family of learning curves

尽管一直以来人们都怀疑遗忘的本质是指数性的，但证明这一事实从未简单过。从放射性衰变到木材干燥，指数衰减似乎在生物和物理系统中普遍存在。它发生在任何预期衰减率与样本大小成比例且单个粒子衰减概率恒定的情况下。自艾宾浩斯（Ebbinghaus，1885）时代以来，以下问题阻碍了给遗忘过程建模的努力：

- 样本量小
- 样本异质性
- 遗忘曲线、再学习曲线、练习曲线、节省曲线、学习试验曲线、错误曲线和其他学习曲线家族成员之间的混淆

By employing SuperMemo, we can overcome all these obstacles to study the nature of memory decay. As a popular commercial application, SuperMemo provides virtually unlimited access to huge bodies of data collected from students all over the world. The forgetting curve graphs available to every user of the program ( **Tools : Statistics : Analysis : Forgetting curves**) are plotted on relatively homogenous data samples and are a bona fide reflection of memory decay in time (as opposed to other forms of learning curves). The quest for heterogeneity significantly affects the sample size though. It is important to note that the forgetting curves for material with different memory stability and different knowledge difficulty differ. Whereas memory stability affects the decay rate, heterogeneous learning material produces a superposition of individual forgetting curves, each characterized by a different decay rate. Consequently, even in bodies with hundreds of thousands of individual pieces of information participating in the learning process, only relatively small homogeneous samples of data can be filtered out. These samples rarely exceed several thousands of repetition cases. Even then, these bodies of data go far beyond sample quality available to researchers studying the properties of memory in controlled conditions. Yet the stochastic nature of forgetting still makes it hard to make an ultimate stand on the mathematical nature of the decay function (see two examples below). Having analyzed several hundred thousand samples we have come closest yet to show that the forgetting is a form of exponential decay.

通过使用 SuperMemo，我们可以克服所有这些障碍来研究记忆衰减的性质。作为一款流行的商业应用，SuperMemo 几乎可以无限制地访问从世界各地的学生那里收集到的海量数据。该程序每个用户都可以访问自己的遗忘曲线图表（**工具：统计：分析：遗忘曲线**），图表由相对同质的数据样本绘制而来，真实地反映了记忆随时间的衰减的过程（与其他形式的学习曲线相反）。然而，对去除异质性的追求会显着影响样本大小。需要注意的是，具有不同记忆稳定性和不同知识难度的材料的遗忘曲线是不同的。记忆稳定性影响衰减率，而异质性学习材料会产生单个遗忘曲线的叠加，每个曲线具有不同的衰减率。因此，即使在学习过程中的信息数量达到数十万个的庞大数据集中，也只有相对较小的同质数据样本可以被筛选出来。这些样本很少超过几千个重复案例。即使如此，这些数据集的质量也远远超出了在受控条件下研究记忆特性的研究人员可获得的样本质量。然而，遗忘的随机性仍然使得对衰减函数的数学性质做出最终结论颇为困难（参见以下两个示例）。在分析了几十万个样本后，我们距离证明遗忘是以指数形式衰减已经前所未有地接近。

![[SuperMemo_The true history of spaced repetition_附件/Exemplary_forgetting_curve_1.jpg]]

> ***Figure:** Exemplary forgetting curve sketched by SuperMemo. The database sample of nearly a million repetition cases has been sifted for average difficulty and low stability (A-Factor=3.9, S in [4,20]), resulting in 5850 repetition cases (less than 1% of the entire sample). The red line is a result of regression analysis with R=e <sup>-kt/S</sup>. Curve fitting with other elementary functions demonstrates that the exponential decay provides the best match to the data. The measure of time used in the graph is the so-called U-Factor defined as the quotient of the present and the previous inter-repetition interval. Note that the exponential decay in the range of R from 1 to 0.9 can plausibly be approximated with a straight line, which would not be the case had the decay been characterized by a power function.
> 
> ***图示**： SuperMemo 绘制的遗忘曲线示例。该数据库样本包含近百万个重复案例，从中筛选出平均难度和稳定性较低的案例（A-因子=3.9，S 值在[4,20]范围内），共计5850个重复案例（不到整个样本的1%）。红线是回归分析的结果，其方程为 R=e <sup>-kt/S</sup>。与其他基本函数进行曲线拟合的结果表明，指数衰减曲线与数据最匹配。图中使用的时间测量单位为 U-因子，其定义为当前重复间隔与上轮重复间隔的比值。需要注意的是，在 R 值位于1到0.9的区间内时，指数衰减曲线可以合理地近似为一条直线，而如果衰减曲线由幂函数表征，则不会出现这种情况*。

![[SuperMemo_The true history of spaced repetition_附件/Exemplary_forgetting_curve_2.jpg]]

> ***Figure:** Exemplary forgetting curve sketched by SuperMemo. The database sample of nearly a million repetition cases has been sifted for average difficulty and medium stability (A-Factor=3.3, S > 1 year) resulting in 1082 repetition cases. The red line is a result of regression analysis with R=e <sup>-kt/S</sup>.*
> 
> ***图示：** SuperMemo 绘制的遗忘曲线示例。该数据库样本包含近百万个重复案例，从中筛选出平均难度和中等稳定性（A-因子=3.3，S>1年）的案例，共计1082个。红线是回归分析的结果，其方程为 R=e <sup>-kt/S</sup>*。

### 遗忘曲线：可检索性公式（Forgetting curve: Retrievability formula）

In Algorithm SM-17, retrievability R corresponds with the probability of recall and represents the exponential forgetting curve. Retrievability is derived from stability and the interval:

在算法 SM-17 中，可检索性 R 对应于回忆成功的概率，并代表指数遗忘曲线。可提取性由稳定性和间隔时长推导而来：

R[n] :=exp <sup>-k*t/S[n-1]</sup>

where:

-   R[n] – retrievability at the n-th repetition
-   k – decay constant
-   t – time (interval)
-   S[n-1] – stability after the (n-1)th repetition

R[n] :=exp <sup>-k*t/S[n-1]</sup>

其中：

- R[n] – 第n次重复时的可检索性
- k – 衰减常数
- t – 时间（重复间隔）
- S[n-1] – 第(n-1)次重复后的稳定性

That neat theoretical approach is made a bit more complex when we consider that forgetting may not be perfectly exponential if items are difficult or with mixed difficulty. In addition, forgetting curves in SuperMemo can be marred by user strategies.

在项目难度较大或难度混合的情况下，因为遗忘可能不是完全呈指数型，这一（关于可检索性的）简洁的公式可能会变得更加复杂。此外，SuperMemo 中的遗忘曲线可能会受到用户策略的影响。

In Algorithm SM-8, we hoped that retrievability information might be derived from grades. This turned out to be false. There is very little correlation between grades and retrievability, and it primarily comes from the fact that complex items get worse grades and tend to be forgotten faster (at least at the beginning).

在算法SM-8中，我们希望能够从（响应）评分中推导出可提取性信息。结果证明这是错误的。评分与可提取性之间几乎没有相关性，主要原因是复杂项目的（响应）评分往往较低，并且更容易被遗忘（至少在开始时是如此）。

### 保留率 vs. 遗忘指数（Retention vs. the forgetting index）

Exponential nature of forgetting implies that the relationship between the measured forgetting index and knowledge retention can accurately be expressed using the following formula:

遗忘的指数特性意味着，测量到的遗忘指数与知识保留率之间的关系可以用以下公式准确地表示：

Retention = -FI/ln(1-FI)

where:

-   Retention – overall knowledge retention expressed as a fraction (0..1),
-   FI – forgetting index expressed as a fraction (forgetting index equals 1 minus knowledge retention at repetitions).

保留率 = -FI/ln(1-FI)

其中：

- 保留率 – 总体知识保留率，以小数表示（0..1），
- FI – 遗忘指数，以小数表示（遗忘指数等于1减去重复时的知识保留率）。

For example, by default, well-executed spaced repetition should result in retention 0.949 (i.e. 94.9%) for the forgetting index of 0.1 (i.e. 10%). 94.9% illustrates how much exponential decay resembles a linear function at first. For linear forgetting, the figure would be 95.000% (i.e. 100% minus half the forgetting index).

例如，默认情况下，良好执行的间隔重复应该在遗忘指数为0.1（即10%）的情况下产生94.9%（即0.949）的保留率。94.9%说明了指数衰减在最初阶段与线性函数有多相似。在线性遗忘的情况下，该数值将为95.000%（即100%减去遗忘指数的一半）。

### 复杂（内容难度不一致的）材料的遗忘曲线（Forgetting curve for poorly formulated material）

In 1994, I was lucky my databases were largely well-formulated. This often wasn’t the case with users of SuperMemo. For badly-formulated items, the forgetting curve is flattened. It is not purely exponential (as superposition of several exponential curves). SuperMemo can never predict the moment of forgetting of a single item. Forgetting is a stochastic process and can only operate on averages. A frequently propagated fallacy about SuperMemo is that it predicts the exact moment of forgetting: this is not true, and this is not possible. What SuperMemo does is a search for intervals at which items of given difficulty are likely to show a given probability of forgetting (e.g. 10%). Those flattened forgetting curves led to a paradox. Neglecting complex items may lead to a great survival after long breaks from review. Even for a pure negatively exponential forgetting curve, a 10-fold deviation in interval estimation will result in R2=exp <sup>10*ln(R1)</sup> difference in retention. This is equivalent to a drop from 98% to 81%. For a flattened forgetting curve typical of badly-formulated items, this drop may be as little as 98%->95%. This leads to a conclusion that keeping complex material at lower priorities is a good learning strategy.

我很幸运，1994年时，我的数据库大部分都编排得很好。但对于 SuperMemo 的用户来说，情况往往并非如此。对于编排糟糕的项目，遗忘曲线会变得平缓。它不是纯粹的指数型（而是多个指数曲线的叠加）。SuperMemo 永远无法预测单个项目在何时被遗忘。遗忘是一个随机过程，只能对平均值进行操作。关 于 SuperMemo 的一个常见的谬误是它可以预测确切的遗忘时刻：这是不正确的，也是不可能的。SuperMemo 所做的是判断项目在给定难度下，被遗忘概率为特定值（例如10%）时所对应的预期间隔。这些平坦的遗忘曲线导致了一个悖论。忽视复杂项目可能会在长时间不复习后导致较高的回忆成功率。即使对于纯负指数遗忘曲线，间隔估计的10倍偏差将导致 R2=exp <sup>10*ln(R1)</sup> 的保留率差异。这相当于从98%下降到81%。对于编排糟糕的项目所具有的平坦遗忘曲线，这种下降可能仅为98%->95%。这得出一个结论：将复杂材料保持在较低的优先级是一种良好的学习策略。

### 指数遗忘曲线的叠加产生幂律（Power law emerges in superposition of exponential forgetting curves）

To illustrate the importance of homogenous samples in studying forgetting curves, let us see the effect of mixing difficult knowledge with easy knowledge on the shape of the forgetting curve. The figure below shows why heterogeneous samples may lead to wrong conclusions about the nature of forgetting. The heterogeneous sample in this demonstration is best approximated with a power function! The fact that power curves emerge through averaging of exponential forgetting curves has earlier been reported by others (Anderson&Tweney 1997; Ritter&Schooler, 2002).

为了说明在研究遗忘曲线时采用同质样本的重要性，让我们看看将困难知识与简单知识混合对遗忘曲线形状的影响。下图显示了为什么异质样本可能导致关于遗忘性质的错误结论。在本演示中，异质样本用幂函数近似的结果最佳！指数遗忘曲线的平均化产生幂曲线这一事实已由其他人早先报道（Anderson&Tweney 1997; Ritter&Schooler, 2002）。

![[SuperMemo_The true history of spaced repetition_附件/Heterogenous_forgetting_index-1.gif]]

> ***Figure:** Superposition of forgetting curves may result in obscuring the exponential nature of forgetting. A theoretical sample of two types of memory traces has been composed: 50% of the traces in the sample with stability S=1 (thin yellow line) and 50% of the traces in the sample with stability S=40 (thin violet line). The superimposed forgetting curve will, naturally, exhibit retrievability R=0.5*Ra+0.5*Rb=0.5*(e <sup>-k*t</sup>+e <sup>-k*t/40</sup>). The forgetting curve of such a composite sample is shown in granular black in the graph. The thick blue line shows the exponential approximation (R2=0.895), and the thick red line shows the power approximation of the same curve (R2=0.974). In this case, it is the power function that provides the best match to data, even though the forgetting of sample subsets is negatively exponential.*
> 
>***图：** 遗忘曲线的叠加可能会掩盖遗忘的指数特性。图中的示例由两种类型的记忆痕迹组成：其中，50%的痕迹稳定性S=1（细黄色线），50%的痕迹稳定性S=40（细紫色线）。自然情况下，叠加后的遗忘曲线的可提取性R=0.5Ra+0.5Rb=0.5×(e <sup>-k×t</sup>+e <sup>-k×t/40</sup>)。这种叠加后本的遗忘曲线在图中以黑色颗粒状曲线显示。粗蓝线为通过指数函数与复合曲线近似的曲线（R2=0.895），粗红线为通过幂函数与复合曲线近似的曲线（R2=0.974）。在这种情况下，尽管样本子集的遗忘呈负指数型，但幂函数与数据反而最匹配。*

![[SuperMemo_The true history of spaced repetition_附件/Forgettingcurve.jpg]]

> ***Figure:** The first review forgetting curve for newly learned knowledge collected with SuperMemo. Power approximation is used in this case due to the heterogeneity of the learning material freshly introduced in the learning process. Lack of separation by memory complexity results in superposition of exponential forgetting with different decay constants. On a semi-log graph, the power regression curve is logarithmic (in yellow), and appearing almost straight. The curve shows that in the presented case recall drops merely to 58% in four years, which can be explained by a high reuse of memorized knowledge in real life. The first optimum interval for review at retrievability of 90% is 3.96 days. The forgetting curve can be described with the formula R=0.9907*power(interval,-0.07), where 0.9907 is the recall after one day, while -0.07 is the decay constant. In this is case, the formula yields 90% recall after 4 days. 80,399 repetition cases were used to plot the presented graph. Steeper drop in recall will occur if the material contains a higher proportion of difficult knowledge (esp. poorly formulated knowledge), or in new students with lesser mnemonic skills. Curve irregularity at intervals 15-20 comes from a smaller sample of repetitions (later interval categories on a log scale encompass a wider range of intervals)*
> 
> **图示：** SuperMemo 收集的新知识的首次复习遗忘曲线。由于学习过程中新引入的学习材料的异质性，在此情况下使用幂函数对结果进行近似。数据没有根据记忆材料的难度做出区分，导致不同衰减常数的指数遗忘曲线叠加。在半对数图上，幂回归曲线呈对数形式（黄色），几乎呈直线。曲线显示，在本示例中，四年中回忆成功仅下降到58%，这可以用记忆的知识在现实生活中被反复再利用来解释。想要保持90%的记忆率，首次复习的最佳间隔为3.96天。遗忘曲线可以用公式R=0.9907×power(interval,-0.07)来描述，其中0.9907是一天后的回忆成功率，而-0.07是衰减常数。在这种情况下，该公式在4天后产生90%的回忆成功率。该图使用80,399个重复案例绘制。如果材料包含更高比例的困难知识（尤其是编排不当的知识），或者新学生掌握的记忆技巧更少，则回忆成功率的下降幅度会更大。间隔15-20处的曲线不规则性是重复样本数量较少所致（对数尺度上的后期间隔包含更广泛的间隔范围（*译注：即，如果将选用时间的对数作为横轴，越到后面，相同长度横轴对应的实际时间长度越长*））。

## 1995年：超媒体 SuperMemo（1995: Hypermedia SuperMemo）

### 山间小屋中诞生的 SM-8 算法（Birth of Algorithm SM-8 in a mountain hut）

In 1995, SuperMemo was rewritten from grounds up and it was a great opportunity to implement a new spaced repetition algorithm based on data collected in 4 years of the use of Algorithm SM-6.

1995年，SuperMemo进行了从头到尾的重写，这为（在四年间使用算法 SM-6 收集的数据上）实施新的间隔重复算法提供了绝佳机会。

In March 1995 at CeBIT in Hannover, we saw a new fantastic development environment from Borland: Delphi. It has lifted the old Borland Pascal to a new level and opened dozens of development opportunities for SuperMemo. We decided to redesign the program along the lines depicted in my PhD dissertation. In addition to spaced repetition, we wanted to have knowledge structure and hypermedia. Instead of a mass of items, the users would build a knowledge tree. Instead of the old template of a question, answer, picture, and sound, we wanted to have all possible component types that could be mixed up into new hypermedia forms for expressing knowledge. There was also a dream of programmable SuperMemo in which developers could write their own procedures for any form of training, incl. procedural training, touch typing, or solving quadratic equations. At the same time, we have collected a lot of data that indicated that the algorithm used in SuperMemo could be improved. For example, the mathematical nature of the matrix of optimal factors has become pretty obvious.

1995年3月，在汉诺威的 CeBIT 上，我们看到了 Borland 推出的一个梦幻般的全新开发环境：Delphi。它将旧版的 Borland Pascal 提升到了一个新的水平，为 SuperMemo 打开了数十个开发机会。我们决定按照我的博士论文中描述的思路重新设计该程序。除了间隔重复之外，我们还希望拥有知识结构和超媒体。用户将构建知识树，而不是一团糟的项目。我们希望兼容所有可能的知识组件类型，并可以将它们混合成新的超媒体形式来表达知识，而不是沿用旧模板（问题、答案、图片和声音）。我们还有一个梦想，即可编程的 SuperMemo，开发人员可以为任何形式的训练编写自己的程序，包括程序性训练、盲打或求解二次方程。与此同时，我们收集了大量数据，表明 SuperMemo 中使用的算法还能改进。例如，最佳因子矩阵的数学性质已经变得非常明显了。

In May 1995, I took my Pentium PC to a remote mountain hut in southern Poland to work on those ideas. That was a period of 100 days of total isolation interrupted only by a short visit from Krzysztof Biedalak during which we re-synchronized our vision for future SuperMemo. By September 1995, the new algorithm was ready and tested on my own data. Back in Poznan, I started gradually moving all my learning process from multiple collections in SuperMemo 7 to the new environment nicknamed “Genius”. Genius became SuperMemo 8 only two years later when the new program added up all functionality that was originally available in SuperMemo 7.

1995年5月，我带着我的奔腾电脑前往波兰南部的偏远山间小屋，致力于这些想法的研究。那是一段长达100天的完全隔离期，只有克里斯托夫·比达拉克（Krzysztof Biedalak）短暂的来访作为打扰，在采访中我们重新同步了对未来 SuperMemo 的愿景。到1995年9月，新算法已经准备就绪并在我自己的数据上进行了测试。回到波兹南后，我开始逐渐将我的所有学习过程从SuperMemo 7中的多个合集迁移到名为“Genius”的新环境中。“Genius”两年后才成为SuperMemo 8（在新程序添加了SuperMemo 7中最初提供的所有功能之后）。

The main data that helped develop Algorithm SM-8 were forgetting curves and OF matrix data collected with SuperMemo 6 and SuperMemo 7. This data took away a great deal of guesswork from the algorithm. The work was pretty easy in comparison to Algorithm SM-17 (2014-2016) when I had mountains of repetition histories to process, and the requirements for precision and good metrics have tripled. While Algorithm SM-17 took two years to develop, Algorithm SM-8 was designed, implemented, and well-tested in mere 100 days.

帮助开发算法 SM-8 的主要数据是使用 SuperMemo 6和 SuperMemo 7收集的遗忘曲线和OF矩阵数据。这些数据消除了算法中大量的猜测。与算法 SM-17（2014-2016）相比，这项工作相当容易，（制作算法 SM-17 时）我需要处理大量的重复历史记录，对精度和良好指标的要求也提高了三倍。算法 SM-17 的开发耗时两年，但算法 SM-8 的设计、实施和良好测试仅用了短短100天。

The main ideas behind Algorithm SM-8:

-   precise mathematical determination of the OF matrix based on live approximations. Instead of matrix smoothing known from SuperMemo 5, I wanted to know the exact mathematical function that could describe the matrix and perform live updates. It was easy to determine that a negative power function would determine OF=f(RepNo) (which is an expression of SInc=f(S)) in today’s terms). A bit more guesswork went into the impact of difficulty on SInc. I opted for a linear approximation of the function mapping difficulty ( A-Factor) to the decay constant for SInc (D-Factor), which expressed the decline in stability increase with stability/interval. That linear bet has survived to this day. It was a good guess.
-   with a good definition of the OF matrix, I could provide a precise definition of item difficulty: instead of a fluid E-Factor that could be manually controlled by grades at the whim of the user, I wanted to have an absolute difficulty A-factor, which was defined as the stability increase after the first repetition timed for R=0.9. This made it possible for SuperMemo to adjust item difficulty with each repetition by correcting the fit of item’s performance with the expected performance based on the OF matrix
-   faster determination of startup difficulty by correlating the first grade with the A-factor. This is a weak mechanism of little significance, as shown by the fact that even with multi-repetition histories, item difficulty is still a hazy concept. In that context, users should be reminded that the best approach is to formulate items well and just keep them easy
-   approximating the first post-lapse interval by an exponential fit based on the number of memory lapses. The biggest value of that approach was to abolish a myth that reducing the length of intervals in case of memory lapses could speed up learning (some authors of software based on Algorithm SM-2 opted for such a solution, which has been proven wrong)
-   the idea to correlate grades with the forgetting index was a failure and did not contribute to improving the algorithm. That truth transpired slowly. It took nearly a decade to come to the ultimate verdict: grades correlate poorly with the forgetting index. The intuition born with Algorithm SM-2 is only weakly correct

算法SM-8背后的主要思想：

- **基于实时近似精准确定 OF 矩阵**：我不希望继续使用 SuperMemo 5中的矩阵平滑，而是希望获得可以描述矩阵并执行实时更新的精确数学函数。很容易确定 OF=f(RepNo) 是一个负幂函数（用今天的术语来说，这是 SInc=f(S) 的表达式）。对难度对 SInc 的影响进行了一些猜测。我选择了一个线性近似函数，将难度（A-因子）映射到 SInc 的衰减常数（D-因子）上，该函数表示稳定性增长幅度随稳定性/间隔的增加而下降。这个（A-因子与D-因子呈线性关系的）猜测一直沿用到今天。这是一个很好的猜测。
- **有了OF矩阵的良好定义，我就可以提供项目难度的精确定义**：我希望有一个对应绝对难度的 A-因子，而非用户可以通过主观响应等级手动控制的灵活的 E-因子，A-因子定义为 R=0.9 时第一次重复后稳定性的增加。这使得 SuperMemo 能够基于 OF 矩阵，对校正项目的实际表现与预期表现进行拟合，来调整每次重复的项目难度估值。
- **通过将第一个等级与A-因子相关联来更快地确定启动难度**。这是一种微不足道的弱机制，正如以下事实所示：即使有多次重复历史记录，项目难度仍然是一个模糊的概念。在这种情况下，应提醒用户最佳方法是正确地表述项目并保持它们的难度较低。
- **通过基于记忆失效次数的指数拟合来近似（估计）第一次失效后的间隔**。这种方法的最大价值在于消除了一个误解，即在记忆失效的情况下缩短间隔可以加快学习速度（一些基于算法 SM-2 的软件作者选择了这种解决方案，事实证明这是错误的）。
- **将（响应）等级与遗忘指数相关联的想法失败了，并且没有给改进算法带来帮助**。这个事实是逐步显现的。最终结论在将近十年的时间后才浮现：（响应）等级与遗忘指数的相关性很差。算法 SM-2 产生的直觉只有很弱的正确性。

Interestingly, Algorithm SM-8 did not require full repetition history for elements. Full repetition histories were to be implemented only in Feb 1996. The advantage was an easier implementation. The disadvantage came with the fact that once the user intervened manually in the learning process, the algorithm had no record of that intervention, and could not defend itself from a possible inflow of incorrect data. Naturally, only full repetition history record made it possible to implement Algorithm SM-17 two decades later.

有趣的是，算法 SM-8 不需要完整重复历史记录。重复历史的完整记录在1996年2月后才被实现。（这一特征带来的）优点是算法更容易实现。缺点是，一旦用户手动干预学习过程，算法就无法记录该干预，也无法防御可能输入的错误数据。直到二十年后，完整的重复历史记录才（用于改进算法），使算法 SM-17 的实现成为可能。

My first “live” repetition in Algorithm SM-8 on my own data took place on Aug 16, 1995, Wed. For the test, I “sacrificed” a small 100 item collection with mnemonic peg list for memorizing numbers. Over the next two years, I gradually converted all my other collections to work with the new algorithm and in the new SuperMemo environment. In 1997, all my knowledge have finally been integrated into a single well-structured database. In 1995-1997, we called such a database a “knowledge system”. Today we just call it collection (as in a collection of pieces of knowledge).

我用算法 SM-8 的进行的第一次“实时”重复是在1995年8月16日，星期三，用了我自己的数据。为了测试，我“牺牲”了一个100项的小型集合，其中包含用于记忆数字的记忆桩列表。在接下来的两年里，我逐渐将我所有的其他集合转换为兼容新算法且适用于新的 SuperMemo 环境。1997年，我终于将所有知识都整合到了一个单一的、结构良好的数据库中。在1995-1997年，我们称这样的数据库为“知识系统”。今天我们只是称之为“集合”（如一组知识片段）。

To this day, the core of the algorithm born in 1995 runs in SuperMemo 17 in the background, and the user can still choose intervals based on that old algorithm in case he is unhappy with propositions of Algorithm SM-17.

直到今天，1995年诞生的算法的核心仍在 SuperMemo 17中后台运行，如果用户对算法 SM-17 的建议不满意，他仍然可以选择基于该旧算法的间隔。
### 绝对项目难度（Absolute item difficulty）

In SuperMemo 1.0 through SuperMemo 3.0, E-Factors were defined in the same way as O-Factors (i.e. the ratio of successive intervals). They were an approximate measure of item difficulty (the higher the E-Factor, the easier the item). However, the spaced repetition optimization would force E-factors to correspond with stability increase which drops with stability. In other words, by definition, in Algorithm SM-2, items would be tagged as more and more “difficult” as they were subject to successive repetitions. This is a bit counter-intuitive and users never seemed to notice.

在 SuperMemo 1.0 到 3.0 中，E-因子与 O-因子的定义相同（即连续间隔的比率）。它们是对项目难度的近似衡量（E-因子越高，项目越简单）。然而，间隔重复优化将迫使 E-因子随“稳定性增加幅度”变化，而“稳定性增加幅度”会随着稳定性升高而下降。换句话说，根据定义，在**算法 SM-2**中，项目在经历连续重复后会被标记为越来越“困难”。这有点违反直觉，用户似乎从未注意到这一点。

Starting with SuperMemo 4.0, E-Factors were used to index the matrix of O-Factors. They were still used to reflect item difficulty. They were still used to compute O-Factors. However, they could differ from O-Factors and thus make for a better reflection of difficulty.

从 SuperMemo 4.0 开始，E-因子被用来索引 O-因子矩阵。它们仍然能反映项目难度。它们也仍然能用于计算 O-因子。然而，它们可能与 O-因子不再完全相同，从而更好地反映难度。

In SuperMemo 4 through SuperMemo 7, difficulty of material in a given database would shape the relationship between O-Factors and E-Factors. For example, in an easy collection, the starting-point O-Factor (i.e. the one corresponding with the first repetition and the assumed starting difficulty) would be relatively high. As performance in repetitions determines E-Factors, items of the same difficulty in an easy collection would naturally have a lower E-Factor than the exactly same items in a difficult collection. 

在 SuperMemo 4到 SuperMemo 7中，给定数据库中材料的难度会影响 O-因子和 E-因子之间的关系。例如，在一个简单的集合中，起始点 O-因子（即与第一次复习和假设的起始难度相对应的 O-因子）会相对较高。由于复习中的表现决定了 E-因子，因此简单集合中相同难度的项目自然会比困难集合中完全相同的项目具有更低的 E-因子。

This all changed in SuperMemo 8 where A-Factors where introduced. A-Factors are “bound” to the second row of the O-Factor matrix. This makes them an absolute measure of item difficulty. Their value **does not depend on the content of the collection** . For example, you know that if A-Factor is 1.5, the third repetition will take place in an interval that is 50% longer than the first interval.

这一切在 SuperMemo 8 中发生了变化，我们引入了 A-因子。A-因子被“绑定”到 O-因子矩阵的第二行。这使得它们成为衡量项目难度的绝对标准。**它们的值不取决于集合的内容**。例如，如果已知 A-因子为 1.5，则第三次学习（译注：*即第二次复习*）将在比第一次复习间隔长 50% 的时间内进行。

Archive warning: Why use literal archives?

下面是引用文档

A-Factor is a number associated with every element in a collection. A-Factor determines how much intervals increase in the learning process. The higher the A-Factor, the faster the intervals increase. A-Factors reflect item difficulty. The higher the A-Factor the easier the item. The most difficult items have A-Factors equal to 1.2. A-Factor is defined as the quotient of the second optimum interval and the first optimum interval used in repetitions

**A-因子**是与集合中每个**元素**相关联的一个数值。A-因子决定了学习过程中间隔的增长幅度。A-因子越高，间隔增长越快。A-因子反映了项目的难度。A-因子越高，项目越容易。最难的项目的 A-因子等于 1.2。A-因子定义为第二次最佳间隔与第一次最佳间隔的商（“最佳间隔”是指为了达到理想的保留率在复习中使用的最佳间隔）。

### 失误后间隔（Post-lapse interval）

Post-lapse interval approximation in Algorithm SM-8 abolished two myths:

-   shortening intervals after a lapse is a good idea (this idea was advocated multiple times in the years 1991-2000)
-   the first interval should always be 1 day (as in some older SuperMemo solutions)

算法 SM-8 中对失误后复习间隔的近似消除了两个误解：

- 失误后缩短间隔是一个好主意（这一观点在 1991-2000 年间多次被提倡）
- 第一个间隔应该始终为 1 天（如某些较旧的 SuperMemo 解决方案中所述）

In the graph presented below, we can see that with successive lapses, the optimum post-lapse interval keeps getting slightly shorter. This expresses nothing else but the fact that those high-lapse counts are reached only by badly formulated items, or items that are really hard to remember for their semantic nature or knowledge interference. For memories starting with Lapse=10, I suggested a term ” toxic” to express their impact on the learning process. If the brain rejected a piece of information that many times, we should get a message: this knowledge is badly formulated or has become toxic for other reasons (e.g. stress associated with learning, e.g at school).

在下图中，我们可以看到，随着连续的遗忘，失误后最佳复习间隔仍然会逐渐变短。这恰恰表明，只有那些表述不佳的项目，或由于语义性质/知识干扰而确实难以记忆的项目，才会达到如此高的遗忘次数。对于以 Lapse=10 开始的记忆，我建议使用术语“有毒”来表达它们对学习过程的影响。如果大脑多次拒绝接受一条信息，我们应该意识到：这条知识表述不佳或由于其他原因（例如学业压力）而变得“有毒”。

Archive warning: Why use literal archives?

下面是引用文档

**First interval** – the length of the first interval after the first repetition depends on the number of times a given item has been forgotten. Note that the first repetition here means the first repetition after forgetting, *not* the first repetition ever. In other words, a twice-repeated item will have the repetition number equal to one after it has been forgotten; the repetition number will not equal three. The first interval graph shows exponential regression curve that approximates the length of the first interval for different numbers of memory lapses (including the zero-lapses category that corresponds with newly memorized items). In the graph below, blue circles correspond to data collected in the learning process (the greater the circle, the more repetitions have been recorded).

**第一个间隔** - 第一次复习后的第一个重复间隔的长度取决于给定项目被遗忘的次数。请注意，此处第一次复习是指遗忘后的第一次复习，*而不是*历来第一次复习。换句话说，重复两次的项目在遗忘后其重复次数将等于一；而非等于三。第一次重复间隔对应的图表显示了指数回归曲线，通过该曲线对不同记忆遗忘次数（包括零遗忘次数，对应于新记忆的项目）对应的第一个间隔的长度进行近似。在下图中，蓝色圆圈对应于学习过程中收集的数据（圆圈越大，记录的重复次数越多）。

![[SuperMemo_The true history of spaced repetition_附件/First_interval.jpg]]

> ***Figure**: In the graph above, which includes data from over 130,000 repetitions, newly memorized items are optimally repeated after seven days. However, the items that have been forgotten 10 times (which is rare in SuperMemo) will require an interval of two days. (Due to logarithmic scaling, the size of the circle is not linearly proportional to the data sample; the number of repetition cases for Lapses=0 is by far larger than for Lapses=10, as can be seen in **Distributions : Lapses**)*
> 
> **图示：** 上图包含了超过13万次重复的数据，新记忆的项目最佳的复习间隔为7天。然而，那些被遗忘10次的项目（在 SuperMemo 中很少见）需要的间隔是 2 天。（由于对数刻度，圆圈的大小与样本数目并非成线性比例；如**分布：遗忘次数**中所示，遗忘次数为0的重复案例数目远远大于遗忘次数为10的案例数目。）

### 初次响应评分与 A-因子的关系（First grade vs. A-Factor）

Correlating the first grade with the estimated item difficulty was to help classify items by difficulty at the entry to the learning process. The correlation appears to be weak and is highly dependent on user’s grading system. For some users, there is virtually no correlation (picture #1). For others, the correlation is good enough to cover the full range of difficulty (A-factor) (picture #2).

将初次响应评分与项目难度（的估计值）相关联，是为了有助于在学习过程的开始阶段，将项目按难度进行分类。这种相关性似乎很弱，并且高度依赖于用户的（响应）评分系统。对于某些用户来说，两者几乎没有相关性（图1）。但对于其他用户来说，相关性足够好，可以覆盖整个难度范围（A-因子取值范围）（图2）。

![[SuperMemo_The true history of spaced repetition_附件/First_Grade_vs_A-Factor_All.jpg]]

![[SuperMemo_The true history of spaced repetition_附件/First_Grade_vs_A-Factor_Molie.jpg]]

In addition, in Algorithm SM-11 derived from Algorithm SM-8, the user was allowed to execute premature repetitions. Those repetitions would account for the spacing effect, however, they would still contribute to the graph and overestimate the grade for difficult items. With extensive use of incremental reading, this would flatten the graph.

此外，在源自算法 SM-8 的算法 SM-11 中，用户被允许提前执行复习。这些复习将影响间隔效应，但是，数据仍然会加入图表并使困难项目的（响应）评分偏高。随着增量阅读的广泛使用，最终将使图表变得平坦。

Algorithm SM-17 does not use grade-difficulty correlation and derives difficulty from the entire repetition history. Practice shows that even then the estimate is hard to make and the good practice of learning is to keep all items easy (i.e. in the accepted mnemonic fit with the rest of the student’s knowledge).

算法 SM-17 不使用（响应）评分-难度相关性，而是从整个复习历史中推导难度。实践表明，即使这样，也很难（对难度）做出估计，良好的学习习惯是让所有项目都尽可能简单（即与学生的其余知识保持良好的关联）。

Archive warning: Why use literal archives?

下面是引用文档

**First Grade vs. A-Factor** – G-AF graph correlates the first grade obtained by an item with the ultimate estimation of its A-Factor value. At each repetition, the current element’s old A-Factor estimation is removed from the graph and the new estimation is added. This graph is used by Algorithm SM-15 to quickly estimate the first value of A-Factor at the moment when all we know about an element is the first grade it has scored in its first repetition.

**初次响应评分与 A-因子的关系** - G-AF 图将项目获得的初次响应评分与其 A-因子值的最终估计值相关联。在每次重复时，当前元素的旧 A-因子估计值将从图表中移除，并添加新的估计值。算法 SM-15 使用该图表来快速估计 A-因子的第一个值，此时我们仅知道元素在其第一次重复中获得的初次响应评分。

### 响应评分与遗忘指数的关系（Grade vs. Forgetting Index）

By correlating grades with the expected forgetting index (predicted retrievability), I hoped to be able to compute the estimated forgetting index (post-repetition estimate of the actual retrievability). This correlation appeared to be weak due to the fact that all users tend to deploy their own grading systems, which is often inconsistent. The grade and R correlation comes primarily from the fact that complex items get worse grades and tend to be forgotten faster (at least at the beginning). In that sense, grades provide a better reflection of complexity than a reflection of retrievability.

通过将（响应）评分与预期的遗忘指数（预期的可检索性）相关联，我希望能够计算遗忘指数的估值（重复后的实际可检索性的估值）。由于所有用户都倾向于部署自己的（响应）评分系统，而这些系统通常并不一致，因此这种相关性似乎很弱。（响应）评分和 R 的相关性主要来自以下事实：复杂的项目会获得较差的评分，并且往往更容易被遗忘（至少在开始时）。从这个意义上说，评分更好地反映了复杂性，而非可检索性。

In the picture below, the entire range of the expected forgetting index seems to fall around the grade 3.

在下图中，预期遗忘指数的整个范围似乎都对应3左右的评分。

![[SuperMemo_The true history of spaced repetition_附件/Grade_vs_Forgetting_Index.jpg]]

For Grade<=3 we can read the maximum estimated forgetting index, and for Grade>=4 we can read the minimum estimated forgetting index. In that light, two grade systems would have the exact same effect on the algorithm as the six grade system.

对于评分 <= 3，我们可以读取最大估计遗忘指数；对于评分 >= 4，我们可以读取最小估计遗忘指数。从这个角度来看，两级评分系统（***记住了*** *和* ***没记住***）对算法的影响与六级评分系统（0~5分）完全相同。

For other users, the curve might even peak at some levels of the expected forgetting index as if grading reflected a wish to remember items that are really hard to remember (lenient grading).

对于其他用户，曲线甚至可能在预期遗忘指数的某些级别达到峰值，就好像评分反映了希望记住真正难以记忆的项目的愿望（对于高难度项目有一套更加宽松的评分标准）。

Algorithm SM-17 makes an extensive use of retrievability estimated after the repetition, however, it derives it from sheer recall data and the expected retrievability. Grade-retrievability correlations are also collected, however, their weight is negligible.

算法 SM-17 对重复后的可检索性估值进行了广泛应用，但是，它（所用的可检索性估值）是从纯粹的回忆数据和预期可检索性中推导出来。还收集了（响应）评分-可检索性相关性，只是它们（（响应）评分-可检索性相关性）的权重可以忽略不计。

Archive warning: Why use literal archives?

下面是引用文档

**Grade vs. Forgetting Index** – FI-G graph correlates the expected forgetting index with the grade scored at repetitions. You need to understand Algorithm SM-15 to understand this graph. You can imagine that the forgetting curve graph might use the average grade instead of the retention on its vertical axis. If you correlated this grade with the forgetting index, you would arrive at the FI-G graph. This graph is used to compute an estimated forgetting index that is, in turn, used to normalize grades (for delayed or advanced repetitions) and estimate the new value of item’s A-Factor. The grade is computed using the formula: *Grade=exp <sup>A*FI+B</sup>* , where A and B are parameters of an exponential regression run over raw data collected during repetitions.

**响应评分与遗忘指数** - FI-G 图表将预期的遗忘指数与重复时获得的（响应）评分相关联。您需要理解算法 SM-15 才能理解此图表。您可以想象，遗忘曲线图可能使用平均分数而不是保留率作为其纵轴。如果将此（响应）评分与遗忘指数相关联，则会得到 FI-G 图表。该图表用于计算遗忘指数的估值，而遗忘指数的估值又用于将分数标准化（针对重复时机延迟或提前的情况）并估计项目 A-因子的新值。分数的计算公式为：*分数 = exp <sup>A×FI+B</sup>*，其中 A 和 B 是对重复期间收集的原始数据进行指数回归的参数。

The FI-G graph is updated after each repetition by using the expected forgetting index and actual grade scores. The expected forgetting index can easily be derived from the interval used between repetitions and the optimum interval computed from the OF matrix. The higher the value of the expected forgetting index, the lower the grade. From the grade and the FI-G graph, we can compute the estimated forgetting index which corresponds to the post-repetition estimation of the forgetting probability of the just-repeated item at the hypothetical pre-repetition stage. Because of the stochastic nature of forgetting and recall, the same item might or might not be recalled depending on the current overall cognitive status of the brain; even if the strength and retrievability of memories of all contributing synapses is/was identical! This way we can speak about the pre-repetition recall probability of an item that has just been recalled (or not). This probability is expressed by the estimated forgetting index.

FI-G 图表会（根据预期的遗忘指数和实际的（响应）评分）在每次重复后进行更新。预期的遗忘指数可以很容易地从重复之间实际使用的间隔和通过 OF 矩阵计算出的最佳间隔推导出来。预期的遗忘指数的值越高，分数越低。根据分数和 FI-G 图表，我们可以计算出遗忘指数的估值，该（遗忘）指数对应于刚刚重复的项目在上次重复后到下次重复前这段时间的遗忘概率。由于遗忘和回忆的随机性，即使所有相关突触的记忆强度和可检索性都相同，同一项目的回忆也同时存在成功和失败两种可能（取决于大脑当前的整体认知状况）！这样我们就可以讨论刚刚被回忆过（不管回忆是否成功）的项目的在下次重复前回忆成功率。该概率由遗忘指数的估值表示。

### SM-15 算法（Algorithm SM-15）

Algorithm SM-8 has been improved over years and evolved into Algorithm SM-11 (2002) and then Algorithm SM-15 (2011). Here I only present the latest version: Algorithm SM-15 (used in SuperMemo 15, SuperMemo 16, and as backup in SuperMemo 17).

算法 SM-8 经过多年改进，演变为算法 SM-11 (2002) 以及随后的算法 SM-15 (2011)。这里仅介绍最新的版本：算法 SM-15 (用于 SuperMemo 15、SuperMemo 16 以及 SuperMemo 17 的备份)。

The key improvements added to Algorithm SM-8 over two decades were:

-   improved stability indexing: instead of using repetition numbers, as of SuperMemo 8 (1997), the algorithm used the concept of “repetition category” which roughly translates to stability
-   tolerance for advanced and delayed repetitions, as of SuperMemo 11 (2002): a heuristic has been added to account for the spacing effect
-   extending the representation of time in U-Factors from 60 days to 15 years (2011)
-   correcting forgetting curve data for repetition delay beyond the original U-Factor span (2011)

与算法 SM-8 相比，二十年来主要改进包括：

- **改进稳定性索引:** 从 SuperMemo 8 (1997) 开始，算法不再使用重复次数，而是使用“重复类别”的概念，（“重复类别”）大致对应于稳定性。
- **容忍重复的延迟和提前:** 从 SuperMemo 11 (2002) 开始，添加了一种启发式方法来衡量间隔效应的影响。
- 将 U-因子中时间的表示范围从 60 天扩展到 15 年 (2011)
- 修正了原始 U-因子跨度之外的重复延迟对遗忘曲线数据的影响 (2011)

Archive warning: Why use literal archives?

下面是引用文档

Algorithm SM-15 begins the effort to compute the optimum inter-repetition intervals by storing the recall record of individual items (i.e. grades scored in learning). This record is used to estimate the current strength of a given memory trace, and the difficulty of the underlying piece of knowledge (item). The item difficulty expresses the complexity of memories, and reflects the effort needed to produce unambiguous and stable memory traces. SuperMemo takes the requested recall rate as the optimization criterion (e.g. 95%), and computes the intervals that satisfy this criterion. The function of optimum intervals is represented in a matrix form (OF matrix) and is subject to modification based on the results of the learning process. Although satisfying the optimization criterion is relatively easy, the complexity of the algorithm derives from the need to obtain maximum speed of convergence possible in the light of the known memory models.

算法 SM-15 开始尝试通过存储单个项目的回忆记录（即学习中获得的响应评分）来计算最佳的重复间隔。该记录用于估计给定记忆痕迹的当前强度和（与其对应的）底层知识（项目）的难度。项目难度表示记忆的复杂性，反映了产生明确且稳定的记忆痕迹所需的工作量。SuperMemo 以（用户）要求的回忆率作为优化标准（例如 95%），并计算满足该标准的间隔。最佳间隔函数以矩阵形式表示（OF 矩阵），并可以根据学习过程的结果进行修改。虽然满足优化标准相对容易，但算法依然具备复杂性，这源于需要在已知的记忆模型的基础上获得尽可能快的收敛速度。

**Important!** Algorithm SM-15 is used only to compute the intervals between repetitions of items. Topics are reviewed at intervals computed with an entirely different algorithm (not described here). The timing of topic review is optimized with the view to managing the reading sequence and is not aimed at aiding memory. Long-term memories are formed in SuperMemo primarily with the help of items, which are reviewed along the schedule computed by Algorithm SM-15.

**重要！** 算法 SM-15 仅用于计算**项目**之间重复的间隔。**主题**的复习间隔由完全不同的算法（此处未描述）计算。主题复习的时间安排旨在管理阅读顺序，而不是辅助记忆。SuperMemo 中长期记忆主要是在项目的帮助下形成的，而项目是按照算法 SM-15 计算的时间表进行复习的。

This is a more detailed description of the Algorithm SM-15:

1.  **Optimum interval**: Inter-repetition intervals are computed using the following formula:
	
	I(1)=OF[1,L+1]
	I(n)=I(n-1)*OF[n,AF]
	
	where:
	-   OF – matrix of optimal factors, which is modified in the course of repetitions
    -   OF[1,L+1] – value of the OF matrix entry taken from the first row and the L+1 column
    -   OF[n,AF] – value of the OF matrix entry that corresponds with the n-th repetition, and with item difficulty AF
    -   L – number of times a given item has been forgotten (from ” memory **L**apses“)
    -   AF – number that reflects absolute difficulty of a given item (from ” **A**bsolute difficulty **F**actor“)
    -   I(n) – n-th inter-repetition interval for a given item
2.  **Advanced repetitions**: Because of possible advancement in executing repetitions (e.g. forced review before an exam), the actual optimum factor (OF) used to compute the optimum interval is decremented by *dOF* using formulas that account for the spacing effect in learning:
	
	*dOF*=dOF <sub>max</sub>×*a*/(t <sub>half</sub>+ *a*)
	dOF <sub>max</sub>=(OF-1)×(OI+t <sub>half</sub>-1)/(OI-1)
	
	where:
    -   *dOF* – decrement to OF resulting from the *spacing effect*
    -   *a* – advancement of the repetition in days as compared with the optimum schedule (note that there is no change to OF if *a*=0, i.e. the repetition takes time at optimum time)
    -   dOF <sub>max</sub> – asymptotic limit on *dOF* for infinite *a* (note that for a=OI-1 the decrement will be OF-1 which corresponds to no increase in inter-repetition interval)
    -   t <sub>half</sub> – advancement at which there is half the expected increase to synaptic stability as a result of a repetition (presently this value corresponds roughly to 60% of the length of the optimum interval for well-structured material)
    -   OF – optimum factor (i.e. OF[n,AF] for the n-th interval and a given value of AF)
    -   OI – optimum interval (as derived from the OF matrix)
3.  **Delayed repetitions**: Because of possible delays in executing repetitions, the OF matrix is not actually indexed with repetitions but with repetition categories. For example if the 5-th repetition is delayed, OF matrix is used to compute the repetition category, i.e. the theoretical value of the repetition number that corresponds with the interval used before the repetition. The repetition category may, for example, assume the value 5.3 and we will arrive at I(5)=I(4)*OF[5.3,AF] where OF[5.3,AF] has a intermediate value derived from OF[5,AF] and OF[6,AF]
4.  **Matrix of optimum intervals**: SuperMemo does not store the matrix of optimum intervals as in some earlier versions. Instead it keeps a matrix of optimal factors that can be converted to the matrix of optimum intervals (as in the formula from Point 1). The matrix of optimal factors OF used in Point 1 has been derived from the mathematical model of forgetting and from similar matrices built on data collected in years of repetitions in collections created by a number of users. Its initial setting corresponds with values found for a less-than-average student. During repetitions, upon collecting more and more data about the student’s memory, the matrix is gradually modified to make it approach closely the actual student’s memory properties. After years of repetitions, new data can be fed back to generate more accurate initial OF matrix. In SuperMemo 17, this matrix can be viewed in 3D with **Tools : Statistics : Analysis : 3-D Graphs : O-Factor Matrix**
5.  **Item difficulty**: The absolute item difficulty factor ( A-Factor), denoted AF in Point 1, expresses the difficulty of an item (the higher it is, the easier the item). It is worth noting that AF=OF[2,AF]. In other words, AF denotes the optimum interval increase factor after the second repetition. This is also equivalent with the highest interval increase factor for a given item. Unlike E-Factors in Algorithm SM-6 employed in SuperMemo 6 and SuperMemo 7, A-Factors express absolute item difficulty and do not depend on the difficulty of other items in the same collection of study material
6.  **Deriving OF matrix from RF matrix**: Optimum values of the entries of the OF matrix are derived through a sequence of approximation procedures from the RF matrix which is defined in the same way as the OF matrix (see Point 1), with the exception that its values are taken from the real learning process of the student for who the optimization is run. Initially, matrices OF and RF are identical; however, entries of the RF matrix are modified with each repetition, and a new value of the OF matrix is computed from the RF matrix by using approximation procedures. This effectively produces the OF matrix as a smoothed up form of the RF matrix. In simple terms, the RF matrix at any given moment corresponds to its best-fit value derived from the learning process; however, each entry is considered a best-fit entry on its own, i.e. in abstraction from the values of other RF entries. At the same time, the OF matrix is considered a best-fit as a whole. In other words, the RF matrix is computed entry by entry during repetitions, while the OF matrix is a smoothed copy of the RF matrix
7.  **Forgetting curves**: Individual entries of the RF matrix are computed from forgetting curves approximated for each entry individually. Each forgetting curve corresponds with a different value of the repetition number and a different value of A-Factor (or memory lapses in the case of the first repetition). The value of the RF matrix entry corresponds to the moment in time where the forgetting curve passes the knowledge retention point derived from the requested forgetting index. For example, for the first repetition of a new item, if the forgetting index equals 10%, and after four days the knowledge retention indicated by the forgetting curve drops below 90% value, the value of RF[1,1] is taken as four. This means that all items entering the learning process will be repeated after four days (assuming that the matrices OF and RF do not differ at the first row of the first column). This satisfies the main premise of SuperMemo, that the repetition should take place at the moment when the forgetting probability equals 100% minus the forgetting index stated as percentage. In SuperMemo 17, forgetting curves can be viewed with **Tools : Statistics : Analysis : Forgetting Curves** (or in 3-D with **Tools : Statistics : Analysis : 3-D Curves**). 
	
	**Figure**: **Tools : Statistics : Analysis : Forgetting Curves** for 20 repetition number categories multiplied by 20 A-Factor categories.
	
	In the picture, blue circles represent data collected during repetitions. The larger the circle, the greater the number of repetitions recorded. The red curve corresponds with the best-fit forgetting curve obtained by exponential regression. For ill-structured material the forgetting curve is crooked, i.e. not exactly exponential. The horizontal aqua line corresponds with the requested forgetting index, while the vertical green line shows the moment in time in which the approximated forgetting curve intersects with the requested forgetting index line. This moment in time determines the value of the relevant R-Factor, and indirectly, the value of the optimum interval. For the first repetition, R-Factor corresponds with the first optimum interval. The values of O-Factor and R-Factor are displayed at the top of the graph. They are followed by the number of repetition cases used to plot the graph (i.e. 21,303). At the beginning of the learning process, there is no repetition history and no repetition data to compute R-Factors. It will take some time before your first forgetting curves are plotted. For that reason, the initial value of the RF matrix is taken from the model of a less-than-average student. The model of average student is not used because the convergence from poorer student parameters upwards is faster than the convergence in the opposite direction. The **Deviation** parameter displayed at the top tells you how well the negatively exponential curve fits the data. The lesser the deviation, the better the fit. The deviation is computed as a square root of the average of squared differences (as used in the method of least squares).****Figure:** 3D representation of the family of forgetting curves for a single item difficulty and varying memory stability levels (normalized for U-Factor).***Figure:** *Cumulative forgetting curve for learning material of mixed complexity, and mixed stability. The graph is obtained by superposition of 400 forgetting curves normalized for the decay constant of 0.003567, which corresponds with recall of 70% at 100% of the presented time span (i.e. R=70% on the right edge of the graph). 401,828 repetition cases have been included in the graph. Individual curves are represented by yellow data points. Cumulative curve is represented by blue data points that show the average recall for all 400 curves. The size of circles corresponds with the size of data samples.*
8.  **Deriving OF matrix from the forgetting curves**: The OF matrix is derived from the RF matrix by:
    
    1.  fixed-point power approximation of the R-Factor decline along the RF matrix columns (the fixed point corresponds to second repetition at which the approximation curve passes through the A-Factor value),
    2.  for all columns, computing D-Factor which expresses the decay constant of the power approximation,
    3.  linear regression of D-Factor change across the RF matrix columns, and
    4.  deriving the entire OF matrix from the slope and intercept of the straight line that makes up the best fit in the D-Factor graph. The exact formulas used in this final step go beyond the scope of this illustration.
    
    Note that the first row of the OF matrix is computed in a different way. It corresponds to the best-fit exponential curve obtained from the first row of the RF matrix. All the above steps are passed after each repetition. In other words, the theoretically optimum value of the OF matrix is updated as soon as new forgetting curve data is collected, i.e. at the moment, during the repetition, when the student, by providing a grade, states the correct recall or wrong recall (i.e. forgetting) (in Algorithm SM-6, a separate procedure Approximate had to be used to find the best-fit OF matrix, and the OF matrix used at repetitions might differ substantially from its best-fit value)
9.  **Item difficulty**: The initial value of A-Factor is derived from the first grade obtained by the item, and the correlation graph of the first grade and A-Factor ( G-AF graph). This graph is updated after each repetition in which a new A-Factor value is estimated and correlated with the item’s first grade. Subsequent approximations of the real A-Factor value are done after each repetition by using grades, OF matrix, and a correlation graph that shows the correspondence of the grade with the expected forgetting index ( FI-G graph). The grade used to compute the initial A-Factor is normalized, i.e. adjusted for the difference between the actually used interval and the optimum interval for the forgetting index equal 10%
10.  **Grades vs. expected forgetting index correlation**: The FI-G graph is updated after each repetition by using the expected forgetting index and actual grade scores. The expected forgetting index can easily be derived from the interval used between repetitions and the optimum interval computed from the OF matrix. The higher the value of the expected forgetting index, the lower the grade. From the grade and the FI-G graph (see: FI-G graph in **Tools : Statistics : Analysis : Graphs**), we can compute the estimated forgetting index which corresponds to the post-repetition estimation of the forgetting probability of the just-repeated item at the hypothetical pre-repetition stage. Because of the stochastic nature of forgetting and recall, the same item might or might not be recalled depending on the current overall cognitive status of the brain; even if the strength and retrievability of memories of all contributing synapses is/was identical! This way we can speak about the pre-repetition recall probability of an item that has just been recalled (or not). This probability is expressed by the estimated forgetting index
11.  **Computing A-Factors**: From (1) the estimated forgetting index, (2) length of the interval and (3) the OF matrix, we can easily compute the most accurate value of A-Factor. Note that A-Factor serves as an index to the OF matrix, while the estimated forgetting index allows one to find the column of the OF matrix for which the optimum interval corresponds with the actually used interval corrected for the deviation of the estimated forgetting index from the requested forgetting index. At each repetition, a weighted average is taken of the old A-Factor and the new estimated value of the A-Factor. The newly obtained A-Factor is used in indexing the OF matrix when computing the new optimum inter-repetition interval

下面使对算法 SM-15 详细描述：

1. **最佳间隔**：重复间隔使用以下公式计算：
	
	I(1) = OF[1,L+1] 
	I(n) = I(n-1) * OF[n,AF]
    
    其中：
    - OF – 最佳因子矩阵，在重复过程中进行修改
    - OF[1,L+1] – 从第一行和第 L+1 列获取的 OF 矩阵项的值
    - OF[n,AF] – 对应于第 n 次重复和项目难度 AF 的 OF 矩阵项的值
    - L – 遗忘次数（来自“记忆**L**apse”）
    - AF – 反映给定项目绝对难度的数字（来自“**A**bsolute difficulty **F**actor”）
2. **提前重复**：由于可能提前执行重复（例如，考试前的强制复习），用于计算最佳间隔的实际最佳因子 (OF) 需要减少 *dOF*，*dOF* 通过下列计算间隔效应影响的公式得到：
	
	*dOF* = dOF <sub>max</sub> * *a*/(t <sub>half</sub>+ _a_) 
	dOF <sub>max</sub> = (OF-1) * (OI+t <sub>half</sub>-1)/(OI-1)

	其中：

	- _dOF_ – 由于*间隔效应*导致的 OF 减少
	- _a_ – 与最佳计划相比，重复提前的天数（注意，如果 _a_=0，即重复时间为最佳时间，则 OF 不变）
	- dOF <sub>max</sub> – *a* 趋于无限时，*dOF* 的渐近极限，（注意，对于 a=OI-1，减少量将为 OF-1，对应于重复间隔不增加）
	- t <sub>half</sub> – 特定提前量，在此时机进行重复会恰好导致突触稳定性增加（最佳计划的）预期一半的值（目前该值大致对应于结构良好的材料的最佳间隔长度的 60%）
	- OF – 最佳因子（即对应第 n 个间隔和给定 AF 值的 OF[n,AF]）
	- OI – 最佳间隔（来自 OF 矩阵）
3. **延迟重复**：由于可能延迟执行重复，OF 矩阵实际上不是用重复次数而是用重复类别索引。例如，如果第 5 次重复被延迟，则使用 OF 矩阵计算重复类别，即对应于重复前的实际间隔的重复次数的理论值。例如，重复类别可以假设值为 5.3，我们将得到 I(5)=I(4)×OF[5.3,AF]，其中 OF[5.3,AF] 是从 OF[5,AF] 和 OF[6,AF] 导出的中间值
4. **最佳间隔矩阵**：SuperMemo 不会像某些早期版本那样存储最佳间隔矩阵。相反，它保留了一个最佳因子矩阵，可以将其转换为最佳间隔矩阵（如第1点中的公式）。第1点中使用的最佳因子（OF）矩阵是从遗忘的数学模型以及许多（从用户创建的集合中多年重复收集数据构建的）类似矩阵中推导出来的。其初始设置的值对应于表现略差的学生的水平。在重复过程中，随着收集到的学生记忆数据累积，矩阵逐渐修正以使其更接近学生的实际记忆水平。多年重复后，可以反馈新数据以生成更准确的初始 OF 矩阵。在 SuperMemo 17 中，可以查看此矩阵的 3D 模型。（依次选择：**工具 : 统计 : 分析 : 3D 图形 : O-Factor 矩阵**）
5. **项目难度**：第1点中用 AF 表示的绝对项目难度因子 (A-因子)，表示项目的难度（A-因子越高，项目越容易）。值得注意的是，AF=OF[2,AF]。换句话说，AF 表示第二次重复后的最佳间隔增加因子。这也等同于给定项目的最高间隔增加因子。与 SuperMemo 6 和 SuperMemo 7 中使用的算法 SM-6 中的 E-因子不同的使，A-因子表示绝对项目难度，不受同一学习材料集合中其他项目的难度的影响。
6. **从 RF 矩阵导出 OF 矩阵**：最佳因子矩阵 OF 中项的最佳值是通过一系列近似程序从 RF 矩阵导出的，RF 矩阵的定义与 OF 矩阵相同（参见第1点），除了其值取自学生的实际学习过程，优化过程正是为其本人服务。最初，矩阵 OF 和 RF 是相同的；但是，RF 矩阵的项在每次重复时都会被修改，并且通过近似程序从 RF 矩阵计算出 OF 矩阵的新值。这有效地产生了 OF 矩阵作为 RF 矩阵的平滑形式。简单来说，在任何给定时刻，RF 矩阵都对应于从学习过程中导出的其最佳拟合值；但是，矩阵中的每个项都只被视为其自身的最佳拟合，即与其他 RF 矩阵中的值无关。同时，OF 矩阵被认为是一个整体的最佳拟合。换句话说，RF 矩阵在重复过程中逐项计算，而 OF 矩阵是 RF 矩阵的平滑备份。
7. **遗忘曲线**：RF 矩阵的各个项都是从为每个项单独近似的遗忘曲线中计算出来的。每条遗忘曲线对应于不同的重复次数和不同的 A-因子值（如果是初次重复，还可能对应不同的记忆遗忘次数）。RF 矩阵项的值对应于遗忘曲线通过（（用户）要求的遗忘指数）对应的知识保留率的时间点。例如，对于新项目的第一次重复，如果（用户要求的）遗忘率等于 10%，并且在四天后遗忘曲线指示的知识保留率下降到 90% 以下，则 RF[1,1] 的值取为四。这意味着所有进入学习过程的项目都将在四天后重复（假设矩阵 OF 和 RF 在第一行第一列的值没有差异）。这满足了 SuperMemo 的主要前提，即重复应该发生在遗忘概率等于 100% 减去用百分比表示的知识保留率（*译注：此处”知识保留率“原文为”遗忘指数“，代入整句话显然不合逻辑，翻译时做了修正*）的时刻。在 SuperMemo 17 中，可以使用**工具 : 统计 : 分析 : 遗忘曲线**查看遗忘曲线（如果想看 3-D 曲线，则使用**工具 : 统计 : 分析 : 3-D 曲线**）
	
	***图***：*使用**工具：统计：分析：遗忘曲线**查看的对应20个重复类别（重复次数）和20个 A-因子取值（难度等级）的遗忘曲线。
	
	在图片中，蓝色圆圈代表重复过程中收集的数据。圆圈越大，记录的重复次数越多。红色曲线对应于通过指数回归获得的最佳拟合遗忘曲线。对于结构不良的材料，遗忘曲线是弯曲的，即不完全是指数的。水平的青绿色线对应于（用户）要求的遗忘指数，而垂直的绿色线显示了近似遗忘曲线与（用户）要求的遗忘指数（水平）线相交的时间点。这个时间点决定了相关 R-因子的值，并间接决定了最佳间隔的值。对于第一次重复，R-因子对应于第一个最佳间隔。O-因子和 R-因子的值显示在图表顶部。后面是用于绘制图形的重复案例数量（即 21,303）。在学习过程开始时，没有重复历史和重复数据能用来计算 R-因子。需要一些时间才能绘制您的第一条遗忘曲线。因此，RF 矩阵的初始值取自水平较低的学生模型。不使用平均水平的学生模型，因为从较差学生的参数向上收敛的速度比相反方向的收敛速度更快。顶部显示的**偏差**参数告诉您负指数曲线与数据的拟合程度。偏差越小，拟合越好。偏差计算方法为平方差平均值的平方根（如最小二乘法中使用的那样）。
	
	***图**：单一项目难度下和不同记忆稳定性水平的遗忘曲线族的三维展示（图形已针对 U-Factor 归一化）。*
	***图**：混杂了不同复杂度和不同稳定性的学习材料的累积遗忘曲线。该图是通过叠加 400 条遗忘曲线获得的，最终归一化为的衰减常数为0.003567的遗忘曲线，在其完整的时间跨度内最终下降至70%的回忆率（即图形右侧边缘的 R=70%）。401,828个重复案例已包含在图表中。单一曲线由黄色数据点表示。（显示所有 400 条曲线的平均回忆率的）叠加曲线由蓝色数据点表示。圆圈的大小对应于数据样本的大小。*
	
8. **从遗忘曲线导出 OF 矩阵**：
	
	通过如下方式从 RF 矩阵导出 OF 矩阵：
	1. 沿 RF 矩阵列对 R-因子衰减曲线进行定点幂近似（定点对应于第二次重复，近似曲线自变量在该点的值与 A-因子的值相同），
	2. 对于所有列，计算表示幂衰减常数近似值的 D-因子，
	3. 对 RF 矩阵列的 D-因子变化进行线性回归，并且
	4. 从（构成 D-因子图表最佳拟合的）直线的斜率和截距导出整个 OF 矩阵。此最终步骤中使用的确切公式超出了本说明的范围。
	
	请注意，OF 矩阵的第一行以不同的方式计算。它对应于从 RF 矩阵的第一行获得的最佳指数拟合曲线。在每次重复之后都会执行上述所有步骤。换句话说，每次收集到新的遗忘曲线数据（即在重复期间，当学生通过提供（响应）评分来表明回忆成功或回忆失败（即遗忘）时），OF 矩阵的理论最佳值就会更新。（在算法 SM-6 中，必须使用单独的近似过程来找到最佳拟合的 OF 矩阵，并且在重复时使用的 OF 矩阵可能与其实际最佳拟合值大不相同）
9. **项目难度**：A-因子的初始值源自项目获得的第一个（响应）评分以及“初次响应评分-A-因子”的关系图（G-AF 图）。在每次重复之后，如果得到了新的 A-因子估值，并将其与项目的初次（响应）评分进行了关联，G-AF 图都会得到更新。通过使用（响应）评分、OF 矩阵和 FI-G 图（显示（响应）评分与期望遗忘指数对应关系的相关图），在每次重复后对实际 A-因子值进行后续近似。用于计算初始 A-因子的（响应）评分是标准化的，即根据实际间隔与（期望遗忘指数等于10%的）最佳间隔之间的差异进行调整至标准值。
10. **（响应）评分与期望遗忘指数的相关性:** 通过使用期望遗忘指数和实际得到的（响应）评分，在每次重复后更新 FI-G 图。可以很容易地通过重复之间使用的间隔，和用 OF 矩阵计算出的最佳间隔，推导出期望遗忘指数。期望遗忘指数越高，（响应）评分越低。从等级和 FI-G 图（请参阅：**工具 : 统计 : 分析 : 图形**中的 FI-G 图），我们可以计算遗忘指数的估值，该估值对应于从上次重复后，到下次重复前的阶段，遗忘概率的估值。由由于遗忘和回忆的随机性，即使所有相关突触的记忆强度和可检索性都相同，同一项目的回忆也同时存在成功和失败两种可能（取决于大脑当前的整体认知状况）！这样我们就可以讨论刚刚被回忆过（不管回忆是否成功）的项目的在下次重复前回忆成功率。该概率由遗忘指数的估值表示。
11. **计算 A-因子:** 通过 (1) 遗忘指数的估值、(2) 间隔长度和 (3) OF 矩阵，我们可以很容易地计算出 A-因子的最准确值。请注意，A-因子用作 OF 矩阵的索引，而遗忘指数的估值帮助我们找到 OF 矩阵中的列（*译注：从这段起有点混乱，笔者也没理解教授想表达的意思，OF 矩阵应该是用 A-因子作为列的索引，怎么一下子又变成“estimated forgetting index”了，搞不懂*），其中的数值表明了“最佳间隔”和“实际使用的间隔”之间的关系（“实际使用的间隔”需要根据（“遗忘指数的估值”与“期望遗忘指数”之间的）偏差进行校正）。在每次重复时，都会对旧的 A-因子值和新的 A-因子估值进行加权平均。新获得的 A-因子用于（在计算新的最佳重复间隔时）索引 OF 矩阵。

To sum it up. Repetitions result in computing a set of parameters characterizing the memory of the student: RF matrix, G-AF graph, and FI-G graph. They are also used to compute A-Factors of individual items that characterize the difficulty of the learned material. The RF matrix is smoothed up to produce the OF matrix, which in turn is used in computing the optimum inter-repetition interval for items of different difficulty ( A-Factor) and different number of repetitions (or memory lapses in the case of the first repetition). Initially, all student’s memory parameters are taken as for a less-than-average student (less-than average yields faster convergence than average or more-than-average), while all A-Factors are assumed to be equal (unknown).

最后做个总结，我们通过重复过程计算得到一组参数，用于表征学生的记忆特征：RF 矩阵、G-AF 图和 FI-G 图。它们还用于计算 A-因子，A-因子被用于表征学习材料中各个项目的难度。RF 矩阵被平滑以产生 OF 矩阵，OF 矩阵又用于计算不同难度（对应不同 A-因子）和不同重复次数（或同为初次重复但被遗忘的次数不同（*译注：注意前面提过被遗忘后的重复均视作初次重复，不管在遗忘前重复了多少次*））的项目的最佳重复间隔。最初，所有学生的记忆参数都与低于平均水平的学生一致（低于平均水平的初始参数收敛速度比平均水平或高于平均水平的参数更快），在假定所有 A-因子都相等的前提下（不确定实际情况是否如此）。

## 1997年：应用神经网络（1997: Employing neural networks）

### 神经网络：萌芽的兴趣（Neural Networks: Budding interest）

In the mid-1980s, I read Michael Arbib’s ” *Brains, Machines and Mathematics*“. It consolidated my view of the brain as an efficient computing machine.

二十世纪八十年代中期，我读了迈克尔·阿比的《大脑、机器与数学》。这本书巩固了我认为大脑本质上是一台高效计算机器的看法。

For anyone with an interest in how the brain works, and this is almost everyone, neural networks are naturally fascinating. While studying computer science, I gained a new, computational perspective of the brain and the neural networks. As neural networks have an uncanny capacity to do their own modelling, it may seem natural to employ them to study memory data to provide answers on how memory works. However, neural networks have one major shortcoming, they do not easily share their findings. It is a bit like the problem with the brain itself, it can do magic things and yet it is hard to say what is actually happening inside. It is fun to write neural network software, I dabbled in that in 1989. It is a bit less fun to see a neural network in action.

对于任何对大脑工作原理感兴趣的人（基本上就是所有人）来说，神经网络自然而然地具有吸引力。在学习计算机科学的过程中，我对大脑和神经网络有了新的、计算性的视角。由于神经网络具有不可思议的自我建模能力，因此似乎很自然地可以利用它们来研究记忆数据，以提供关于记忆工作原理的答案。然而，神经网络有一个主要的缺点，即它们不容易分享其发现。这有点像大脑本身的问题，它可以做神奇的事情，但却很难说出内部实际发生了什么。编写神经网络软件很有趣，我在1989年涉足过这个领域。但观察神经网络的运行则没那么有趣了。

The algebraic approach to SuperMemo outstripped neural networks for two reasons: (1) my questions about memory always seemed too simple to involve neural networks, and (2) networks need data, which need learning, which needs an algorithm, which needs answering simple questions. In this chicken-and-egg race, my brain was always a step ahead of what I might figure out from available data with a neural network.

采用代数方法来构建 SuperMemo 比（通过）神经网络更好，原因有两个：(1) 我对记忆的问题似乎总是过于简单，不需要涉及神经网络；(2) 网络需要数据，数据需要学习，学习需要算法，算法需要回答简单的问题。在这个“先有鸡还是先有蛋”的循环中，我的大脑在“从可用的数据中取得发现”这件事上，总是比神经网络还要领先一步。

The superiority of the algebraic approach is obvious if you consider that the optimum interval can be found by just plotting a forgetting curve and employing regression to find the point where recall drops below 90%. This was even more extreme in my 1985 experiment where my “forgetting curve” was made of just 5 points. I was able to pick the one I just liked most. That was a pre-school exercise. No big guns needed.

如果您考虑到可以通过绘制遗忘曲线并采用回归分析，来找到回忆成功率低于90%的点，从而找到最佳间隔，那么代数方法的优越性就显而易见了。关于这点，我在1985年的实验更为极端，当时我的“遗忘曲线”仅由5个点组成。我可以挑选自己最喜欢的那个点。当然那只能算是学前教育的水平。杀鸡焉用牛刀。

In 1990, when working on the model of intermittent learning, I came closest to employing neural networks. After a 7-hour-long discussion with Murakowski on Jul 06, 1990, we concluded that a neural network could provide some answers. However, my computer was already churning data using algebraic hill-climbing methods. In essence, this is similar to feature extraction in neural networks. Once I got my answers, that motivation has been taken away.

1990年，研究间歇学习模型的时期，是我与神经网络距离最近的一段时间。在1990年7月6日与穆拉科夫斯基（Murakowski）进行了7个小时的讨论后，我们得出结论，神经网络可以帮忙寻找一些答案。然而这时，我的计算机已经在使用代数爬山法处理数据了。从本质上讲，这类似于神经网络中的特征提取。之后我得到了答案，这种（利用神经网络研究的）动力就被消除了。

Nevertheless, in the mid-1990s, we had more and more questions about the adaptability of the algorithm, and the possibility of employing neural networks. Those questions were primarily raised by those who do not understand SuperMemo much. The model behind SuperMemo is simple, the optimization tools are simple, and they work pretty well to our satisfaction. The very first computational approach, Algorithm SM-2, is used to this day. Human dissatisfaction with memory usually comes from unreasonable expectations that are built via school curricula, and our poor ability to formulate knowledge for healthy consumption. This last habit is also perpetuated by the push for cramming that we bring from school. SuperMemo algorithms cannot remedy that dissatisfaction with learning. They have always performed well, and the last 30 years delivered progress that can be measured mathematically, but which does not easily translate into an increase in the pleasure of learning.

然而，在90年代中期，我们收到了越来越多的问题，主要是关于算法的适应性，和使用神经网络的可能性。这些问题主要由不了解 SuperMemo 的人提出。SuperMemo 背后的模型很简单，优化工具也很简单，并且它们运行得相当好，足够令我们满意。第一个计算方法，即算法 SM-2，一直沿用至今。人类对记忆的不满通常源于通过学校课程建立的不合理的期望，以及我们健康吸收与构建知识能力的匮乏。后者同样被学校给我们灌输的“填鸭式学习”雪上加霜。SuperMemo 算法无法弥补这种对学习的不满。但它们的表现一直很好，过去30年的进步可以用数学来衡量，只是不容易转化为学习乐趣的增加。

### 推动神经网络（Push for neural networks）

In the 1990s, mail to SuperMemo World often included hints that the neural network approach would be superior. Even a decade of use of SuperMemo would not prevent a student from writing:

> SuperMemo doesn’t take different user abilities and needs into account. Instead, it assumes that every learner is a “bad learner”. As such each learner will have the same repetition interval, its underlying algorithm is hardwired, but which might not be very efficient if you are a better/different learner. […] Neural networks take into account that there exist very different types of learners who need different optimum repetition intervals. When reviewing new words and by “telling” the programmes how well/bad they did the learner reveal more and more which type of learner they really are. After this feedback the programmes are able to adapt and optimise their underlying repetition intervals if necessary

在20世纪90年代，寄给 SuperMemo World 的邮件中经常包含这样的暗示：神经网络方法将更优越。即使使用 SuperMemo 十年，也无法阻止学生写下这样的内容：

> SuperMemo 没有考虑到不同的用户能力和需求。相反，它假设每个学习者都是“差学生”。因此，每个学习者都会有相同的复习间隔，其底层算法是固定的，但如果您是更好的/不同的学习者，这套算法可能就没那么高效了。[…] 神经网络考虑到存在各种各样（水平不一）的学习者，他们需要不同的最佳复习间隔。在复习新单词时，通过“告诉”程序他们做得有多好/多差，学习者会逐步揭示自己究竟属于哪种类型的学习者。在收到此反馈后，程序就能够在必要时调整并优化其底层的重复间隔。

Those words indicate lack of understanding of SuperMemo. SuperMemo does not use a “bad student model”. It only starts from shorter intervals before collecting first data about student’s memory. The choice of shorter intervals comes from a faster approximation of the optimum model. In other words, SuperMemo adapts to individual students, and the “less than average student model” might be attributed to the starting point before any data is collected.

这些话表明用户对 SuperMemo 缺乏理解。SuperMemo 不使用“差学生模型”。它只是从较短的间隔开始，收集有关学生记忆的第一批数据。选择较短的间隔是为了更快地逼近最佳模型。换句话说，SuperMemo 能适应不同的学生个体，“低于平均水平的学生模型”只是在还没收集到数据之前​​作为起点使用。

In SuperMemo, the average student model is used only as an initial condition in the process of finding the model of the actual student’s memory.

在 SuperMemo 中，平均学生模型仅作为寻找实际学生记忆模型过程中的一种初始条件使用。

In a finite-dimensional trajectory optimization, convergence is fastest for a good initial state guess. Although it is not the case in SuperMemo due to its simple 3-dimensional nature of the function of optimum intervals, in general case, the search for solutions may fail and the optimization will not work. Unlike the univalent matrices used in older SuperMemos for research purposes, a neural network algorithm would produce chaos without pre-training. This is why prior learning data are used to update the average or less-than-average student model used in SuperMemo for the maximum speed of convergence.

在有限维轨迹优化中，初始状态猜测越准确，收敛速度越快。但在一般情况下，针对解决方案的搜索可能会失败，优化将无法工作（尽管在 SuperMemo 中，由于最佳间隔函数的简单三维性质，这种情况并不存在）。与在较早的 SuperMemos 中出于研究目的而使用的单值矩阵不同，神经网络算法在没有预训练的情况下会产生混乱。这就是为什么使用先前的学习数据来更新 SuperMemo 中使用的平均水平或低于平均水平的学生模型，以实现最大收敛速度的原因。

Note that this average student approach is even less significant in Algorithm SM-17 due to the use of best-fit approximations for multiple parameters and functions in the learning process (e.g. item difficulty, stability increase function, etc.). This means that SuperMemo will always make the best of available data (using our current best knowledge of memory models).

请注意，由于使用了多个与学习过程相关的参数和函数（例如项目难度、稳定性增加函数等）的最佳拟合近似值，因此在算法 SM-17中，这种平均学生模型的重要性甚至进一步降低。这意味着 SuperMemo 将始终（根据我们目前对记忆模型的最佳了解）充分利用可用数据。

The approximate shape of the forgetting curve has been known for over a century now (see: Error of Ebbinghaus forgetting curve). SuperMemo collects precise data on the shape of forgetting curves for items of different difficulty and different memory stability. From forgetting curves, SuperMemo easily derives the optimum interval. The data comes from only one student and each repetition contributes to the precision of the computation. In other words, with every minute you spend with SuperMemo, the program knows you better and better. Moreover, it knows you well enough after a month or two. You never need to worry about the efficiency of the algorithm.

遗忘曲线的近似形状已经为人所知超过一个世纪了（参见：艾宾浩斯遗忘曲线的误差）。SuperMemo 收集有关不同难度和不同记忆稳定性的项目的遗忘曲线形状的精确数据。而有了遗忘曲线，SuperMemo 就能轻松推导出最佳间隔。数据仅来自一名学生，每次重复都有助于提高计算精度。换句话说，您与 SuperMemo 共度的每一分钟，程序都会越来越了解您。而且，一两个月后，它就足够了解您了。您无需担心算法的效率。

There is an aura of mystique around neural networks. They are supposed to reveal hidden properties of the studied phenomena. It is easy to forget that networks can fail easily when they are fed with wrong information or with some vital information missing. This was the case with the only functional neural network used in spaced repetition: MemAid by David Calinski.

神经网络周围笼罩着一层神秘的光环。它们通常用于揭示被研究的现象的隐藏属性。但人们很容易忘记，当网络被错误信息喂养或缺少一些重要信息时，它们很容易失败。David Calinski 所制作的 MemAid 就是一个典型的，在间隔重复中只使用功能性神经网络的案例。

The error in the design of MemAid network came from using Interval + Repetition Count on the input to represent the status of memory, while these two variables do not correspond with the Stability : Retrievability pair. Stability and Retrievability have been proven necessary to represent the status of a long-term memory trace. In other words, the network does not get all the information it needs to compute the optimum interval. A better design would code the entire repetition history, e.g. with the use of stability and retrievability variables. Full repetition history is needed to account for the spacing effect of massed presentation or a significant boost in stability for passing grades in delayed repetitions. Calinski’s design would, however, meet basic requirements for learning in “optimum” intervals with few departures from the rules of spaced repetition (as much as Algorithm SM-2).

MemAid 网络设计中的错误源于使用“间隔+重复次数”作为输入来表示记忆状态，而这两个变量与“稳定性：可检索性”这对变量并不对应。稳定性和可检索性已被证明是表示长期记忆痕迹状态所必需的。换句话说，网络没有获得计算最佳间隔所需的所有信息。更好的设计应该是对整个重复历史进行编码，例如使用稳定性和可检索性作为变量。需要完整的重复历史，才能解释大规模呈现的间隔效应，或者是延迟重复中稳定性的显着提高。然而，Calinski 的设计还是能够满足在“最佳”间隔内学习的基本要求，与间隔重复规则（如 SM-2 算法）的偏差很小。

### SuperMemo 不够灵活吗？（Is SuperMemo inflexible?）

It is not true that SuperMemo is prejudiced while a neural network is not. Nothing prevents the optimization matrices in SuperMemo to depart from the memory model and produce an unexpected result. It is true that over years, with more and more knowledge of how memory works, the algorithm used in SuperMemo has been armed with restrictions and customized sub-algorithms. None of these was a result of a wild guess though. The progression of “prejudice” in SuperMemo algorithms is only a reflection of findings from the previous years. The same would inevitably affect any neural network implementation if it wanted to maximize its performance.

并不是只有 SuperMemo 有偏见（预设偏差），而神经网络就没有。没有什么可以阻止 SuperMemo 中的优化矩阵偏离记忆模型并产生意外结果。确实，多年来，随着对记忆工作原理的了解越来越多，SuperMemo 中使用的算法已经被施加了限制，配备了定制的子算法。然而，这些都不是凭空猜测的结果。SuperMemo 算法中“偏见（预设偏差）”的进展只是前几年研究结果的反映。如果神经网络实现想要最大限度地提高其性能，它也必然会受到同样的影响。

It is also not true that the original pre-set values of optimization matrices in SuperMemo are a form of prejudice. These are an equivalent of pre-training in a neural network. A neural network that has not been pre-trained will also be slower to converge onto the optimum model. This is why SuperMemo is “pre-trained” with the model of an average student.

认为 SuperMemo 中优化矩阵的原始预设值是一种偏见，这也是不正确的。这些相当于神经网络中的预训练。没有经过预训练的神经网络收敛到最佳模型的速度也会更慢。这就是为什么 SuperMemo 使用平均学生的模型进行“预训练”。

The rate of interval increase is determined by the matrix of optimum intervals and is by no means constant. Moreover, the matrix of optimum intervals changes in time depending on the user’s performance. You may have an impression of a fixed or rigid algorithm only after months or years of use (the speed of change is inversely proportional to the available learning data). This convergence reflects the invariability of the human memory system. It does not matter if you use the algebraic or neural approach to the optimization problem. In the end, you will arrive at the spaced repetition function that reflects the true properties of your memory. In that light, the speed of convergence should be held as a benchmark of the algorithm’s quality. In other words, the faster the interval function becomes “fixed”, the better.

间隔增加的速度由最佳间隔矩阵决定，绝不是恒定的。此外，最佳间隔矩阵会根据用户的表现而随时间变化。您可能只有在数月乃至数年的使用后，才会对算法是固定的还是刚性的产生印象（算法变化速度与可用学习数据（*译注：即已累积的学习数据*）成反比）。这种收敛反映了人类记忆系统的恒定性。您使用代数方法还是神经网络方法来解决优化问题都无关紧要。最终，您总能得到真实反映您记忆属性的间隔重复函数。从这个角度来看，收敛速度应被视为算法质量的基准。换句话说，间隔函数“固定”得越快，越好。

Finally, there is another area where neural networks must either use the existing knowledge of memory models (i.e. carry a dose of prejudice) or lose out on efficiency. The experimental neural network SuperMemo, MemAid, as well as FullRecall have all exhibited an inherent weakness. The network achieves the stability when the intervals produce a desired effect (e.g. specific level of the measured forgetting index). Each time the network departs from the optimum model it is fed with a heuristic guess on the value of the optimum interval depending on the grade scored during repetitions (e.g. grade=5 would correspond with 130% of the optimum interval in SuperMemo NN or 120% in MemAid). The algebraic SuperMemo, on the other hand, can compute a difficulty estimate, use the accurate retention measurement, and produce an accurate adjustment of the value of the stability increase matrix. In other words, it does not guess on the optimal interval. It computes its exact value for that particular repetition. The adjustments to the memory matrices are weighted and produce a stable non-oscillating convergence. In other words, it is the memory model that makes it possible to eliminate the guess factor. With that respect, the algebraic SuperMemo is less prejudiced than the neural network SuperMemo.

最后，还有一个领域，神经网络如果不使用现有的记忆模型知识（即带有偏见），就会失去效率。实验性神经网络 SuperMemo、MemAid 以及 FullRecall 都表现出固有的弱点。当间隔产生预期效果（例如，测得的遗忘指数达到特定水平）时，网络保持稳定。当网络偏离最佳模型时，则每次都会根据重复期间获得的（响应）评分（例如，5分在 SuperMemo NN 中对应于最佳间隔的130%，在 MemAid 中对应于最佳间隔的120%）对最佳间隔的值进行启发式猜测。另一方面，代数 SuperMemo 可以计算难度估值，对保留率进行准确测量，并对稳定性增加矩阵中的值进行准确调整。换句话说，它不会猜测最佳间隔。而是为特定重复计算其（最佳间隔的）确切值。对记忆矩阵的调整是加权的，并产生稳定的非振荡收敛。换句话说，正是记忆模型使得消除猜测成分成为可能。在这方面，代数 SuperMemo 比神经网络 SuperMemo 偏见（预设偏差）更小。

### 微调间隔重复算法已成徒劳（Futility of the fine-tuning the spaced repetition algorithm）

Algorithm SM-17 is a major step forward, however, many users will not notice the improvement and stick with the older algorithms. This perception problem led to the “SM3+ myth”, which I tried to dispel in this article. At the same time, the value of the new algorithm for further progress in research is astronomical. In other words, there is a big dissonance between practical needs and theoretical needs. My words in an interview for Enter, 1994, still ring true:

SM-17 算法是一个重大进步，但是，许多用户不会注意到改进并坚持使用旧算法。这种感知问题导致了“SM3+ 误解”，我试图在本文中消除它。同时，新算法对进一步研究的价值是巨大的。换句话说，实践需求和理论需求之间存在巨大差异。我在 1994 年接受 Enter 采访时所说的话仍然适用：

> We have already seen that evolution speaks for SuperMemo, findings in the field of psychology coincide with the method, and that facts of molecular biology and conclusions coming from Wozniak’s model seem to go hand in hand. Here is the time to see how the described mechanisms have been put to work in the program itself. In the course of repetitions, SuperMemo plots the forgetting curve for the student and schedules the repetition at the moment where the retention, i.e. proportion of remembered knowledge, drops to a previously defined level. In other words, SuperMemo checks how much you remember after a week and if you remember less than desired it asks you to make repetitions in intervals less than one week long. Otherwise, it checks the retention after a longer period and increases the intervals accordingly. A little kink to this simple picture comes from the fact that items of different difficulty have to be repeated at different intervals, and that the intervals increase as the learning process proceeds. Moreover, the optimum inter-repetition intervals have to be known for an average individual, and these must be used before the program can collect data about the real student. There must be obviously the whole mathematical apparatus involved to put the whole machinery at work. All in all, Wozniak says that there have been at least 30 days in his life when he had an impression that the algorithms used in SuperMemo have significantly been upgraded. Each of the cases seemed to be a major breakthrough. The whole development process was just a long succession of trials and errors, testing, improving, implementing new ideas, etc. Unfortunately, those good days are over. There have not been any breakthrough improvement to the algorithm since 1991. Some comfort may come from the fact that since then the software started developing rapidly providing the user with new options and solutions. Can SuperMemo then be yet better, faster, more effective? Wozniak is pessimistic. Any further fine-tuning of the algorithms, applying artificial intelligence or neural networks would be drowned in the noise of interference. After all, we do not learn in isolation from the world. When the program schedules the next repetition in 365 days, and the fact is recalled by chance at an earlier time, SuperMemo has no way of knowing about the accidental recollection and will execute the repetition at the previously planned moment. This is not optimal, but it cannot be remedied by improving the algorithm. Improving SuperMemo now is like fine tuning a radio receiver in a noisy car assembly hall. The guys at SuperMemo World are now less focused on science. In their view, after the scientific invention, the time has come for the social invention of SuperMemo.
> 
> 我们已经看到，进化论支持 SuperMemo，心理学领域的发现也与该方法一致，分子生物学的事实和来自 Wozniak 模型的结论似乎也是一致的。现在是时候看看我们所描述的机制是如何在程序本身中发挥作用的了。在重复过程中，SuperMemo 绘制学生的遗忘曲线，并在保留率（即记住的知识比例）下降到先前定义的水平时安排重复。换句话说，SuperMemo 检查一周后您记住了多少，如果您的记忆量低于预期，它会要求您以不到一周的间隔进行重复。否则，它会在更长的时间后检查保留率并相应地增加间隔。这个简单图景中出现了一点小问题，即不同难度的项目必须以不同的间隔重复，并且随着学习过程的进行，间隔会增加。此外，必须知道普通个体的最佳重复间隔，并且在程序可以收集有关真实学生的数据之前，必须使用这些间隔。很明显，必须使用整个数学装置来使整个机器运转起来。总而言之，Wozniak 说，在他的一生中，至少有 30 天他有一种印象，即 SuperMemo 中使用的算法有了显著升级。每一个案例似乎都是一个重大的突破。整个开发过程只是一系列的反复试验、故障、测试、改进、实施新想法等。不幸的是，那些美好的日子已经过去了。自 1991 年以来，算法没有任何突破性的改进。令人欣慰的是，自那时以来，软件本身开始迅速发展，为用户提供了新的选项和解决方案。那么，SuperMemo 还能变得更好、更快、更有效吗？Wozniak 悲观地认为。对算法进行任何进一步的微调、应用人工智能或神经网络都将淹没在干扰的噪音中。毕竟，我们不会与世隔绝地学习。当程序在 365 天后安排下一次重复，而事实上，回忆在更早的时间已经偶然发生，SuperMemo 无法知道这种偶然的回忆，并且将在先前计划的时间执行重复。这就不是最佳时机，但也不能通过改进算法来弥补。现在改进 SuperMemo 就像在嘈杂的汽车装配大厅中微调收音机一样。SuperMemo World 的人现在不太关注科学（方面的改进空间）。在他们看来，在 SuperMemo 的科学创新之后，是时候进行 SuperMemo 的社会创新了。

### Dreger 的神经网络项目（Dreger’s Neural Network Project）

On May 20, 1997, my net buddy from the pre-web BBS era, Bartek Dreger, came up with a great idea. He would also write his Master’s Thesis about SuperMemo at Institute of Computer Science at Poznan University of Technology. That would be 8 years after my own, except he would use neural networks to see how they performed. Despite being nearly two decades younger, his plan was to try this project in the same great Węglarz operation research team I mention often elsewhere in this text. As early as in 1990, Dr Nawrocki came up with the idea to use neural networks to improve SuperMemo. The great mind of Prof. Roman Słowiński was to be the supervisor. This could really work.

1997年5月20日，我在前网络 BBS 时代的网友 Bartek Dreger 提出了一项很棒的想法。他也会在波兹南理工大学计算机科学研究所撰写他关于 SuperMemo 的硕士论文。这比我自己的论文晚了8年，但他将使用神经网络并观察它们的表现。尽管他年轻了近二十岁，但他计划在 Węglarz 这个伟大的运筹学团队中尝试这个项目，我在本文其他地方也经常提到这个团队。早在 1990 年，Nawrocki 博士就提出了使用神经网络来改进 SuperMemo 的想法。伟大的 Roman Słowiński 教授将成为监督者。这也许真的可以奏效。

By June 1997, another of my net buddies, Piotr Wierzejewski, joined the project. Then 3 more computer science students climbed aboard. It was a lovely team of five young brains with a combined age of 100. Soon the project was extended by the idea of on-line SuperMemo nicknamed: WebSorb (for the absorption of knowledge from the web). As it often happens in enthusiastic young teams, we started putting too much on the plate, and in the end, only a fraction of the goals has been attained. Only the on-line SuperMemo idea kept evolving and branching out in a meandering fashion with several mini-projects born and dying (e.g. e-SuperMemo, Quizer, Super-Memorizer, Memorathoner, etc.) until the emergence of 3GEMs that became supermemo.net that ultimately evolved into today’s supermemo.com.

到 1997 年 6 月，我的另一个网络好友 Piotr Wierzejewski 加入了该项目。然后又有 3 名计算机科学专业的学生加入。这是一个可爱的年轻团队，有 5 颗大脑，总年龄却仅有 100 岁。很快，该项目通过在线 SuperMemo 的想法进行了扩展，我们给在线 SuperMemo 的昵称是 WebSorb（名字取材于从网络（web）吸收（absrob）知识）。正如在充满激情的年轻团队中经常发生的那样，我们开始承担太多任务，最终，只有部分目标得以实现。但在线 SuperMemo 的想法不断发展壮大，以曲折的方式分支，并导致了数个迷你项目的诞生和死亡（例如 e-SuperMemo、Quizer、Super-Memorizer、Memorathoner 等），直到 3GEMs 出现，随后演变为 supermemo.net，并最终演变为今天的 supermemo.com。

The greatest advantage of youth in similar projects is creativity and passion. The greatest obstacle is schooling, and later, other obligations, including having children. This fantastic brain trust fell victim to the ages old problem of school: converting a project born in passion into a project that became a school chore with deadlines, reports, tests, exams, and grades. As explained here, SuperMemo was also born in that risky school environment. The key to success is the fight for freedom. Bondage destroys passions. The idea of SuperMemo survived the pressure of schooling because of my push for educational freedom.

在类似项目中，年轻人的最大优势是创造力和激情。最大的障碍是学校教育，以及后来的其他义务，包括养育子女。这个梦幻般的智囊团也成为了学校这个古老问题的受害者：将一个充满激情的项目转化为一个带有截止日期、报告、测试、考试和成绩的学校任务。如本文所述，SuperMemo 也是在这种高风险的校园环境中诞生的。成功的关键是争取自由。束缚会摧毁激情。SuperMemo 的想法之所以能够承受住学校压力的考验，是因为我竭力争取教育自由。

### 神经网络 SuperMemo：为什么记忆模型在 SuperMemo 算法中至关重要（Neural Network SuperMemo : Why memory model is vital in SuperMemo algorithms）

Feature extraction proposed for spaced repetition neural networks is based on a well-proven existence of two components of long-term memory described here.

为间隔重复神经网络进行的特征提取，是以此处描述的，已被良好证明的，长时记忆两个组成部分为基础。

The two memory variables are sufficient to represent the status of an atomic memory trace in learning. Those variables make it possible to compute optimum intervals and account for the spacing effect. The function of increased memory stability for delayed repetitions is also known. For those reasons, a simple optimization algorithm makes it easy and fast to determine optimum repetition spacing in SuperMemo. A neural network would need to code the full repetition history for each item and the most obvious coding choices are memory stability (S) and memory retrievability (R). In other words, the same assumptions underlie the design of repetition spacing algorithms: algebraic or neural. Needless to say, the algebraic solution is easy and fast. It converges fast. It requires no pre-training (memory model is encapsulated in the matrix of optimum intervals).

这两个记忆变量足以表示学习中记忆痕迹在原子层面的状态。这些变量使得计算最佳间隔和解释间隔效应成为可能。延迟重复的记忆稳定性增加函数也是已知的。出于这些原因，简单的优化算法可以轻松快速地确定 SuperMemo 中的最佳重复间隔。神经网络需要为每个项目的完整重复历史进行编码，最明显的编码选择是记忆稳定性 (S) 和记忆可检索性 (R)。换句话说，相同的假设构成了重复间隔算法设计的基石：不管是代数算法还是神经网络。毋庸置疑，代数解法简单快捷。它收敛速度快。而且也不需要预训练（记忆模型封装在最佳间隔矩阵中）。

A neural network working with full repetition histories will produce the same outcome as a hill-climbing algorithm employed in building stability of memory. Hill-climbing is simply a better/faster tool for the job. It will carry the same limitations as neural networks, i.e. the answers will be as good as the question posed.

基于完整重复历史的神经网络，和与用于构建记忆稳定性的爬山算法，二者将产生相同的结果。爬山是一种更好/更快的工具。它和神经网络具有相同的局限性，即答案有多好，取决于问题设计得有多好。

### 神经网络 SuperMemo：设计阶段（Neural Network SuperMemo: Design）

With Bartek Dreger we designed a simple ANN system for handling the spaced repetition problem (Dec 1997). Note that this project would not be possible without the expertise of Dr Krzysztof Krawiec who was helpful in polishing the design:

1997年12月，我们与 Bartek Dreger 合作，设计了一个简单的人工神经网络（ANN）系统，用于处理间隔重复问题。值得一提的是，如果没有 Krzysztof Krawiec 博士的专业知识，这个项目是不可能实现的，他在完善设计方面提供了很大帮助。

Archive warning: Why use literal archives?

下面是引用文档

The repetition spacing problem consists in computing optimum inter-repetition intervals in the process of human learning. The intervals are computed for individual pieces of information (later called items) and for a given individual. The entire input data are grades obtained by the student in repetitions of items in the learning process. This problem has until now be most effectively solved by means of a successive series of algorithms known commercially as SuperMemo and developed by Dr. Wozniak at SuperMemo World, Poland. Wozniak’s model of memory used in developing the most recent version of the algorithm ( Algorithm SM-8) cannot be considered as the ultimate algebraic description of human long-term memory. Most notably, the relationship between the complexity of the synaptic pattern and item difficulty is not well understood. More light on this relationship might be shed once a neural network is employed to provide adequate mapping between the memory status, grading and the item difficulty.

重复间隔问题在于计算人类学习过程中的最佳重复间隔。这些间隔的计算是针对单个信息片段（后称为项目）和特定个体（人）的。所有输入数据都是学生在学习过程中，进行项目重复时取得的成绩（响应评分）。迄今为止，这个问题最有效的解决方案是通过一系列连续的算法（在商业上被称为 SuperMemo，由在波兰 SuperMemo World 工作的 Wozniak 博士开发）。Wozniak 用于开发最新版本算法（算法 SM-8）的记忆模型还不能被视为人类长期记忆的终极代数描述。最值得注意的是，突触模式的复杂性和项目难度之间的关系尚不清楚。等神经网络帮忙找到记忆状态、评分和项目难度之间的适当映射之后，我们可能会对这种关系有更深入的了解。

Using current state-of-the-art solutions, the technical feasibility of a neural network application in a real-time learning process seems to depend on the appropriate application of the understanding of the learning process to adequately define the problems that will be posed to the neural network. 

使用当前最先进的解决方案，将神经网络应用在实时学习过程的技术可行性，似乎取决于我们能否正确运用对学习过程的理解，以充分定义将向神经网络提出的问题。

It would be impossible to expect the network to generate the solution upon receiving the input in the form of the history of grades given in the course of repetitions of thousands of items. The computational and space complexity of such an approach would naturally run well beyond the network’s ability to learn and respond in real time.

期望网络在接收千上万个项目在重复过程中给出的历史成绩（作为输入），然后直接生成生成解决方案（作为输出）是不可能的。这种方法的计算难度和空间复杂性自然会远远超出网络实时学习和响应的能力。

Using Wozniak’s model of two components of long-term memory we postulate that the following neural network solution might result in fast convergence and high repetition spacing accuracy.

利用 Wozniak 的提出的长期记忆的二元模型，我们假设以下神经网络解决方案最终能快速收敛，并高度准确地计算出重复间隔。

The two memory variables needed to describe the state of a given engram are retrievability (R) and stability (S) of memory ( Wozniak, Gorzelańczyk, Murakowski, 1995). The following equation relates R and S:

(1) R=e <sup>-k/S*t</sup>

where:

-   k is a constant
-   t is time

描述给定记忆痕迹状态所需的两个变量分别是可检索性（R）和稳定性（S）（Wozniak, Gorzelańczyk, Murakowski, 1995）。以下等式描述了 R 和 S 的关系：

(1) R=e <sup>-k/S*t</sup>

其中：

- k 是一个常数
- t 是时间

By using Eqn (1) we conclude about changes of retrievability in time at a given stability, as well as we can determine the optimum inter-repetition interval for given stability and given forgetting index.

通过使用等式 (1)，我们可以在给定稳定性的前提下，计算出可检索性随时间的变化关系，并且可以确定给定稳定性和给定遗忘指数下的最佳重复间隔。

The exact algebraic shape of the function that describes the change of stability upon a repetition is not known. However, experimental data indicate that stability usually increases from 1.3 to 3 times for properly timed repetitions and depends on item difficulty (the greater the difficulty the lower the increase). By providing the approximation of the optimum repetition spacing taken from experimental data as produced by optimization matrices of Algorithm SM-8, the neural network can be pre-trained to compute the stability function:

(2) S <sub>i+1</sub>=f <sub>s</sub>(R,Si,D,G)

where:

-   S <sub>i</sub> is stability after the i-th repetition
-   R is retrievability before repetition
-   D is item difficulty
-   G is grade given in the i-th repetition

描述重复后稳定性变化的函数，其确切代数形式尚不清楚。然而，实验数据表明，在适时重复的情况下，稳定性通常会增加1.3到3倍，并与项目难度相关（难度越大，增加幅度越小）。通过提供最佳重复间隔的近似值（从 SM-8 算法的优化矩阵生成的实验数据中获得），可以对神经网络进行预训练以计算稳定性函数：

(2) S <sub>i+1</sub>=f <sub>s</sub>(R,Si,D,G)

其中：

- S <sub>i</sub> 是第 i 次重复后的稳定性
- R 是重复前的可检索性
- D 是项目难度
- G 是第 i 次重复的评分

The stability function is the first function to be determined by the neural network. The second one is the item difficulty function with analogous input parameters:

(3) D <sub>i+1</sub>=f <sub>d</sub>(R,S,Di,G)

where:

-   D <sub>i</sub> is item difficulty approximation after the i-th repetition
-   R is retrievability before repetition
-   S is stability after the i-th repetition
-   G is grade given in the i-th repetition

稳定性函数是神经网络要确定的第一个函数。第二个是具有类似输入参数的项目难度函数：

(3) D <sub>i+1</sub>=f <sub>d</sub>(R,S,Di,G)

其中：

- D <sub>i</sub> 是第 i 次重复后的项目难度近似值
- R 是重复前的可检索性
- S 是重复后的稳定性
- G 是第 i 次重复的评分

Consequently, a neural network with four inputs (D, R, S and G) and two outputs (S and D) can be used to encapsulate the entire knowledge needed to compute inter-repetition intervals (see: Implementation of the repetition spacing neural network).

因此，可以使用具有四个输入（D、R、S 和 G）和两个输出（S 和 D）的神经网络来封装计算重复间隔所需的所有知识（参见：重复间隔神经网络的实现）。

The following approach will be taken in order to verify the feasibility of the aforementioned approach:

1.  Pretraining of the neural network will be done on the basis of approximated S and D functions derived from functions used in Algorithm SM-8 and experimental data collected thereof
2.  Such a pretrained network will be implemented as a SuperMemo Plug-In DLL that will replace standard sm8opt.dll used by SuperMemo 8 for Windows. The teaching of the network will continue in a real learning process in alpha testing of the neural network DLL. A procedure designed specifically for the purpose of the experiment will be used to provide cumulative results and a resultant neural network. The procedure will use neural networks used in alpha testing for training the network that will take part in beta-testing. The alpha-testing networks will be fed with a matrix of input parameters and their output will be used in as training data for the resultant network
3.  In the last step, beta-testing of the neural network will be open to all volunteers over the Internet directly from the SuperMemo Website. The volunteers will only be asked to submit their resultant networks for the final stage of the experiment in which the ultimate network will be developed. Again, the beta-testing networks will all be used to train the resultant network. Future users of neural network SuperMemo (if the project appears successful) will obtain a network with a fair understanding of the human memory and able to further refine its reactions to the interference of the learning process with day-to-day activities of a particular student and particular study material.

为了验证上述方法的可行性，将采取以下方法：

1. 神经网络的预训练将基于近似 S 和 D 函数进行，这两个近似函数源于算法 SM-8 中使用的函数以及由此收集的实验数据。
2. 这样的预训练网络将被实现为一个 SuperMemo 插件 DLL，它将替换 SuperMemo 8 在 Windows 系统下使用的标准 sm8opt.dll。在 alpha 测试中，神经网络 DLL 将在真实的学习过程中进行训练。将使用专门为实验目的设计的流程来进行结果累积，并生成最终的神经网络。该过程将使用 alpha 测试中使用的神经网络来训练将参与 beta 测试的神经网络网络。 alpha 测试网络将接收一个输入参数矩阵，其输出将作为训练数据被最终的神经网络使用。
3. 在最后一步，神经网络的 beta 测试将通过 SuperMemo 网站直接向所有志愿者开放。志愿者只需提交其生的成网络即可用于实验的最后阶段，最终的神经网络将由此开发而成。同样，所有 beta 测试网络都将用于训练生成网络。如果项目成功，未来神经网络 SuperMemo 的用户将获得对人类记忆有相当程度的理解的网络，并且能够进一步改进其对学习过程中所遭遇的干扰的反应（学习过程应以每日活动的形式进行，并且与特定的学生和学习材料对应）。

The major problem in all spacing algorithms is the delay between comparing the output of the function of optimum intervals with the result of applying a given inter-repetition interval in practise. On each repetition, the state of the network from the previous repetition must be remembered in order to generate the new state of the network. In practise, this equates to storing an enormous number of network states in-between repetitions.

所有间隔算法的主要问题是延迟，这里的延迟指的是从“最佳间隔函数给出输出”到“实际应用给定重复间隔得到结果”之间的延迟。在每次重复时，必须记住来自先前重复的网络状态，以便生成新的网络状态。实际上，这相当于在重复之间存储大量网络状态。

Luckily, Wozniak’s model implies that functions S and D are time-independent (interestingly, they are also likely to be user-independent!); therefore, the following approach may be taken for simplifying the procedure:

| Time moment                 | T1                                                                        | T2                                                                                            | T3                                                                                            |
| --------------------------- | ------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |
| Decision                    | I <sub>1</sub>N <sub>1</sub>O <sub>1</sub>=N <sub>1</sub>(I <sub>1</sub>) | I <sub>2</sub>N <sub>2</sub>O <sub>2</sub>=N <sub>2</sub>(I <sub>2</sub>)                     | I <sub>3</sub>N <sub>3</sub>O <sub>3</sub>=N <sub>3</sub>(I <sub>3</sub>)                     |
| Result of previous decision |                                                                           | O\* <sub>1</sub>E <sub>1</sub>=O\* <sub>1</sub>-O <sub>1</sub>                                | O\* <sub>2</sub>E <sub>2</sub>=O\* <sub>2</sub>-O <sub>2</sub>                                |
| Evaluation for teaching     |                                                                           | O’ <sub>1</sub>=N <sub>2</sub>(I <sub>1</sub>)E’ <sub>1</sub>=O* <sub>1</sub>-O’ <sub>1</sub> | O’ <sub>2</sub>=N <sub>3</sub>(I <sub>2</sub>)E’ <sub>2</sub>=O* <sub>2</sub>-O’ <sub>2</sub> |

Where:

-   E <sub>i</sub> is an Error bound with O <sub>i</sub> (see error correction for memory stability and error correction for item difficulty)
-   E’ <sub>i</sub> is an Error bound with O’ <sub>i</sub>
-   I <sub>i</sub> are input data at T <sub>i</sub>
-   N <sub>i</sub> is the network state at T <sub>i</sub>
-   O <sub>i</sub> is an output decision of N <sub>i</sub> being given I <sub>i</sub>, that is the decision after i-th repetition made at T <sub>i</sub>
-   O* <sub>i</sub> is an optimum output decision, that should be obtained at T <sub>i</sub> instead of O <sub>i</sub>; it can be computed from the grade and O <sub>i</sub> (the grade indicates how O <sub>i</sub> should have changed to obtain better approximation)
-   O’ <sub>i</sub> is an output decision of N <sub>i+1</sub> given I <sub>i</sub>, that is the decision after i-th repetition that would be made at T <sub>i+1</sub>
-   T <sub>i</sub> is time of the i-th repetition of a given item

幸运的是，Wozniak 的模型暗示函数 S 和 D 与时间无关（有趣的是，它们看起来似乎与用户也无关！）；因此，可以采用以下方法来简化程序：

| 时刻      | T1                                                                        | T2                                                                                            | T3                                                                                            |
| ------- | ------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |
| 决策      | I <sub>1</sub>N <sub>1</sub>O <sub>1</sub>=N <sub>1</sub>(I <sub>1</sub>) | I <sub>2</sub>N <sub>2</sub>O <sub>2</sub>=N <sub>2</sub>(I <sub>2</sub>)                     | I <sub>3</sub>N <sub>3</sub>O <sub>3</sub>=N <sub>3</sub>(I <sub>3</sub>)                     |
| 先前决策的结果 |                                                                           | O\* <sub>1</sub>E <sub>1</sub>=O* <sub>1</sub>-O <sub>1</sub>                                 | O\* <sub>2</sub>E <sub>2</sub>=O* <sub>2</sub>-O <sub>2</sub>                                 |
| 用于教学的评估 |                                                                           | O’ <sub>1</sub>=N <sub>2</sub>(I <sub>1</sub>)E’ <sub>1</sub>=O* <sub>1</sub>-O’ <sub>1</sub> | O’ <sub>2</sub>=N <sub>3</sub>(I <sub>2</sub>)E’ <sub>2</sub>=O* <sub>2</sub>-O’ <sub>2</sub> |


其中：

- E <sub>i</sub> 是 O <sub>i</sub> 的误差界限（参见记忆稳定性的误差校正和项目难度的误差校正）
- E’ <sub>i</sub> 是 O’ <sub>i</sub> 的误差界限
- I <sub>i</sub> 是 T <sub>i</sub> 时的输入数据
- N <sub>i</sub> 是 T <sub>i</sub> 的（神经）网络状态
- O <sub>i</sub> 是给定 I <sub>i</sub> 时 N <sub>i</sub> 的输出决策，即在 T <sub>i</sub> 进行的第 i 次重复后的决策
- O* <sub>i</sub> 是一个最佳输出决策，应该在 T <sub>i</sub> 而不是 O <sub>i</sub> 获得；它可以从评分和 O <sub>i</sub> 计算得出（评分表明 O <sub>i</sub> 应该如何改变以获得更好的近似值）
- O’ <sub>i</sub> 是给定 I <sub>i</sub> 时 N <sub>i+1</sub> 的输出决策，即在 T <sub>i+1</sub> 进行的第 i 次重复后的决策
- T <sub>i</sub> 是给定项目的第 i 次重复的时间

The above approach requires only I <sub>i-1</sub> to be stored for each item between repetitions taking place at T <sub>i-1</sub> and T <sub>i</sub> with substantial saving to the amount of data stored during the learning process (E’ <sub>i</sub> is as valuable for training as E <sub>i</sub>). This way the proposed solution is comparable for its space complexity with the Algorithm SM-8! Only one (current) state of the neural network has to be remembered throughout the process.

上述方法仅需要在 T <sub>i-1</sub> 和 T <sub>i</sub> 两次重复之间的时间段，为每个项目存储 I <sub>i-1</sub>，从而大大节省了学习过程中存储的数据量（就训练用途来看，E’ <sub>i</sub> 与 E <sub>i</sub> 价值相当）。通过这种方式，所提出的解决方案在空间复杂性上与算法 SM-8 相当！在整个过程中，只需要记住神经网络的一个状态（当前状态）即可。

These are the present implementation assumptions for the discussed project:

-   neural network: unidirectional, layered, with resilient back-propagation; an input layer with four neurons, an output layer with two neurons, and two hidden layers (15 neurons each)
-   item difficulty interpretation: same as in Algorithm SM-8, i.e. defined by A-Factor
-   each item stores: Last repetition date, Stability (at last repetition), Retrievability (at last repetition), Item difficulty, Last grade
-   default forgetting index: 10%
-   network DLL input (at each repetition): item number and the current grade
-   network DLL output (at each repetition): next repetition date
-   neural network DLL implementation language: C++
-   neural network DLL shell: SuperMemo 98 for Windows (same as the 32-bit SM8OPT.DLL shell)

以下是讨论项目目前的实现假设：

- 神经网络：单向、分层，具有弹性反向传播；一个包含四个神经元的输入层，一个包含两个神经元的输出层，以及两个隐藏层（每层 15 个神经元）。
- 项目难度的解释：与算法 SM-8 相同，即由 A-Factor 定义。
- 每个项目需要存储的信息：上次重复日期、稳定性（上次重复时的稳定性）、可检索性（上次重复时的可检索性）、项目难度、上次评分（最近评分）。
- 默认遗忘指数：10%。
- 网络 DLL 输入（每次重复时）：项目编号和当前评分。
- 网络 DLL 输出（每次重复时）：下次重复日期。
- 神经网络 DLL 实现语言：C++。
- 神经网络 DLL 外壳：SuperMemo 98 for Windows（与 32 位 SM8OPT.DLL 外壳相同）

### 神经网络 SuperMemo：实现阶段（Neural Network SuperMemo: Implementation）

The network has practically been given the spaced repetition algorithm on a silver platter. Its only role would be to fine-tune the performance over time. This is exactly what all SuperMemo algorithms do as of Algorithm SM-5. In that sense, the design did not ask the network for a discovery. It asked for improvements upon the discovery. The model was wired in into the design.

实际上，神经网络已经获得了一个现成的间隔重复算法。它唯一的使命是随着时间的推移微调性能。这正是从算法 SM-5 开始，所有 SuperMemo 算法都在做的事情。从这个意义上讲，我们的设计并没有要求（神经）网络进行新发现，而是要求它在已有的发现基础上进行改进。该模型已经融入到设计中。

Archive warning: Why use literal archives?

下面是引用文档

#### 基本假设（Basic assumption）

The state of memory will be described with only two variables: retrievability (R) and stability (S) ( Wozniak, Gorzelańczyk, Murakowski, 1995). The following equation relates R and S:

(1) R=e <sup>-k/S*t</sup>

where:

-   k is a constant
-   t is time

For simplicity, we will set k=1 to univocally define stability.

记忆的状态将仅用两个变量来描述：可检索性（R）和稳定性（S）（Wozniak, Gorzelańczyk, Murakowski, 1995）。以下等式将R和S关联起来：

(1) R=e <sup>-k/S*t</sup>

其中：

- k是一个常数
- t是时间

为了简化，我们将设定k=1，以唯一地定义稳定性。

#### 输入与输出（Input and output）

The following functions are to be determined by the network:

> (2) S <sub>i+1</sub>=f <sub>s</sub>(R, S <sub>i</sub>, D, G)
> 
> (3) D <sub>i+1</sub>=f <sub>d</sub>(R, S, D <sub>i</sub>, G)

The neural network is supposed to generate stability (S) and item difficulty (D) on the output given R, S, D and G on the input:

(4) (Ri, Si, Di, Gi) => (D <sub>i+1</sub>,S <sub>i+1</sub>)

where:

-   R <sub>i</sub> is retrievability before the i-th repetition
-   S <sub>i</sub> is stability before the i-th repetition
-   S <sub>i+1</sub> is stability after the i-th repetition
-   D <sub>i</sub> is item difficulty before the i-th repetition
-   D <sub>i+1</sub> is item difficulty after the i-th repetition
-   G <sub>i</sub> is grade given in the i-th repetition

以下函数将由（神经）网络确定：

> (2) S <sub>i+1</sub>=f <sub>s</sub>(R, S <sub>i</sub>, D, G)
> 
> (3) D <sub>i+1</sub>=f <sub>d</sub>(R, S, D <sub>i</sub>, G)

神经网络应该在给定输入R、S、D和G的情况下，在输出端生成稳定性（S）和项目难度（D）：

(4) (R<sub>i</sub>, S<sub>i</sub>, D<sub>i</sub>, G<sub>i</sub>) => (D <sub>i+1</sub>, S <sub>i+1</sub>)

其中：

- R <sub>i</sub> 是第 i 次重复之前的可检索性
- S <sub>i</sub> 是第 i 次重复之前的稳定性
- S <sub>i+1</sub> 是第 i 次重复之后的稳定性
- D <sub>i</sub> 是第 i 次重复之前的项目难度
- D <sub>i+1</sub> 是第 i 次重复之后的项目难度
- G <sub>i</sub> 是第 i 次重复时给出的评分

#### 难度 D 的误差修正（Error correction for difficulty D）

Target difficulty will be defined as in Algorithm SM-8 as the ratio between second and first intervals. The neural network plug-in (NN.DLL) will record this value for all individual items and use it in training the network:

(5) D <sub>o</sub>=I <sub>2</sub>/I <sub>1</sub>

where:

-   D <sub>o</sub> is guiding difficulty used in error correction (the higher the D <sub>o</sub>, the less the difficulty)
-   I <sub>1</sub> is the first optimum interval computed for the item in question (same for all items)
-   I <sub>2</sub> is the second optimum interval computed for the item

目标难度将按照SM-8算法中的规定，被定义为第二个间隔与第一个间隔的比率。神经网络插件（NN.DLL）将记录所有单个项目的这个值，并在网络训练中使用它：

(5) D <sub>o</sub>=I <sub>2</sub>/I <sub>1</sub>

其中：

- D <sub>o</sub> 是用于误差修正的引导难度（D <sub>o</sub> 越高，难度越低）
- I <sub>1</sub> 是为相关项目计算的第一个最优间隔（所有项目相同）
- I <sub>2</sub> 是为该项目计算的第二个最优间隔

Important! The optimum intervals I <sub>1</sub> and I <sub>2</sub> are not the ones proposed by the network before its verification but the ones used in error correction after the proposed interval had already been executed and verified (see error correction for stability S)!

**重要提示！** 最优间隔 I<sub>1</sub> 和 I<sub>2</sub> 不是（神经）网络在验证之前就提出的间隔，而是在间隔已经被提出，执行并验证之后，在误差修正中使用的间隔（参见稳定性 S 的误差修正）！

The initial value of difficulty will be set to 3.5, i.e. D <sub>1</sub>=3.5. This is for similarity with Algorithm SM-8 only. As initial difficulty is not known, it cannot be used to determine the first interval. After scoring the first grade the error correction is still impossible due to the fact that second optimum interval is not known. Once it is known, D <sub>o</sub> can be used for error correction of D on the output.

项目难度的初始值将被设置为3.5，即 D<sub>1</sub>=3.5。这仅仅是为了与 SM-8 算法保持相似性。由于初始难度未知，因此 D1 不能用于确定第一个间隔。在第一次评分后，由于第二个最优间隔未知，误差修正仍然不可能进行。一旦第二个最优间隔已知，D<sub>o</sub> 就可以用于输出端 D 的误差修正。

To avoid convergence problems in the network, the following formula will be used to determine the correct output on D:

(6) D<sub>opt</sub>=0.9×D<sub>i</sub>+0.1×D<sub>o</sub>

where:

-   D<sub>opt</sub> is difficulty used in error correction after the i-th repetition
-   D<sub>i</sub> is difficulty before the i-th repetition
-   D<sub>o</sub> is guiding difficulty from Eqn (5)

The convergence factor of 0.9 in Eqn (6) is arbitrary and may change depending on the network performance.

为了避免网络中的收敛问题，将使用以下公式来确定 D 上的正确输出：

(6) D<sub>opt</sub>=0.9×D<sub>i</sub>+0.1×D<sub>o</sub>

其中：

- D<sub>opt</sub> 是第i次重复后用于误差修正的难度
- D<sub>i</sub> 是第i次重复前的难度
- D<sub>o</sub> 是来自公式（5）的引导难度

公式（6）中的收敛因子0.9是随机选定的，可能会根据网络性能而变化。

#### 稳定性 S 的误差修正（Error correction for stability S）

The following formula, derived from Eqn (1) for forgetting index equal 10% and k=1, makes it easy to convert stability and the optimum interval: I=-ln(0.9)×S

以下公式由公式（1）推导而来，适用于遗忘指数等于10%且k=1的情况，可以方便地转换稳定性和最优间隔：I=-ln(0.9)×S

In the optimum case, the network should generate the requested forgetting index for each repetition. Variable forgetting index can easily be used once the stability S is known (see Eqn (1)). For simplicity then we will use forgetting index equal 10% in further analysis.

在最优情况下，（神经）网络应响应请求，为每次重复生成遗忘指数。一旦已知稳定性 S，就可以轻松使用可变的遗忘指数（参见公式（1））。为了简化，我们将在后续分析中使用等于10%的遗忘指数。

To accelerate the convergence, the network will measure forgetting index for 25 classes of repetitions. These classes are set by (1) five difficulty categories: 1-1.5, 1.5-2.5, 2.5-3.5, 3.5-5, and over 5, and (2) five interval categories: 1-5, 5-20, 20-100, 100-500 and over 500 days. We will denote the forgetting index measurements for these categories as FI(D <sub>m</sub>,I <sub>n</sub>). Additionally, the overall forgetting index FI <sub>tot</sub> will be measured and used in stability error correction.

为了加速收敛，网络将测量25个重复类别的遗忘指数。这些类别由以下因素设定：（1）五个难度等级：1-1.5、1.5-2.5、2.5-3.5、3.5-5和超过5，以及（2）五个间隔（时长）等级：1-5、5-20、20-100、100-500和超过500天。我们将这些（重复）类别的遗忘指数测量值表示为 FI(D<sub>m</sub>, I<sub>n</sub>)。此外，还将测量总遗忘指数 FI<sub>tot</sub>，并将其用于稳定性误差修正。

The ultimate goal is to reach the forgetting index of 10% in all categories. The following formula will be used in error correction for stability:

(7) FI<sub>opt(m,n)</sub>=(10×FI<sub>tot</sub>+Cases(m,n)×FI(m,n))/(10+Cases(m,n))

where:

-   FI<sub>opt(m,n)</sub> is forgetting index used in error correction after a repetition belonging to category (m,n)
-   FI<sub>tot</sub> is the overall forgetting index measured in repetitions
-   Cases(m,n) is the number of repetition cases used to measure the forgetting index in category (m,n)

最终目标是在所有类别中达到10%的遗忘指数。以下公式将用于稳定性误差修正：

(7) FI<sub>opt(m,n)</sub>=(10×FI<sub>tot</sub>+Cases(m,n)×FI(m,n))/(10+Cases(m,n))

其中：

- FI<sub>opt(m,n)</sub> 是属于类别（m,n）的重复后用于误差修正的遗忘指数
- FI<sub>tot</sub> 是在重复中测得的总遗忘指数
- Cases(m,n) 是用于测量类别（m,n）中遗忘指数的重复案例数

The formula in Eqn (7) is supposed to shift the weight on error correction from the overall forgetting index to forgetting index recorded in given categories as soon as the number of cases in individual categories increases. Obviously, for Cases(m,n)=0, we have FI <sub>opt(m,n)</sub>=FI <sub>tot</sub>. For Cases(m,n)=10 the weights for overall and category FI balance, and for a large number of cases, FI <sub>opt(m,n)</sub> is approaching FI(m,n).

公式（7）旨在随着各个类别中案例数量的增加，将误差修正的权重从总遗忘指数转移到给定类别中记录的遗忘指数。显然，在 Cases(m,n)=0 的情况下，FI<sub>opt(m,n)</sub>=FI<sub>tot</sub>。而在 Cases(m,n)=10 的情况下，总遗忘指数和类别遗忘指数的权重平衡，最后，对于类别中已经有大量案例的情况，FI<sub>opt(m,n)</sub> 接近 FI(m,n)。

The following table illustrates the assumed relationship between FI <sub>opt(m,n)</sub>, grades and the interval correction applied:

| Grade                      | 0             | 1             | 2             | 3             | 4             | 5             |
| -------------------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |
| FI <sub>opt(m,n)</sub>>10% | 40%           | 60%           | 80%           | no correction | no correction | no correction |
| FI <sub>opt(m,n)</sub>=10% | no correction | no correction | no correction | no correction | no correction | no correction |
| FI <sub>opt(m,n)</sub><10% | no correction | no correction | no correction | 110%          | 120%          | 130%          |


下表说明了假设的，FI<sub>opt(m,n)</sub>、评分和应用间隔修正之间的关系：

| 评分                        | 0   | 1   | 2   | 3    | 4    | 5    |
| ------------------------- | --- | --- | --- | ---- | ---- | ---- |
| FI<sub>opt(m,n)</sub>>10% | 40% | 60% | 80% | 无修正  | 无修正  | 无修正  |
| FI<sub>opt(m,n)</sub>=10% | 无修正 | 无修正 | 无修正 | 无修正  | 无修正  | 无修正  |
| FI<sub>opt(m,n)</sub><10% | 无修正 | 无修正 | 无修正 | 110% | 120% | 130% |

In SuperMemo, grades less than 3 are interpreted as forgetting, while grades equal 3 or more are understood as sufficient recall. That is why no correction is used for passing grades in case of satisfactory FI, and no correction is used for failing grades if FI is greater than requested. An exemplary correction for an excessive forgetting rate and grade=2 for applied interval of 10 days would be 80%. Consequently, the network will be instructed to assume Interval=8 as correct. Correct stability would then be derived from S=-8/ln(0.9) and used in error correction. The values of interval corrections are arbitrary but shall not undermine the convergence of the network. In case of unlikely stability problems, the corrections might be reduced (note that the environmental noise in the learning process will dramatically exceed the impact of ineffectively choosing the correction factors!). Similar corrections used to be applied in successive SuperMemo algorithms with encouraging results.

在 SuperMemo 中，低于3分的（响应）评分被理解为遗忘，而等于或高于3分的（响应）评分则被理解为充分回忆。这就是为什么在遗忘指数（FI）令人满意的情况下，我们不会根据评分（对间隔）进行修正，以及在遗忘指数（FI）高于要求的情况下，即使（响应）评分不及格我们也不会对间隔进行修正。只有在例如，遗忘率过高，并且（响应）评分只有2分（不及格）的情况下，我们才会（针对间隔）做出调整至80%的修正。因此，网络将被指示假设间隔=8是正确的。然后，正确的稳定性将从 S=-8/ln(0.9) 计算得来，并用于误差修正。间隔修正的值是任意生成的，但不应破坏（神经）网络的收敛性。如果出现稳定性问题（虽然不太可能），可以减少修正（请注意，学习过程中的环境噪声将大大超过无效选择修正因子的影响！）。类似的修正曾在一系列 SuperMemo 算法中使用，并取得了令人鼓舞的结果。

#### 边界条件（Border conditions）

The following additional constraints will be imposed on the neural network to accelerate the convergence:

-   interval increase in two successive repetition must be at least 1.1 (consequently, difficulty cannot be less than 1.1)
-   interval increase cannot surpass 8 after the first repetition, and 4 in later repetitions
-   the first interval must fall between 1 and 40 days
-   difficulty measure cannot exceed 8

为了加速收敛，将对神经网络施加以下附加约束：

- 两次连续重复中的间隔增加必须至少为1.1（因此，难度不能低于1.1）
- 第一次重复后的间隔增加不能超过8，后续重复中不能超过4
- 第一个间隔必须在1到40天之间
- 难度度量不能超过8

These conditions will not prejudice the network as they have been proven beyond reasonable doubt as true in the practice of using SuperMemo and its implementations over the last ten years.

这些条件不会使得（神经）网络带有偏见，因为在过去十年中使用 SuperMemo 及其应用的实践中，它们已毫无疑问地被证明是正确的。

#### 预训练（Pretraining）

In the pretraining stage, the following form of Eqns (2) and (3) will be used:

> (8) D <sub>i+1</sub>:=D <sub>i</sub>+(0.1-(5-G)×(0.08+(5-G)×0.02))
> 
> (9) S <sub>i+1</sub>:=S <sub>i</sub>×D <sub>i</sub>×(0.5+1/i)

With D <sub>1</sub>=3.5 and S <sub>1</sub>=-3/ln(0.9).

在预训练阶段，将使用公式（2）和（3）的以下形式：

> (8) D <sub>i+1</sub>:=D <sub>i</sub>+(0.1-(5-G)×(0.08+(5-G)×0.02))
> 
> (9) S <sub>i+1</sub>:=S <sub>i</sub>×D <sub>i</sub>×(0.5+1/i)

其中D<sub>1</sub>=3.5，S<sub>1</sub>=-3/ln(0.9)。

Eqn (8) has been derived from Algorithm SM-2 (see E-Factor equation). Eqn (9) has been roughly derived from Matrix OF in Algorithm SM-8. D <sub>1</sub>=3.5 corresponds with the same setting in Algorithm SM-8. S <sub>1</sub>=-3/ln(0.9) corresponds with the first interval of 3 days and forgetting index 10%. The value of 3 days is close to an average across a wide spectrum of students and difficulty of the learning material.Pretraining will also use border conditions mentioned in the previous paragraph.

公式（8）是从 SM-2 算法（参见E-Factor方程）推导出来的。公式（9）是从 SM-8 算法中的矩阵 OF 大致推导出来的。D<sub>1</sub>=3.5 与 SM-8 算法中的相同设置相对应。S<sub>1</sub>=-3/ln(0.9) 对应于3天的第一个间隔和10%的遗忘指数。3天的值接近于广大学生和学习材料难度的平均值。预训练还将使用前一段提到的边界条件。

There were multiple problems with the neural network, implementation, bugs, convergence, interference, and the like. The only way to effectively study the network was to plug it in real SuperMemo and see how it works on real data. I came up with an idea of plug-in algorithms in a DLL. We could study algorithmic variants in the same shell. We tried out Algorithm SM-2, Algorithm SM-8 and now a neural network was to do the same. Unfortunately, that DLL implementation proved a step too far. Once the enthusiastic kids graduated, they soon dispersed, found jobs elsewhere, got married, and I never had a chance to try the plug-in in my own learning in my favorite shell, which was SuperMemo 9 at that time (aka SuperMemo 98).

神经网络在诸多方面存在问题，像是实现、错误、收敛、干扰等等。有效研究网络的唯一方法是将其插入到真实的SuperMemo中，观察它在真实数据上的运行情况。我提出了在 DLL 中插入算法插件的想法。我们可以通过同一个外壳（*译注：shell，计算机科学中指“界面”和“框架”*）研究算法变体。我们尝试了 SM-2 算法、SM-8 算法，现在要让神经网络做同样的事情。不幸的是，在 DLL 实现这事上，我们步子迈得太大了。一旦那些充满热情的孩子们毕业，他们很快就散落各地，入了职，结了婚，我再也没有机会在我最喜欢的 SuperMemo 9（当时也称为SuperMemo 98）外壳中尝试这个插件了。

Neural network SuperMemo was a student project with a sole intent to verify the viability of neural networks in spaced repetition. Needless to say, neural networks are a viable tool. Moreover, all imaginable valid optimization tools, given sufficient refinement, are bound to produce similar results to those currently accomplished by SuperMemo. In other words, as long as the learning program is able to quickly converge to the optimum model and produce the desired level of knowledge retention, the optimization tool used to accomplish the goal is of secondary importance.

“神经网络 SuperMemo”是一个学生项目，其唯一目的是验证神经网络在间隔重复（预测）中的可行性。毋庸置疑，神经网络是一种可行的工具。此外，所有可想象到的有效优化工具，只要经过充分的改进，都必然会产生取得与目前 SuperMemo 相似的结果。换句话说，只要学习程序能够快速收敛到最优模型，并产生期望的知识保留率，那么这一目标是用哪种优化工具实现，就显得没那么重要了。

Considering the number of problems at earlier stages, I doubt that successful plug-in would change my thinking about neural networks. I am a programmer and a tinkerer, I like to see what I create. Neural network appeared too black boxy to me. As for the team, they are all successful in their careers today. The kids have contributed to some other SuperMemo efforts later on. Youth is creative, youth is unpredictable, and I am glad we took on the project.

考虑到早期阶段的诸多问题，我怀疑一个成功的插件是否足以改变我对神经网络的看法。我是一名程序员，也是一个喜欢动手尝试的人，我更喜欢看到自己创造的东西。神经网络对我来说显得太像一个“黑匣子”。至于这个团队，他们现在都在各自的职业生涯中取得了成功。这些年轻人后来也为 SuperMemo 的其他项目做出了贡献。年轻人的创造力是无限的，他们的潜能难以预测，我很高兴我们当时接受了这个项目。

### 大卫·卡林斯基与 FullRecall（David Calinski and FullRecall）

David Calinski (b. 1981) was one of the early youthful SuperMemo enthusiasts in the 1990s. He showed rich interest in accelerated learning, psychology, psychiatry, and beyond.

大卫·卡林斯基（David Calinski）（生于1981年）是20世纪90年代早期年轻的 SuperMemo 爱好者之一。他在加速学习、心理学、精神病学等诸多领域表现出浓厚的兴趣。

I quickly recognized his talents and was hoping to recruit him in some SuperMemo projects, incl. SuperMemo for Linux, however, many a genius like to walk alone. At some point, he switched from SuperMemo to his own application (FullRecall, see later), and from that point on, he would not abandon his project.

我很快就发现了他的才华，并希望招募他参与一些 SuperMemo 项目，包括只做 SuperMemo 的 Linux 版本。然而，许多天才都喜欢独行。在某个时候，他从 SuperMemo 转向了自己的应用程序（FullRecall，见后文），从那时起，他就再也没有放弃过他的项目。

Our discussions about neural networks started in 2001. David was a fan of SuperMemo, however, he also admitted to have never truly studied the algorithm. This led to a criticism:

> I don’t know the exact details of SM algorithm(s) (I never was much interested in it), but important here is the main idea. Algorithm in SM gets some data (e.g. number of repetitions, difficulty of item, current grade, etc. etc.) and returns next optimal interval it calculated. This algorithm, even if it’s “smart” and corrects itself somehow, will be still dumb – it won’t correct itself more than was designed for.

我们关于神经网络的讨论始于2001年。大卫是 SuperMemo 的忠实拥趸，但他承认自己从未真正研究过该算法。这导致了他提出如下批评：

> “我并不了解 SuperMemo 算法的具体细节（我从来没有对它产生过太大的兴趣），但重要的是它的核心思想。SuperMemo 中的算法获取一些数据（例如，重复次数、项目难度、当前评分等等），并返回它计算出的下一个最佳间隔。这个算法，即使它‘很聪明’并且能以某种方式自我修正，也仍然是‘愚笨的’——它的自我修正程度不会超过设计时的上限。”

He is right, Algorithm SM-17 is inherently bound to the two component model of long-term memory, however, this is a happy marriage. The bond can only be broken by counter-evidence that hasn’t come in three decades thus far.

他是对的，SM-17 算法本质上受限于长期记忆的二元模型，然而，这是一种完美的结合。这种联系只能被迄今为止三十年来尚未出现的反证所打破。

David’s stance is entirely justifiable. It is all about modelling and prior knowledge. For David, Algorithm SM-8 was complex. Neural networks seem like a simple way to take away the complexity. To me, my own algorithm is as simple as the multiplication table. That modelling difference often leads to cognitive divergence and this is a good thing. Without those differences, we would know much less about neural networks in spaced repetition today!

大卫的立场完全合理。这完全取决于建模和先验知识。对大卫来说，SM-8算法很复杂。神经网络似乎是一种消除复杂性的简单方法。对我来说，我自己的算法就像乘法表一样简单。这种建模差异经常导致认知上的分歧，而这是一件好事。如果没有这些差异，我们今天对间隔重复中的神经网络的了解就会少得多！

I wrote to David in 2004: *“Further improvements to the algorithm used in SuperMemo are not likely to result in further acceleration of learning. However, there is still scope for improvement for handling unusual cases such as dramatically delayed repetitions, massed presentation, handling items whose contents changed, handling semantic connections between items, etc. Interestingly, the greatest progress in the algorithm is likely to come from a better definition of the model of human long-term memory. In particular, the function describing changes in memory stability for different levels of retrievability is becoming better understood. This could dramatically simplify the algorithm. Simpler models require fewer variables and this simplifies the optimization. The algorithm based on stability and retrievability of memory traces could also result in better handling of items with low retrievability. However, as unusual item cases in the learning process form a minority, and testing a new algorithm would take several years, it is not clear if such an implementation will ever be undertaken”*.

我在2004年给大卫的信中写道：“*对 SuperMemo 中使用的算法的进一步改进不太可能导致学习速度的进一步提升。然而，在处理异常情况方面仍有改进的空间，例如显著的重复延迟、混乱的知识呈现、处理内容发生变化的项目、处理项目之间的语义联系等等。有趣的是，算法的最大进步可能来自于对人类长期记忆模型的更好定义。特别是，描述不同可检索性水平下，记忆稳定性变化的函数正在被更好地理解。这可能会极大地简化算法。更简单的模型需要的变量更少，从而使得优化步骤也更简单。基于记忆痕迹的稳定性和可检索性的算法，也可能使可检索性低的项目得到更好的处理。然而，由于学习过程中异常项目的情况只占少数，并且测试新算法需要数年时间，因此尚不清楚这些想法能否真正得到实施。*”

David developed his own neural network, MemAid. Later he converted it into a commercial product. The move from free to commercial was hard as users tend to prefer a drop in prices, for obvious reasons. Despite all ups and downs, David persisted, and his DIY tinkerer and passion for science and programming always gave him an upper hand. Like Anki, he tried to keep his program cross-platform which imposed some limits and demands on simplicity. In his words: *“I love speed and lack of borders, lack of dependency on just one solution, system, computer, etc.”*

大卫开发了自己的神经网络，MemAid。后来，他将其转化为商业产品。从免费到商业化的转变是艰难的，因为出于显而易见的原因，用户往往更喜欢节约成本。尽管经历了起起落落，大卫仍然坚持了下来，他的 DIY 精神，还有他对科学和编程的热情使他始终占据优势。像 Anki 一样，他试图保持他的程序能够跨平台运行，这在简易性方面提出了一些限制和要求。用他的话来说就是：“*我喜欢速度和无边界，不喜欢依赖单一的解决方案、系统、计算机等等。*”

Today FullRecall is free. See the changelong.

如今，FullRecall是免费的。请参阅更新日志。

![[SuperMemo_The true history of spaced repetition_附件/ANN_interval_distribution.jpg]]

> ***Figure:** Interval distribution in FullRecall. Repetitions scheduled with the help of a neural network*
> 
> **图：** FullRecall 中的间隔分布。使用神经网络安排复习时间。

The open-source MemAid project closed in 2006, but FullRecall continued. So did another project inspired by MemAid: Mnemosyne. Mnemosyne, however, opted for their own version of Algorithm SM-2. To this day, Mnemosyne generates data that can be used by spaced repetition enthusiasts or researchers at The Mnemosyne Project.

开源项目 MemAid 于2006年关闭，但 FullRecall 仍在继续。另一个受 MemAid 启发的项目也诞生了：Mnemosyne。然而， Mnemosyne 选择了他们自己版本的SM-2算法。时至今日， Mnemosyne 仍在生成数据，这些数据可供间隔重复学习爱好者或 Mnemosyne 项目的研究人员使用。

Like Calinski, Peter Bienstman is skeptical of newer algorithms: *“SuperMemo now uses SM-11. However, we are a bit skeptical that the huge complexity of the newer SM algorithms provides for a statistically relevant benefit. But, that is one of the facts we hope to find out with our data collection.”*

与卡林斯基（Calinski）一样，彼得·比恩斯特曼（Peter Bienstman）对新的算法持怀疑态度：“*SuperMemo 现在使用 SM-11。但是，我们有点怀疑，新的 SM 算法的巨大复杂性是否能提供统计学上显著的益处。但是，这是我们希望通过数据收集来发现的事实之一*。”

*“Statistically relevant benefit”* depends on the criteria. For users, the actual algorithm may be secondary. For research, Algorithm SM-17 is a goldmine (as much as data that all programs like Mnemosyne can generate).

“*统计学上显著的益处*”取决于评价标准。对于用户来说，实际的算法可能是次要的。对于研究来说，SM-17 算法是一个金矿（所有 Mnemosyne 等类似程序生成的数据也是同样）。

### 为什么 FullRecall 中的神经网络存在缺陷？（Why is the neural network in FullRecall flawed?）

The two memory variables are both necessary and sufficient to represent an atomic memory in spaced repetition. Moreover, the two variables can be used to account for spacing effect in massed presentation. They can also explain the benefit of high forgetting index for long-term retention as discussed here. Those two variables of long-term memory which we named: stability and retrievability are necessary to represent the status of memory. Any neural network that wants to find patterns in the relationship between spacing and recall must receive the full status of memory on its input otherwise it won’t ever compute the optimum spacing. That status may have a form of the full history of repetition. It may also be the stability : retrievability pair (if it can be computed). It may also be any other code over the history of repetitions from which the status of memory can be computed.

在间隔重复学习中，用两个记忆变量来表示一个原子记忆，既是必要的，也是充分的。此外，这两个变量可以用来解释集中呈现的间隔效应。它们还可以解释高遗忘指数对长期记忆保持的好处，正如这里所讨论的一样。我们命名为“稳定性”和“可检索性”的这两个长期记忆变量，是表示记忆状态所必需的。任何想要在间隔和回忆之间的关系中找到规律的神经网络，都必须在其输入端接收完整的记忆状态，否则它永远无法计算出最佳间隔。这个状态可以是完整的重复历史的形式。它也可以是稳定性：可检索性对（如果可以计算的话）。它也可以是重复历史的任何其他编码，只要从中可以计算出记忆状态就行。

The design of the FullRecall network does not meet those criteria:

-   input: last_interval_computed_by_ann [0-2048 days] (zero if this is not a review, but a first presentation)
-   input: real_interval_since_last_review [0-2048 days] (same comment as above)
-   input: number_of_repetitions_of_an_item_so_far [0-128]
-   input: current_grade [0-5, 5 is the best]
-   output that ANN gives us: new_interval [0-2048]

FullRecall 网络的设计不符合这些标准：

- 输入：神经网络计算的最后一个间隔[0-2048天]（如果不是复习，而是第一次呈现，则为零）
- 输入：自上次复习以来的实际间隔[0-2048天]（同上）
- 输入：项目迄今为止的重复次数[0-128]
- 输入：当前评分[0-5，5为最佳]
- 神经网络给出的输出：新间隔[0-2048]

Neither interval nor repetitions count can reflect memory stability or retrievability. You can obtain high repetition counts in massed presentation subject to spacing effect with a negligible increase in memory stability. At the same time, long intervals for suboptimum schedules may result in low values for both stability and retrievability. In short, for the same interval, the status of memory will depend on the distribution of repetitions in time.

无论是间隔还是重复次数，都无法反映记忆的稳定性和可检索性。在集中呈现的情况下，你可能会获得较高的重复次数，但由于间隔效应，记忆稳定性几乎没有增加。与此同时，与最优值不符的长时间间隔可能导致稳定性和可检索性都处于较低水平。简而言之，对于相同的间隔，记忆状态将取决于重复时间的分布。

This can be shown with an example: for 10 repetitions, and 1000 days, 9 repetitions in 9 days combined with 991 day interval will produce stability approaching zero (assuming no interference). At the same time, for the same pair of inputs, optimally spaced repetition can bring retrievability of nearly 100% and stability that allows of optimum intervals close to 1000 days.

这可以通过一个例子来说明：对于在1000天内进行10次重复的情况，如果前9次重复在9天内完成，然后间隔991天，那么稳定性将接近于零（假设没有干扰）。与此同时，对于相同的输入组合，按最优间隔重复，可以带来接近100%的可检索性，和允许最优间隔达到接近1000天的稳定性。

The only scenario where the network might perform well is where the user adheres precisely to the optimum spaced repetition schedule. This, in turn, can only come from a network that has been pre-trained, e.g. with Algorithm SM-2. In this scenario, the network will be unstable and won’t converge on the optimum due to the fact that all departures from the optimum schedule, incl. those caused by network error will shift the state of the network away from the original state in which it was still able to compute memory status from its inputs.

神经网络可能表现良好的唯一情况，是用户严格遵守最优间隔重复计划。但这种情况，反而只能来自于一个预先训练过的神经网络，例如借助 SM-2 算法。在这种情况下，神经网络将是不稳定的，并且不会收敛到最优状态，因为会有许多偏离最优计划的情况，包括由网络错误引起的偏差，都会使（神经）网络偏离其原始状态，而在原始状态下，它才能够从其输入计算记忆状态。

Stability and retrievability are sufficient in the idealized case for a unitary monosynaptic association. In real life, the semantic network involved in the association is likely to involve a number of such ideal unitary memories. This is why SuperMemo uses the concept of absolute item difficulty. In Algorithm SM-17, the absolute item difficulty is determined by the maximum increase in memory stability for the first optimally scheduled review at the default forgetting index of 10%. The FullRecall network does not receive any reliable measure of item difficulty either. This will compound the network’s inefficiency.

在理想情况下，对于单一的单突触关联，（用）稳定性和可检索性（进行描述）是充分的。但在现实生活中，与（单突触）关联相关的语义网络很可能涉及许多这样的理想单一记忆（译注：*译者个人理解这里的意思是“记忆一个项目往往涉及不止一个神经突触，不同难度的项目涉及的突触数量也不同，因此会有难度之分”*）。这就是 SuperMemo 使用绝对项目难度这一概念的原因。在 SM-17 算法中，绝对项目难度，由默认遗忘指数为10%的情况下，按最优计划首次复习后，记忆稳定性的最大增幅决定。FullRecall 网络也没有接收到任何衡量项目难度的可靠标准。这将加剧网络的低效性。

The FullRecall network is said to work pretty well, according to users reports. In the light of the present analysis, the network might employ well-chosen boundary conditions, however, this would be equivalent to returning to Algorithm SM-2 employed in older versions of SuperMemo. Needless to say, that old SuperMemo algorithm is more biased and less plastic than newer matrix-based algebraic versions employed in SuperMemo.

据说根据用户报告， FullRecall 网络运行良好。根据目前的分析，该网络可能采用了精心选择的边界条件，然而，这相当于回到 SuperMemo 旧版本中使用的 SM-2 算法。毋庸置疑，旧的 SuperMemo 算法比新版本 SuperMemo 中使用的“基于矩阵的代数算法”更具偏见，也更缺乏可塑性。

If the FullRecall network is pre-trained, e.g. with the help of Algorithm SM-2, and the student sticks rigorously to his or her repetition, the network might work ok as the interval correlates well with memory stability, esp. if the information is enhanced by the number of repetitions. However, without appropriate boundary conditions, in incremental reading, the network would certainly fail as it might receive false memory status information. Depending on the scenario, the same Repetitions : Interval pair may occur for Stability=0 and for maximum stability corresponding with lifetime memories. Similarly, the retrievability may also vary in the 0-1 range for the same input pair in the network. For example, frequent subset review before an exam followed by a longer break in learning (e.g. caused by overflow) may correspond with very low stability and retrievability despite providing the same input as a correctly executed series of spaced reviews in the same period (with high stability and retrievability above 0.9). In incremental reading, overload, auto-postpone, item advance, subset review, and spacing effect would be invisible to the network.

如果 FullRecall 网络经过预先训练，例如借助 SM-2 算法，并且学生严格遵守其重复计划，那么该网络可能会运行良好，因为间隔与记忆稳定性密切相关，特别是当信息通过重复次数增强时。然而，如果没有适当的边界条件，在增量阅读中，该网络肯定会失败，因为它可能会收到错误的记忆状态信息。根据具体情况，相同的“重复次数：间隔”组合既可能出现在稳定性=0时，也可能出现在稳定性已经对应于终身记忆的最大值时。同样的，相同的（“重复次数：间隔”）输入对，其对应的可检索性也可能是 0-1 范围内的任意值。例如，考试前频繁针对知识子集进行复习，然后是较长的学习中断，可能带来非常低的稳定性和可检索性，尽管与正确执行的一系列间隔复习（对应高稳定性和高于0.9的可检索性）相比，它同一时期内提供了相同的输入。在增量阅读中，过载、自动推迟、项目提前、子复习和间隔效应对于（神经）网络来说都是不可见的。

（*译注：简单来说，“重复次数：间隔”这个输入对和稳定性还有可检索性之间不存在绝对关系，而稳定性和可检索性才是描述记忆状态的关键，仅仅以“重复次数：间隔”作为输入对的话神经网络是无法找到记忆随时间变化的规律的。*）

Assuming good design, the flaws of FullRecall will then only show in intermitted learning, which may trigger boundary conditions. It should not detract from the value of the software itself. It is only to emphasize that neural network design is not easy, and may turn out inferior.

假如设计良好，FullRecall 的缺陷只会在间歇性学习中显现出来，因为这（间歇性学习）可能会触发边界条件。但我们不应为此贬低软件本身的价值。这只是为了强调神经网络设计并不容易，并且不一定都有好结果。

In short, its inputs do not reflect all necessary information needed for computing optimum intervals. In particular, repetition count is a very poor measure of memory stability or retrievability. A better approach would be to code the entire history of repetitions or compute the status of memory with the use of stability and retrievability variables. Both stability and retrievability must be computable from the network input.

简而言之，它的输入没有反映计算最优间隔所需的所有必要信息。特别是，重复次数是衡量记忆稳定性和可检索性的非常糟糕的指标。更好的方法是编码整个重复历史，或者使用“稳定性”和“可检索性”这两个变量计算记忆状态。稳定性和可检索性都必须能够从（神经）网络的输入内容中计算出来。

### SuperMemo 中神经网络的未来（Future of neural networks in SuperMemo）

In our discussions with Calinski (in 2001), I summarized my reservations and vowed to continue on the same old “conservative” path. 17 years later, I am glad. There has not been much progress in the area of employing neural networks in spaced repetition. It might be the fact that SuperMemo itself is an inhibitor of progress. In the meantime, however, Algorithm SM-17 has revealed further potential for improvements in spaced repetition and understanding human memory. Time permitting, there will still be progress.

在2001年与卡林斯基的讨论中，我总结了我的保留意见，并誓言继续走“保守主义”的老路。17年后，我很高兴。在间隔重复中使用神经网络的研究领域，并没有取得太多进展。这可能是因为 SuperMemo 本身就是进步的一大阻碍。然而，与此同时，SM-17 算法揭示了间隔重复中进一步改进和理解人类记忆的潜力。只要时间允许，我们还会继续进步。

SuperMemo will continue with its algebraic algorithms for the following reasons:

-   **Known model**: Neural networks are superior in cases where we do not know the underlying model of the mapped phenomena. The model of forgetting is well-known and makes it easy to fine-tune the algebraic optimization methods used in computing inter-repetition intervals. The well-known model also makes SuperMemo resistant to unbalanced datasets, which might plague neural networks, esp. in initial stages of learning. Last but not least, the validity of the two component model of memory has been proven in many ways and giving up the model while designing the network, in the name of stemming prejudice, would be wasteful. Such approach may have a research value only
-   **Overlearning**: Due to case-weighted change in array values, optimization arrays used in SuperMemo are not subject to “overlearning”. No pretraining is needed, as the approximate shape of the function of optimal intervals is known in advance. There is no data representation problem, as all kinky data input will be “weighed out” in time
-   **Equivalence**: Mathematically speaking, for continuous functions, n-input networks are equivalent to n-dimensional arrays in mapping functions with n arguments, except for the “argument resolution problem”. The scope of argument resolution problem, i.e. the finite number of argument value ranges, is strongly function dependent. A short peek at the optimization arrays displayed by SuperMemo indicates that the “argument resolution” is far better than what is actually needed for this particular type of function, esp. in the light of the substantial “noise” in data. Hill-climbing algorithms used in SuperMemo are reminiscent of the algorithms aimed at reweighing the networks
-   **Research**: The use of matrices in SuperMemo makes it easy to see “memory in action”. Neural networks are not that well-observable. They do not effectively reveal their findings. You cannot see how a single forgetting curve affects the function of optimum intervals. This means that the black-box nature of neural networks makes them less interesting as a memory research tool
-   **Convergence**: The complexity of the algorithm does not result from the complexity of the memory model. Most of the complexity comes from the use of tools that are supposed to speed up the convergence of the optimization procedure without jeopardizing its stability. This fine-tuning is only possible due to our good knowledge of the underlying memory model, as well as actual learning data collected over years that help us precisely determine best approximation function for individual components of the model
-   **Forgetting curve**: The only way to determine the optimum interval for a given forgetting index is to know the (approximate) forgetting curve for a given difficulty class and memory stability. If a neural network does not attempt to map the forgetting curve, it will always oscillate around the value of the optimum interval (with good grades increasing that value, and bad grades decreasing it). Due to data noise, this is only a theoretical problem; however, it illustrates the power of using a symbolic representation of stability-retrievability-difficulty-time relationship instead of a virtually infinite number of possible forgetting curve data sets. If the neural network does not use a weighted mapping of the forgetting curve, it will never converge. In other words, it will keep oscillating around the optimum model. If the neural network weighs in the status history and/or employs the forgetting curve, it will take the same approach as the present SuperMemo algorithm, which was to be obviated by the network in the first place

SuperMemo 将继续使用其代数算法，原因如下：

- **已知模型：**
    - 在不了解映射现象的底层模型的情况下，神经网络更具优势。
    - 遗忘模型已被详尽解明，这使得微调用于计算复习间隔的代数优化方法变得容易。
    - 已知的模型也使 SuperMemo 能够抵抗可能困扰神经网络（尤其是在学习初始阶段）的不平衡数据集。
    - 最重要的是，记忆的二元模型的有效性已通过多种方式得到证明，为了“消除偏见”而在设计网络时放弃该模型是浪费的。这种方法可能只具有研究价值。
- **过度学习：**
    - 由于数组值的加权变化，SuperMemo 中使用的优化数组不会受到“过度学习”的影响。
    - 由于最优间隔函数的大致形状是预先知道的，因此不需要预训练。
    - 不存在数据表示问题，因为所有棘手的数据输入都会随着时间的推移被“权衡掉”。
- **等价性：**
    - 从数学上讲，对于连续函数，n 输入网络在映射具有 n 个参数的函数时，与 n 维数组是等价的，除了“参数解析度问题”。
    - “参数解析度问题”的范围，即参数的取值范围，很大程度上取决于函数。
    - 对 SuperMemo 显示的优化数组的简单观察表明，其“参数解析度”远好于这种特定类型的函数实际需要的，尤其是在数据中存在大量“噪声”的情况下。
    - SuperMemo 中使用的爬山算法让人联想到旨在重新加权网络的算法。
- **便于研究：**
    - 在 SuperMemo 中使用矩阵可以很容易地看到“记忆的行为”。
    - 神经网络的可观察性没有那么好。它们不能有效地揭示它们的发现。
    - 你无法看到单个遗忘曲线如何影响最优间隔的函数。
    - 这意味着神经网络的黑箱性质使其作为记忆研究工具的吸引力降低。
- **收敛性：**
    - 算法的复杂性并非源于记忆模型的复杂性。
    - 大部分复杂性来自于使用旨在加速优化过程收敛而不损害其稳定性的工具。
    - 这种微调之所以成为可能，是因为我们对底层记忆模型的良好了解，以及多年来收集的实际学习数据，这些数据有助于我们精确确定模型各个组件的最佳近似函数。
- **遗忘曲线：**
    - 确定给定遗忘指数的最佳间隔的唯一方法是知道给定难度等级和记忆稳定性的（近似）遗忘曲线。
    - 如果神经网络不尝试描绘遗忘曲线，它将始终在最佳间隔的值附近振荡（好的评分会增加该值，坏的评分会减少该值）。
    - 由于数据噪声，这只是一个理论问题；然而，它说明了稳定性-可检索性-难度-时间关系这一表达方案的强大，远远胜过几乎无限数量的可能遗忘曲线数据集。
    - 如果神经网络不使用遗忘曲线的加权映射，它将永远不会收敛。换句话说，它将继续围绕最优模型振荡。
    - 如果神经网络权衡历史数据和/或使用遗忘曲线，它将采用与当前 SuperMemo 算法相同的方法，而该算法最初是要被（神经）网络取代的。

In other words, neural networks could be used to compute the intervals, but they do not seem to be the best tool in terms of computing power, research value, stability, and, most of all, the speed of convergence. When designing an optimum neural network, we run into similar difficulties as in designing the algebraic optimization procedure. In the end, whatever boundary conditions are set in “classic” SuperMemo, they are likely to appear, sooner or later, in the network design (as can be seen in: Neural Network SuperMemo).

换句话说，神经网络可以用来计算间隔，但在计算能力、研究价值、稳定性，尤其是收敛速度方面，它似乎并不是最佳工具。在设计最优神经网络时，我们遇到的困难与设计代数优化程序时类似。最终，在“经典版本”的 SuperMemo 中设置的所有边界条件，可能都迟早要出现在（神经）网络的设计中（如“神经网络 SuperMemo”中提到的那样）。

As with all function approximations, the choice of the tool and minor algorithmic adjustments can make a world of difference in the speed of convergence and the accuracy of mapping. Neural networks could find use in mapping the lesser known accessory functions that are used to speed up the convergence of the algebraic algorithm. For example, to this day, item difficulty estimate problem has not been fully cracked. We simply tell users to keep their knowledge simple, which is a universal recommendation from any educator aware of mnemonic limits of human memory.

（神经网络）与所有寻找近似函数的过程一样，工具的选择和算法的细微调整，都可能对收敛速度和映射精度产生巨大影响。神经网络可以用于映射一些鲜为人知的辅助函数，这些辅助函数用于加速代数算法的收敛。例如，直到今天，项目难度估计问题仍未完全解决。我们只能告诉用户要保持知识的简单性，这也是任何了解人类记忆记忆限制的教育者都会提出的建议。

## 1999年：选定名称：“间隔重复”（1999: Choosing the name: “spaced repetition”）

###  起名前的思索过程（Quest for a good unique name）

The term ” *spaced repetition* ” is very old and has been used for decades in the advertising industry and in behavioral research. However, its modern meaning based on the optimum review intervals has been established only when the name was used to stand for the *SuperMemo method* (as of 1999).

“*间隔重复*”这个术语非常古老，并且已经在广告业和行为研究中使用了几十年。然而，其基于最优复习间隔的现代含义，直到该名称被用来代表“*SuperMemo 方法*”（始于1999年）时才确立。

In the early days of SuperMemo World, we actively searched for a well-recognized scientific term to use when referring to ” *the SuperMemo method*” in scientific contexts. The company’s marketing strategy was to move away from a ” *program developed by a student*” to a ” *program based on a scientific method*“. Unfortunately, memory and learning literature was scant on publications other than short-term studies of the spacing effect with a notable exception of H. Bahrick’s research on the retention of Spanish vocabulary.

在 SuperMemo World 的早期，我们积极寻找一个被广泛认可的科学术语，以便在科学语境中指代“*SuperMemo 方法*”。公司的营销策略是将产品形象从“学生开发的程序”转变为“基于科学方法的程序”。不幸的是，关于记忆和学习的文献极为匮乏，除了对间隔效应的短期研究之外，几乎没有其他出版物。唯一值得注意的例外可能就只有 H. Bahrick 对西班牙语词汇记忆保留率的研究了。

Memory researchers have investigated various ” repetition schedules” for ages. Sometimes they used intervals of minutes. Sometimes they used “intervening items” to separate review. Three review patterns have been most prevalent: (1) **massed** with many repetitions in short time, (2) **distributed** with repetitions dispersed in time, and (3) **expanding** with increasing interval. Spaced repetition relies on a progressively expanding schedule. Over decades, memory literature could not settle on a specific term to refer to the expanding schedule. Pimsleur used *graduated intervals*, Bjork used *expanding rehearsal*, Baddley used *distributed practice*, in my Master’s Thesis, I used *progressive schedule*, Pavlik uses more general *optimal schedule* that we know is progressive, etc.

记忆研究者们多年来一直在研究各种“重复计划”。有时他们使用分钟计时作为复习间隔，有时他们使用“插入项目”作为复习间隔。三种复习模式最为流行：(1) **集中式**，在短时间内进行多次重复，(2) **分散式**，将重复分散在时间上，以及 (3) **递增式**，让间隔时间不断增加。间隔重复依赖于一种（间隔）逐渐递增的时间表。几十年来，记忆文献未能确定一个特定的术语来指代“递增式”的重复计划。皮姆斯勒（Pimsleur）使用了“*渐进间隔（*graduated intervals）*”，比约克（Bjork）使用了“*递增复习（expanding rehearsal）*”，巴德利（Baddley）使用了“*分散练习（distributed practice）*”，在我的硕士论文中，我使用了“*渐进计划（progressive schedule）*”，帕夫利克（Pavlik）使用了更通用的“*最优计划（optimal schedule）*”，虽然（帕夫利克的）这个名字没体现出“递增”的属性，但我们本身已经知道这个计划是递增的了，诸如此类的命名还有很多。

A seminal article by Frank N. Dempster ” *The Spacing Effect A Case Study in the Failure to Apply the Results of Psychological Research*” (American Psychologist, 43, 627-634, 1988) gave an early boost to SuperMemo. The article deplored the fact that educators ignore the spacing effect in the pracise of learning. SuperMemo could fill the gap by providing a simple universal tool for spaced learning. Dempster freely used terms such as “spaced presentation”, “spaced reviews”, “spaced practise”, “spaced tests”, and even “spaced readings”, or “well-spaced presentations”.

弗兰克·N·邓普斯特（Frank N. Dempster）的一篇开创性文章《间隔效应：心理学研究成果应用失败的案例研究》（《美国心理学家》，第43期，627-634页，1988年）曾推动了 SuperMemo 的早期发展。该文章对教育者在学习实践中忽视间隔效应这一事实表示遗憾。SuperMemo 可以通过提供一个简单的通用间隔学习工具来填补这一空白。邓普斯特自由地使用了“间隔呈现（spaced presentation）”、“间隔复习（spaced reviews）”、“间隔练习（spaced practise）”、“间隔测试（spaced tests）”，甚至“间隔阅读（spaced readings）”或“良好间隔呈现（well-spaced presentations）”等术语。

We chose the term ”*repetition spacing*” to be used instead of ” *the SuperMemo method*“. The first-ever English language scholarly article describing **computational spaced repetition** (1994) still used the term ” *repetition spacing*“.

我们选择使用“重复间隔（repetition spacing）”一词，而不是“SuperMemo 方法（the SuperMemo method）”。第一篇描述**计算间隔重复**的英语学术文章（1994年）沿用了“重复间隔”一词。

### 选择名称：间隔重复（Choosing the name: spaced repetition）

On Feb 3, 1999, inspired by an e-mail from a user of SuperMemo (*Tony D’Angelo*), I reviewed literature using the keyword ”*spaced repetition*“. Upon that review, I got convinced that we should move from using the term ”*repetition spacing*” to ” *spaced repetition*“. The term ”*spaced repetition*” was equally obscure and rarely used, but had a better use count than ” *repetition spacing*“.

1999年2月3日，受到 SuperMemo 用户（*托尼·德安杰洛（Tony D’Angelo）*）的电子邮件启发，我回顾了使用关键词“_间隔重复_”的文献。经过这次回顾，我确信我们应该将（间隔递增式的重复记忆）过程的名称从“*重复间隔（repetition spacing）”改为“*间隔重复*”。“_间隔重复_”这个术语同样晦涩且很少使用，但其使用次数至少比“_重复间隔_”要多。

We decided that in future SuperMemos, the term ” *spaced repetition*” should be used instead of ” *repetition spacing*“. The first use of the term at supermemo.com probably came on Feb 4, 2000 in SuperMemo is useless

于是我们决定在未来的 SuperMemo 版本中，使用“*间隔重复*”一词代替“*重复间隔*”。在 supermemo.com 上首次使用该术语可能是在2000年2月4日的《SuperMemo 是无用的》一文中。

Over time, the term ” *spaced repetition*” has become more and more popular. In that light, SuperMemo can also take credit for making this generic scientific term take root in public’s mind with a specific association to optimum intervals in learning.

随着时间的推移，“*间隔重复*”这个术语变得越来越流行。从这个角度来看，SuperMemo 让这个通用科学术语在公众心中扎根，并使其与学习中的最优间隔产生联系，这一工作成果值得受到赞誉。

### “间隔重复”这一名称的未来（The future of the name: spaced repetition）

As of 1999, largely due to our choice of the name, the term ” *spaced repetition* ” has consolidated its presence in texts referring to flashcard applications, incl. those based on the Leitner system. There is also a hope, the term will become dominant in scientific literature. All authors prefer to stick to the terminology they have used for years or decades. However, a great deal of terminological acceleration can be attributed to Wikipedia. The dominant term in there is *spaced repetition*, however, memory scientists tend to flock to *spaced retrieval* or *distributed practice* (which is a wider concept). There are also *island entries* like *spaced learning* that have been attributed by spambots to Paul Kelly (at the time headmaster at Monkseaton High School).

截至1999年，很大程度上由于我们选择了这个名称，“_间隔重复_”一词在与卡片记忆类应用程序（包括基于莱特纳系统（the Leitner system）的应用程序）相关的文本中巩固了其地位。我们还希望这个术语在科学文献中也能占据主导地位。可惜所有作者都倾向于坚持他们多年乃至几十年来使用的术语。现在，术语的加速普及很大程度上依赖于维基百科。那里的主导术语是“_间隔重复_”。然而，记忆科学家倾向于使用“*间隔提取*”或“*分散练习*”（这是一个更广泛的概念）等词。还有像“*间隔学习*”这样的“孤岛条目”，它们被垃圾邮件机器人四处发送，最早由保罗·凯利（当时是蒙克西顿高中的校长）提出。

This confusion contributes to the disconnect between research and popular applications of spaced repetition, but the merger and unification are just a matter of time. Wikipedia uses a concept of *proposed mergers*. Scientists may oppose merging their “clean” versions with the popular version peppered with commercial links. However, such a merger is inevitable and good. There are scientists who investigate spaced repetition today who do not know the term spaced repetition, and never heard of SuperMemo. There are also engineers who work on spaced repetition algorithms who know very little of actual memory research in the field. Both problems can be reduced by unifying the terminology. Google will do the rest.

这种混乱导致了流行的间隔重复应用程序和一线研究之间的脱节，但合并和统一只是时间问题。维基百科使用“*提议合并*”的概念。科学家们可能会反对将他们的“纯净”版本与充斥着商业链接的流行版本合并。然而，这种合并是不可避免且有益的。今天研究间隔重复的科学家中，有些人不知道间隔重复这个术语，也没听说过 SuperMemo。还有一些开发间隔重复算法的工程师，他们对该领域的实际记忆研究知之甚少。通过统一术语，这两个问题都可以得到缓解。谷歌自然会完成剩下的工作。（*译注：教授的意思是统一名称之后，有利于那些从事行业相关工作却不知道理论基础的人通过搜索自学*）

Unification of terminology under the banner of ” **spaced repetition**” will serve further research and popular applications

在“**间隔重复**”的旗帜下统一术语将有助于进一步的学术研究和应用开发。

## 2005年：稳定性增长函数（2005: Stability increase function）

### 为什么一个简单的想法无法实现？（Why a simple idea could not materialize?）

A perfect mathematical description of long-term memory is just about a corner. It may seem amazing today, but despite its simplicity, it took three long decades of starts and stops before a good model could emerge. In human endeavor, science is often a side effect of human curiosity while other burning projects often receive priority. The problem with science that it is blind, it says little of its secrets before they are uncovered. A moral of the story is that all governments and companies should spare no resources for good science. Science is a bit like SuperMemo, today it seems like the reward is little, but in the long-term, the benefits can be stunning.

对长期记忆的完美数学描述近在咫尺。今天看来也许令人惊讶，但尽管如此简单，一个好的模型依然在经历了三十年的断断续续的研究后才问世。在人类的努力中，科学往往是人类好奇心的副产品，总有其他紧迫的项目获得更优先的关注。科学的问题在于它是盲目的，在秘密被揭示之前，它很少主动透露什么。我们能从中学到的是，所有政府和公司都应该不遗余力地支持优秀的科学。科学有点像 SuperMemo，今天看来回报甚微，但从长远来看，收益将会惊人。

Today we can almost perfectly describe memory with the toolset employed in Algorithm SM-17. The only limit on further progress in understanding memory is the imagination, availability of time, and the ability to pose the right questions. We have all the tools and we have a lot of data. We even have a nice portion of data combined with sleep logs that can now add a new dimension to the model: homeostatic readiness for learning, homeostatic fatigue and even the circadian factor.

今天，我们可以使用算法 SM-17 中的工具集几乎完美地描述记忆。进一步理解记忆的唯一限制是想象力、时间的可用性以及提出正确问题的能力。我们不止拥有所有的工具，还拥有大量的数据。我们甚至拥有一部分与睡眠日志相结合的数据，这些数据现在可以为模型添加一个新的维度：学习的稳态准备度、稳态疲劳，甚至昼夜节律因素。

An important moral of the story behind SuperMemo is that if you have an idea, put it to life (unless you have another better idea). The problem with ideas is that they may often seem a fraction as attractive as they are. I plotted my first forgetting curve in 1984, I forgot about it within a few months and recalled the fact 34 years later at the time when my whole life revolves around forgetting curves. Imagine the surprise! When I came up with the first spaced repetition algorithm, it took me over 2 years before I decided to recruit the first user. Without Tomasz Kuehn, SuperMemo for Windows might arrive 2-4 years later. Without Janusz Murakowski, vital big data: repetition history record in SuperMemo might have been delayed by 1-2 years. When incremental reading came to life in 2000, only I knew it was a monumental thing. However, it took me quite a while to appreciate the extent of that fact. Today, I know neural creativity is a breakthrough tool, but I am still using it half-heartedly and not as often as its simpler alternative: subset review.

SuperMemo 背后的故事有一个重要的寓意，那就是如果你有一个想法，就把它付诸实践（除非你有另一个更好的想法）。想法的问题在于，它们表面上的吸引力往往只有其真实价值的一小部分。我于1984年绘制了我的第一条遗忘曲线，几个月后我就忘记了它，并在34年后，当我的整个生活都围绕着遗忘曲线旋转时，才回忆起这件事。想象一下我当时的惊讶！当我提出第一个间隔重复算法时，我花了两年多的时间才决定招募第一个用户。如果没有托马斯·库恩（Tomasz Kuehn），Windows 上的 SuperMemo 可能要晚到2-4年才能问世。如果没有雅努什·穆拉科夫斯基（Janusz Murakowski），SuperMemo 中至关重要的大数据：重复历史记录可能会被推迟1-2年。当增量阅读在2000年诞生时，只有我知道这是一件具有里程碑意义的事情。然而，我花了相当长的时间才意识到这件事的影响程度。今天，我知道神经创造力（neural creativity）是一种突破性的工具，但我仍然半心半意地使用它，而且还不如使用子复习那样频繁，子复习其实只是神经创造力的下位替代方案。

#### 1990年：最初的迹象（1990: First hint）

Algorithm SM-17 was in the making for nearly a quarter of a century. While preparing materials for this article, in my archive, I found a picture of a matrix named “new strength” with rows marked as “strength” and columns marked as “durability”. These were the original names for stability and retrievability used in the years 1988-1990. Like an old fossil, the paper tells me that the idea of Algorithm SM-17 must have been born around 1990.

算法 SM-17 的形成历时近四分之一个世纪。在为本文准备资料时，我在我的档案中发现了一张名为“新强度”的矩阵图片，其行标记为“强度”，列标记为“耐久性”。这些是1988年至1990年间使用的“稳定性”和“可检索性”的原始名称。这张纸，就像一块古老的化石，告诉我算法 SM-17 的想法一定是在1990年左右诞生的。

![[SuperMemo_The true history of spaced repetition_附件/New_strength_matrix.jpg]]

> ***Figure:** A picture of a matrix named “new strength” with rows marked as “strength” and columns marked as “durability”. These were the original names for stability and retrievability used in the years 1988-1990. The paper suggests that the idea of Algorithm SM-17 must have been born around 1990.*
> 
> **图示：** 一张名为“新强度”的矩阵图片，其中行标记为“强度”，列标记为“耐久性”。这些是1988年至1990年间使用的“稳定性”和“可检索性”的原始名称。该论文表明，算法 SM-17 的想法可能诞生于1990年左右。

From the very early beginnings of the two component model of memory, I wanted to build an algorithm around it. My motivation was always half-hearted. SuperMemo worked well enough to make this just a neat theoretical exercise. However, today I see that the algorithm provides data for a model that can answer many questions about memory. Some of those questions have actually never been asked (e.g. about subcomponents of stability). This is also similar to SuperMemo itself. It has always struggled because its value is hard to appreciate in theory. Practical effects are what changes the mind of good students most easily.

从记忆的二元模型最初的萌芽阶段开始，我就想围绕它构建一个算法。我的动力一直都是半心半意的。SuperMemo 运行得足够好，以至于这只是一次绝妙的理论操练。然而，今天我意识到，该算法为模型提供了数据，而这个模型可以回答许多关于记忆的问题。其中一些问题实际上从未被提出过（例如，关于稳定性的子成分）。这与 SuperMemo 本身也很相似。它一直很挣扎，因为它的价值在理论上很难被理解。实际效果才是最容易改变优秀学生想法的东西。

#### 1993年：分心（1993: Distraction）

In 1993, my own thinking was an inhibitor of progress. Further explorations of the algorithm were secondary. They would not benefit the user that much. Memory modelling was pure blue sky research. See: Futility of fine-tuning the algorithm. At that time it was Murakowski who would push hardest for progress. He kept complaining that ” *SuperMemo keeps leaking Nobel Prize value data*“. He screamed at me with words verging on abuse: ” *implement repetition histories now!*“. It was simply a battle of priorities. We had a new Windows version of SuperMemo, the arrival of audio data, the arrival of CD-ROM technology, the arrival of solid competition, incl. at home where Young Digital Poland beat us to the title of the first CD-ROM title in our home country by a month or so. We still cherish the claim to the first Windows CD-ROM in Poland. It was actually still produced in the US, but the contents were made entirely in Poland around 100% pure Polish SuperMemo.

1993年，我自己的思维成为了进步的阻碍。对算法的进一步探索是次要的。它们不会给用户带来太大的好处。记忆建模研究是纯粹的空中楼阁（参见：微调算法的徒劳性）。当时，穆拉科夫斯基（Murakowski）是推动进步最努力的人。他不停地抱怨说：“*SuperMemo 一直在白白流失有价值获得诺贝尔奖的数据*”。他对我大喊大叫，言语近乎辱骂：“*现在就实现复习历史记录！*”。这完全是一场事项优先度之间的争夺战。我们有了新版本的 Windows 上的 SuperMemo，我们兼容了音频学习材料，我们引入了 CD-ROM 技术，我们参与了激烈的市场竞争，包括在国内，Young Digital Poland 比我们早一个月左右获得了国内第一个 CD-ROM 产品的称号。我们仍然珍视我们在波兰推出首个 Windows CD-ROM 的成就。它实际上仍然在美国生产，但内容完全在波兰制作，大约100%纯正的波兰 SuperMemo。

#### 1996年：风险投资（1996: Venture capital）

In February 1996, all obstacles have been cleared and SuperMemo finally started collecting full repetition history data (at that time, it was still an option to prevent clogging lesser systems with unused data). My own data now reaches largely back to 1992-1993 as all items in February 1996 still had their last repetition easily identifiable from the interval. I even have quite a number of histories dating back to 1987. In my OCD for data, I recorded the progress of some specific items manually and was later able to complete repetition histories by manual editing. My own data is now, therefore, the longest spanning repetition history data in spaced repetition in existence. 30 years of data with a massive coverage for 22-25 years of learning. This is a goldmine.

1996年2月，所有障碍都被清除，SuperMemo 终于开始收集完整的复习历史数据（当时，为了防止防止堵塞较弱的系统，适当舍弃不必要的数据仍然是值得考虑的）。我的个人数据现在可以追溯到1992-1993年左右，当时的所有项目，到1996年2月都还可以通过间隔轻松识别出它们的最后一次复习时间。我甚至有相当多的历史数据可以追溯到1987年。出于我对数据的强迫症，我手动记录了一些特定项目的进展，后来通过手动编辑完成了复习历史。因此，我个人的数据现在是现存间隔重复系统中跨度最长的复习历史数据。30年的数据，其中相当一部分学习记录覆盖了22-25年的时长。这是一座金矿。

On Sep 29, 1996, Sunday, in the evening, I devoted two hours to sketching the new algorithm based on the two component model of memory. It all seemed very simple and requiring little work. SuperMemo has just started collecting repetition histories, so I should have plenty of data at hand. Our focus switched from multimedia courses, like Cross Country, to easier projects, like Advanced English. It was a good moment, it seemed. Unfortunately, the next day we got a call from Antek Szepieniec who talked to investors in America with a dream to make SuperMemo World the first Polish company at NASDAQ. He excitedly prophesied his belief that there is a good chance for an injection of a few million dollars into our efforts from venture capital. That instantly tossed me into new roles and new jobs. Of bad things, this has delayed Algorithm SM-17 by two decades. Of good things, the concept of Hypermedia SuperMemo, aka Knowledge Machine, aka incremental reading has gained a great deal of momentum in terms of theory and design. Practice trumped science again.

1996年9月29日，星期日晚间，我花了两个小时来勾勒基于记忆二元模型的新算法。一切看起来都很简单，不需要太多工作。SuperMemo 刚刚开始收集复习历史，所以我应该手头有大量数据。我们的重点从多媒体课程（如定向越野）转向更简单的项目（如高级英语）。这似乎是一个好时机。不幸的是，第二天我们接到了安泰克·谢皮涅茨（Antek Szepieniec）的电话，他与美国的投资者进行了交谈，梦想着让 SuperMemo World 成为第一家在纳斯达克上市的波兰公司。他兴奋地预言，我们的努力很有可能从风险投资中获得数百万美元的注入。这立刻把我推向了新的角色和新的工作。不幸的是，这推迟了算法 SM-17 二十年。幸运的是，超媒体 SuperMemo（又名知识机器，又名增量阅读）的概念在理论和设计方面获得了巨大的发展势头。实践再次战胜了科学。

#### 2005年：理论探索（2005: Theoretical approach）

In 2000, with incremental reading, and then 2006 with priority queue, the need for the delay of repetitions, and the need for early review increased dramatically. This called for huge departures from the optimum. The old Algorithm SM-8 could not cope with that effectively. The function of optimum intervals had to be expanded into the dimension of time (i.e. retrievability). We needed a stability increase function.

2000年，随着增量阅读的引入，以及2006年优先级队列的出现，对重复延迟的需求和提前复习的需求都急剧增加。这迫使我们大幅偏离最优状态。原有的 SM-8 算法无法有效地应对这些变化。最优间隔的函数必须扩展到时间维度（即，可检索性）。我们需要一个稳定性增长函数。

One of the very interesting dynamics of progress in science is that the dendritic explorations of reality often require a critical brain mass to push a new idea through. In 2005, Biedalak and others were largely out of the loop busy with promoting SuperMemo as a business. I was on the way to a major breakthrough in incremental reading: handling overload. With the emergence of Wikipedia, it suddenly appeared that importing tons of knowledge requires little effort, but low-priority knowledge can easily overwhelm high-priority knowledge by sheer volume. Thus richness undermines the quality of knowledge. My solution to the problem was to employ the priority queue. It was to be implemented only in 2006. In the meantime, Gorzelańczyk and Murakowski were busy with their own science projects.

科学进步中一个非常有趣的规律是，对现实的枝状探索往往需要批判性思维才能推动新想法的产生。2005年，别达拉克（Biedalak）和其他人主要忙于将 SuperMemo 推广为一项业务，而我则在增量阅读方面进行重大突破：处理过载问题。随着维基百科的出现，导入大量知识突然变的几乎不需要任何努力，但低优先级知识很容易因其庞大的数量而压倒高优先级知识。因此，知识的丰富性反而损害了知识的质量。我对这个问题的解决方案是采用优先级队列。这个方案直到2006年才得以实施。与此同时，戈热兰奇克（Gorzelańczyk）和穆拉科夫斯基（Murakowski）则忙于他们自己的科学项目。

Gorzelańczyk used to attend a cybernetics conference in Cracow powered by my early inspiration: Prof. Ryszard Tadeusiewicz. For his presentation in 2005, Gorzelańczyk suggested we update our memory model. With the deluge of new data in molecular biology, a decade since the last formulation could make a world of difference. I thought that my ideas of finding a formula for building memory stability would make a good complement. This initial spark soon gained momentum in exchanges with Murakowski. Without those three brains working in concert and whipping up the excitement, the next obvious step would not have been made. Using the tools first employed in the model of intermittent learning in 1990, I decided to find out the function for stability increase. Once my computer started churning data, interesting titbits of information kept flowing serially. The job was to take just a few evenings. In the end, it took half the winter.

戈热兰奇克（Gorzelańczyk）过去常常参加在克拉科夫举办的控制论会议，这个会议受到了我早期灵感来源：雷沙德·塔德乌谢维奇教授（Prof. Ryszard Tadeusiewicz）的启发。为了他在2005年的演讲，戈热兰奇克建议我们更新记忆模型。随着分子生物学中大量新数据的涌现，自上次提出模型以来的十年间，情况可能已经发生了巨大的变化。我认为，我寻找构建记忆稳定性的公式的想法会是一个很好的补充。这个最初的火花很快在与穆拉科夫斯基（Murakowski）的交流中获得了动力。如果没有这三个大脑协同工作并激发兴奋感，下一个显而易见的步骤就不会实现。利用1990年首次应用在间歇性学习模型中的工具，我决定找出稳定性增长的函数。一旦我的计算机开始处理数据，有趣的信息片段就不断地串行流出。这项工作本应只需要几个晚上。最终，它耗费了半个冬天。

#### 2013年：全局视角重新觉醒（2013: Big picture re-awakening）

Like in 2005, in 2013, the critical brain mass had to build up to push the new solutions through. However, I must give most credit to Biedalak. It was he who tipped the scales. With a never-ending battle for the recognition of SuperMemo‘s leadership and pioneering claims, he demanded we go on with the project and sent me for a short creative vacation to complete it. It was to be just one winter project, and it turned out to be two years, and it still consumes a lot of my time.

就像2005年一样，在2013年，必须建立批判性思维，才能推动新解决方案的实施。然而，我必须把大部分功劳归于别达拉克（Biedalak）。是他最终打破了僵局。在为 SuperMemo 的领导地位和开创性主张争取认可的永无止境的战斗中，他要求我们继续推进这个项目，并送我进行一次短暂的创意假期来完成它。原本这只是一个冬季项目，结果却变成了两年，而且至今仍耗费我大量时间。

On Nov 09, 2014, we took a 26 km walk to discuss the new algorithm. Walktalking is our best form of brainstorming that always brings great fruits. Next day, we met in a swimming pool joined with Leszek Lewoc, worshipper of big data, who always has a great deal of fantastic ideas (I first met Lewoc in 1996, and his wife was probably a user as of SuperMemo as early as in 1992[verify!]). Simple conclusions from that brainstorming time were to use the two component model of memory to simplify the approach to the algorithm, simplify the terminology, and make it more human-friendly (no more A-Factors, U-Factors, R-Factors, etc.).

2014年11月9日，我们进行了一次26公里的步行，讨论新算法。边走边谈是我们最好的头脑风暴形式，总是能带来丰硕的成果。第二天，我们在一个游泳池见面，莱谢克·莱沃克（Leszek Lewoc）也加入了我们，他是大数据的崇拜者，总是能提出许多绝妙的想法（我最早在1996年认识莱沃克，他的妻子可能早在1992年就是 SuperMemo 的用户了[待验证！]）。那次头脑风暴得出的简单结论是，利用记忆的二元来简化算法的近似方法，简化术语，使其更人性化（不再使用 A 因子、U 因子、R 因子等）。

### 通过复习增加记忆稳定性（Increase in memory stability with rehearsal）

To understand Algorithm SM-17, it is helpful to understand the calculations used to figure out the formula for the increase in memory stability. In 2005, our goal was to find the function of stability increase for any valid level of R and S: *SInc*= *f*(R,S). The goals and tools were pretty similar to those used in the quest to build the model of intermittent learning (1990).

了理解SM-17算法，了解用于计算记忆稳定性增长公式的过程会很有帮助。在2005年，我们的目标是找到适用于任何有效的 R（复习次数）和 S（间隔时间）水平的稳定性增长函数，即 *SInc* = _f_(R,S)。为了实现这个目标和所使用的工具与1990年构建间歇性学习模型的探索过程中用过的非常相似。

Archive warning: Why use literal archives?

下面是引用文档

Until 2005, we were not able to formulate a universal formula that would link a repetition with an increase in memory stability. Repetition spacing algorithms were based on a general understanding of how stability increases when so-called optimum inter-repetition intervals are used (defined as intervals that produce a known recall rate that usually exceeds 90%). The term *optimum interval* is used for interval’s applicability in learning. The said repetition spacing algorithms also allow for determining an accurate stability increase function for optimum intervals in a matrix form. However, little has been known about the increase in stability for low retrievability levels (i.e. when intervals are not *optimum*). With data collected with the help of SuperMemo, we can now attempt to fill in this gap. Although SuperMemo has been designed to apply the optimum intervals in learning, in real-life situations, users are often forced to delay repetitions for various reasons (such as holiday, illness, etc.). This provides for a substantial dose of repetitions with lower retrievability in nearly every body of learning material. In addition, in 2002, SuperMemo introduced the concept of a mid-interval repetition that makes it possible to shorten inter-repetition intervals. Although the proportion of mid-interval repetitions in any body of data is very small, for sufficiently large data samples, the number of repetition cases with very low and very high retrievability should make it possible to generalize the finding on the increase in memory stability from the retrievability of 0.9 to the full retrievability range.

在2005年之前，我们一直无法建立一个通用公式，将复习与记忆稳定性的增长联系起来。复习间隔算法是基于对以下内容的普遍理解建立的：当使用所谓的“最佳复习间隔”（定义为能使回忆成功率达到目标水准（通常超过90%）的间隔）时，稳定性如何增长。术语“*最佳间隔*”用于描述间隔在学习中的适用性。上述的复习间隔算法也允许（以矩阵形式）确定最佳间隔的精确稳定性增长函数。然而，对于低可检索性水平（即间隔并非“*最佳*”时）下的稳定性增长状况，我们知之甚少。借助 SuperMemo 收集的数据，我们现在可以尝试填补这一空白。尽管 SuperMemo 的设计目的是将最佳间隔应用到学习中，但在实际情况下，用户经常因各种原因（如假期、疾病等）被迫延迟复习。这为几乎所有学习材料带来了大量（材料处在）低可检索性（时）的复习。此外，2002年，SuperMemo 引入了中期间隔复习的概念，使得缩短复习间隔成为可能。尽管任何数据集中的中期间隔复习比例都很小，但只要有足够大的数据样本，我们就能获得足够多的、具有极低或者极高可检索性的复习案例数量，进而应该能够将关于记忆稳定性增长的发现，从可检索性为0.9的情况推广到整个可检索性范围。

To optimally build memory stability through learning, we need to know the *function of optimum intervals*, or, alternatively, the *function of stability increase* ( *SInc*). These functions take three arguments: memory stability (S), memory retrievability (R) and difficulty of knowledge (D). Traditionally, SuperMemo has always focused on the dimensions S and D, as keeping retrievability high is the chief criterion of the optimization procedure used in computing inter-repetition intervals. The focus on S and D was dictated by practical applications of the stability increase function. 

为了通过最优路径学习，以建立记忆稳定性，我们需要了解“最佳间隔函数”，或“稳定性增长函数”（_SInc_）。这些函数需要三个参数：记忆稳定性（S）、记忆可检索性（R）和知识难度（D）。传统上，SuperMemo 一直专注于稳定性（S）和难度（D）这两个维度，因为在计算重复间隔时，“保持高可检索性”是优化程序的主要标准。对 S 和 D 的关注源于稳定性增长函数的实际应用。

In the presented article, we focus on S and R as we attempt to eliminate the D dimension by analyzing “pure knowledge”, i.e. non-composite memory traces that characterize knowledge that is easy to learn. Eliminating the D dimension makes our theoretical divagations easier, and the conclusions can later be extended to composite memory traces and knowledge considered difficult to learn. In other words, as we move from practice to theory, we shift our interest from the (S,D) pair to the (S,R) pair.

在本文中，我们专注于稳定性（S）和可提取性（R），试图通过分析“纯知识”（即标记着“易于学习的知识”的非复合记忆痕迹）来消除难度（D）这一维度。消除难度（D）维度使我们的理论推导更加容易，并且所获得的结论随后成功推广到复合记忆痕迹和被认为难以学习的知识。换句话说，当我们从实践转向理论时，我们将兴趣从（S，D）对转移到（S，R）对。

In line with this reasoning, all data sets investigated have been filtered for item difficulty. At the same time, we looked for possibly largest sets in which representation of items with low retrievability would be large enough as a result of delays in rehearsal (in violation of the optimum spacing of repetitions).

为了符合这种思路，所有被用于研究的数据集都已针对项目难度进行了筛选。同时，我们寻找尽可能大的数据集，确保其中在低可提取行下被复习的项目样本足够大，能够作为延迟复习（即违反最佳重复间隔）的结果参考。

We have developed a two-step procedure that was used to propose a symbolic formula for the increase in stability for different retrievability levels in **data sets characterized by low and uniform difficulty** (so-called well-formulated knowledge data sets that are easy to retain in memory). Well-formulated and uniform learning material makes it easy to distill a pure process of long-term memory consolidation through rehearsal. As discussed elsewhere in this article, ill-formulated knowledge results in superposition of independent consolidation processes and is unsuitable for the presented analysis.

我们还开发了一个两步程序，用于从**难度低且均匀的数据集**（即易于记忆的所谓“良好构建的知识数据集”）中，提炼各个不同可提取性水平下，稳定性增长的符号公式。构建良好且难度均匀的学习材料，使得提炼“通过复习巩固长期记忆”的纯粹过程变得容易。正如本文其他部分所讨论的，构建不良的知识会导致独立（记忆）巩固过程的叠加，不适合本分析。

#### 两步计算（Two-step computation）

In SuperMemo 17, it is possible to run through the full record of repetition history to collect stability increase data. This makes it possible to plot a graphic representation of the *SInc[]* matrix. That matrix may then be used in an effort to find a symbolic approximation of the function of stability increase. The same reasoning was used in 2005. The procedure was much simpler though. This can then be used to better understand Algorithm SM-17:

在 SuperMemo 17中，可以遍历完整的重复历史记录，以收集稳定性增长数据。这使得绘制 *SInc[]* 矩阵的图表示成为可能。然后，就可尝试用该矩阵寻找稳定性增长的近似函数表达。2005年我们也使用了相同的推理。然而，当时的程序要简单得多。这可以用来更好地理解 SM-17 算法：

Archive warning: Why use literal archives?

下面是引用文档

The two-step procedure for determining the function of the increase in memory stability *SInc*:

-   **Step 1**: Using a matrix representation of *SInc* and an iterative procedure to minimize the deviation *Dev* between the grades in a real learning process (data) and the grades predicted by *SInc*. *Dev* is defined as a sum of *R-Pass* over a sequence of repetitions of a given piece of knowledge, where *R* is retrievability and *Pass* is 1 for passing grades and 0 for failing grades
-   **Step 2**: Using a hill-climbing algorithm to solve a least-square problem to evaluate symbolic candidates for *SInc* that provide the best fit to the matrix *SInc* derived in Step 1

确定记忆稳定性增长函数 *SInc* 的两步程序：

- **第一步**：使用 *SInc* 的表示矩阵和一套迭代程序，以最小化实际学习过程（数据）中的等级与 *SInc* 预测的等级之间的偏差 *Dev* 。*Dev* 定义为给定知识的一系列重复中 *R-Pass* 的总和，其中 *R* 是可提取性，*Pass* 在成绩及格为1，不及格时为0。
- **第二步**：使用爬山算法解决最小二乘问题，以评估 *SInc* 的候选表达式，看哪个候选表达式能最好地拟合第一步中导出的矩阵 *SInc* 。

#### 计算稳定性增长（Computing stability increase）

The matrix of stability increase ( *SInc[]* ) was computed in **Step 1**. In 2005, we could take any initial hypothetical plausible value of *SInc*. Today, as we know the approximate nature of the function, we can speed up the process and make it non-iterative (see Algorithm SM-17).

稳定性增长矩阵（_SInc[]_）在**第一步**中计算得出。2005年，我们可能采用任何合理的假设值作为 *SInc* 的初始值。如今，由于我们已经了解了该函数的近似性质，我们可以加快该过程并使其无需迭代（参见SM-17算法）。

Archive warning: Why use literal archives?

下面是引用文档

Let us define a procedure for computing stability of memory for a given rehearsal pattern. This procedure can be used to compute stability on the basis of known grades scored in learning (practical variant) and to compute stability on the basis of repetition timing only (theoretical variant). The only difference between the two is that the practical variant allows of the correction of stability as a result of stochastic forgetting reflected by failing grades.

让我们定义一个针对给定复习模式，计算记忆稳定性的程序。该程序既可以基于学习中已经获得的（响应）评分（实际变体）计算（记忆）稳定性，也可以仅基于重复时间计算稳定性（理论变体）。两者之间的唯一区别在于，实际变体允许根据不及格评分所反映的随机遗忘而对稳定性进行校正。

In the following passages we will use the following notation:

-   S(t) – memory stability at time t
-   S[r] – memory stability after the r <sup>th</sup> repetition (e.g. with S[1] standing for memory stability after learning a new piece of knowledge)
-   R(S,t) – memory retrievability for stability S and time t (we know that R=exp <sup>-k*t/S</sup> and that k=ln(10/9))
-   *SInc*(R,S) – increase in stability as a result of a rehearsal for retrievability R and stability S such that *SInc*(R(S,t),S(t))=S(t*)/S(t’)=S[r]/S[r-1] (where: t’ and t* stand for the time of rehearsal as taken before and after memory consolidation with t*-t’ being indistinguishable from zero)*

在以下段落中，我们将使用以下符号：

- S(t) – 时间为 t 时的记忆稳定性
- S[r] – 第 r 次重复后的记忆稳定性（例如，S[1]表示新学到的知识的记忆稳定性）
- R(S,t) – 稳定性为 S 且时间为 t 的记忆可提取性（我们已经知道 R=exp<sup>-k*t/S</sup>，且 k=ln(10/9)）
- *SInc*(R,S) – 可提取性为 R 且稳定性为 S 的复习所带来的稳定性增长，使得 *SInc*(R(S,t),S(t))=S(t*)/S(t’)=S[r]/S[r-1]（其中：t’ 和 t* 表示复习时间，分别表示记忆巩固之前和之后的时间，t*-t’ 接近于0）

Our goal is to find the function of stability increase for any valid level of R and S: *SInc*= *f*(R,S).

我们的目标是找到一个稳定性增长函数，该函数适用于任何有效的 R 和 S 值：_SInc_ = _f_(R, S)。

If we take any plausible initial value of *SInc*(R,S), and use S[1]=S<sub>1</sub>, where S<sub>1</sub> is the stability derived from the memory decay function after the first-contact review (for optimum inter-repetition interval), then for each repetition history we can compute S using the following iteration:

```
r:=1;
S[r]:=S1
repeat
 t:=Interval[r]; // where: Interval[r] is taken from a learning process (practical variant) or from the investigated review pattern (theoretical variant)
 Pass:=(Grade[r]&gt;=3); // where: Grade[r] is the grade after the r-th interval (practical variant) or 4 (theoretical variant)
 R:=Ret(S[r],t);
 if Pass then
    S[r+1]:=S[r]*SInc[R,S[r]]
    r:=r+1;
else begin
   r:=1;
   S[r]:=S1;
   end;
until (r is the last repetition)
```

如果我们取 _SInc_(R, S) 的任何合理的初始值，并使用 S[1] = S<sub>1</sub>，其中 S<sub>1</sub> 是在（遵循最佳复习间隔）第一次复习后，通过记忆衰减函数得出的稳定度。那么，对于每个复习历史，我们可以使用以下迭代方案来计算 S：

```
r:=1;
S[r]:=S1
repeat
 t:=Interval[r]; // 其中：Interval[r] 取自学习过程（实际变体）或（作为研究对象的）复习模式（理论变体）
 Pass:=(Grade[r]&gt;=3); // 其中：Grade[r] 是第 r 个间隔后的（响应）评分（实际变体）或直接取 4（理论变体）。
 R:=Ret(S[r],t);
 if Pass then
    S[r+1]:=S[r]*SInc[R,S[r]]
    r:=r+1;
else begin
   r:=1;
   S[r]:=S1;
   end;
until (r is the last repetition)
```

In Algorithm SM-8, we can use the first-interval graph to determine S<sub>1</sub>, which is progressively shorter after each failing grade.

在 SM-8 算法中，我们可以使用初次间隔时长的图表来确定 S<sub>1</sub>，该时长在每次不及格后都会缩短。

We start the iterative process with a hypothetical initial value of matrix *SInc[R,S]*, e.g. with all entries arbitrarily set to E-Factor as in Algorithm SM-2.

我们以假设的矩阵 _SInc[R, S]_ 初始值开始迭代过程，例如，将所有条目任意设置为 SM-2 算法中的 E-Factor。

We can then keep using the above procedure on the existing repetition history data to compute a new value of *SInc[R,S]* that provides a lesser deviation from grades scored in the actual learning process (we use differences *R-Pass* for the purpose).

然后，我们可以继续在现有的复习历史数据上使用上述程序，计算出新的 _SInc[R, S]_ 值，该值与实际学习过程中获得的（响应）评分偏差更小（为此，我们使用了差值 _R-Pass_）。

Incremental improvements are possible if we observe that:

如果我们留意以下情况，还可以持续进行改进：

Archive warning: Why use literal archives?

下面是引用文档

-   if Pass=true and S[r]<Interval[r] then *SInc[R,S[r-1]]* entry is underestimated (and can be corrected towards Interval[r]/S[r]* *SInc[R,S[r-1]]*)
-   if Pass=false and S[r]>Interval[r] then *SInc[R,S[r-1]]* entry is overestimated

- 如果 Pass=true 且 S[r]<Interval[r]，则 *SInc[R, S[r-1]]* 的值被低估（可以向 Interval[r]/S[r]* _SInc[R, S[r-1]]_ 进行校正）。
- 如果 Pass=false 且 S[r]>Interval[r]，则 *SInc[R, S[r-1]]* 的值被高估。

We can iterate over *SInc[]* to bring its value closer and closer to the alignment with grades scored in the learning process.This approach makes it possible to arrive at the same final *SInc[R,S]* independent of the original value of *SInc[R,S]* set at initialization

我们可以迭代 *SInc[]*，使其值越来越接近，向着学习过程中获得的（响应）评分对齐。这种方法使得无论初始设置的 *SInc[R, S]* 原始值如何，都能得到相同的最终 _SInc[R, S]_。

In Algorithm SM-17, instead of the above bang-bang incremental approach, we use actual forgetting curves to provide a better estimate of retrievability, which can then be used to correct the estimated stability. The ultimate stability estimate combines the theoretical prediction of retrievability, actual recall taken from forgetting curves (weighted for the availability of data), and the actual grade combined with the interval as in the above reasoning. By combining those three sources of information, Algorithm SM-17 can provide stability/interval estimates without the need to iterate over the *SInc[]* matrix over and over again.

在 SM-17 算法中，我们没有采用上述起停式的增量迭代方法，而是使用实际的遗忘曲线来提供更好的可检索性估计，这样之后还可以利用该（可检索性的）估值来校正稳定性的估值。最终的稳定性估计结合了可检索性的理论预测、从遗忘曲线中获得的实际回忆率（根据数据的可用性进行加权）以及如上述推理中使用的实际（响应）等级与间隔。通过结合这三个信息来源，SM-17 算法可以提供稳定性/间隔估计，而无需反复迭代 _SInc[]_ 矩阵。

（*注：起停式控制（bang-bang control），也称为砰砰控制、bang-bang控制、开关控制、继电器式控制或磁滞控制，是会让控制输出在两种状态之间切换的回授控制器，起停式控制会使控制输出在某个状态停留一段时间，再跳到另一个状态。起停式控制可以用有迟滞功能的元件实作。*）

#### 稳定性增长的符号公式（Symbolic formula for stability increase）

After many iterations, we obtain a value of *SInc* that minimizes the error. The procedure is convergent. With the matrix of stability increase available, we can look for a symbolic formula expressing the increase in stability.

经过多次迭代，我们获得一个能使误差最小化的 _SInc_ 值。这个过程是收敛的。有了稳定性增长矩阵，我们就可以寻找一个表达稳定性增长的符号公式。

##### 稳定性增长对 S（稳定性）的依赖性（Dependence of stability increase on S）

Predictably, *SInc* decreases with an increase in *S* :

可以预见的是，_SInc_ 随着 _S_ 的增加而减少：

Archive warning: Why use literal archives?

下面是引用文档

In Step 2, we will use the *SInc[R,S]* matrix obtained here to obtain a symbolic formula for *SInc*.

在步骤 2 中，我们将使用此处获得的 _SInc[R, S]_ 矩阵，来获得 _SInc_ 的符号公式。

**Step 2** – Finding *SInc* as a symbolic formula

**步骤 2** – 将 _SInc_ 转化为符号公式

We can now use any gradient descent algorithm to evaluate symbolic candidates for SInc that provide the best fit to the matrix SInc derived above.

我们现在可以使用任何梯度下降算法，来评估 _SInc_ 的符号候选式，这些候选式能最好地拟合上面导出的 _SInc_ 矩阵。

When inspecting the SInc matrix, we immediately see that SInc as a function of S for constant R is excellently described with a negative power function as in the exemplary data set below:

在检查 _SInc_ 矩阵时，我们立即看到，对于恒定的 R，*SInc* 作为 S 的函数，可以用负幂函数很好地描述，如下面的示例数据集所示：

![[SuperMemo_The true history of spaced repetition_附件/SInc-vs-S-2.gif]]

Which is even more clear in the log-log version of the same graph:

在同一图表的对数-对数版本中，这一点更加明显：

![[SuperMemo_The true history of spaced repetition_附件/LogSInc-vs-logS-1.gif]]

The conclusion on the power dependence between *SInc* and *S* above confirms the previous findings. In particular, the decline of R-Factors along repetition categories in SuperMemo has always been best approximated with a power function

上述关于 *SInc* 和 S 之间幂依赖性的结论，证实了之前的发现。特别是，在 SuperMemo 中，R 因子随复习次数的下降，一直以来都用幂函数得到了最好的近似。

（*译注：翻到这里译者不太记得之前 R 因子的定义了，大概回顾了一下，应该是指下次最佳复习间隔和上次最佳复习间隔的比值（下次间隔时长是上一次的多少倍）*）

##### 稳定性增长对 R（可检索性）的依赖性（Dependence of stability increase on R）

As predicted by the spacing effect, *SInc* is greater for lower levels of *R* . Note, however, that the procedure used in 2005 might have introduced an artifact: the survival of a memory trace over time would linearly contribute to the new stability estimate. This is problematic due to the stochastic nature of forgetting. Longer survival of memories may then be a matter of chance. In Algorithm SM-17, more evidence is used to estimate stability, and the *survival interval* is weighed up with all other pieces of evidence.

正如间隔效应所预测的，对于较低的 R 值，*SInc* 更大。然而，请注意，2005 年使用的程序可能引入了一个人为因素：记忆痕迹随时间的残留会线性地影响新的稳定性估计。由于遗忘的随机性，这存在问题。记忆的较长时间保留可能是偶然的。在 SM-17 算法中，使用了更多的证据来估计稳定性，并且*残留间隔*与所有其他证据一起被权衡。

Archive warning: Why use literal archives?

下面是引用文档

When we look for the function reflecting the relationship of *SInc* and R for constant S, we see more noise in data due to the fact that SuperMemo provides far fewer hits at low R (its algorithm usually attempts to achieve R>0.9). Nevertheless, upon inspecting multiple data sets we have concluded that, somewhat surprisingly, *SInc* increases exponentially when R decreases (see later to show how this increase results in a nearly linear relationship between *SInc* and time). The magnitude of that increase is higher than expected, and should provide further evidence of the power of the spacing effect. That conclusion should have a major impact on learning strategies.

当我们寻找基于恒定的 S 值，反映 _SInc_ 和 R 之间关系的函数时，由于 SuperMemo 在低 R 值时提供的达成（目标记忆保留率的）次数要少得多（其算法通常试图实现 R>0.9），因此我们在数据中看到了更多的噪声。尽管如此，在检查多个数据集后，我们得出结论，令人惊讶的是，当 R 降低时，_SInc_ 呈指数增长（稍后将展示这种增长如何导致 _SInc_ 和时间之间几乎呈线性关系）。这种增长的幅度高于预期，能够进一步证明间隔效应的强大作用。这一结论应该对学习策略产生重大影响。

Here is an exemplary data set of SInc as a function of R for constant S. We can see that SInc=f(R) can be quite well approximated with a negative exponential function:

这是一个示例数据集，展示了基于恒定的 S 值时，*SInc* 与 R 之间的关系。我们可以看到，SInc=f(R) 可以用负指数函数很好地近似：

![[SuperMemo_The true history of spaced repetition_附件/SInc-vs-R-2.gif]]

And the semi-log version of the same graph with a linear approximation trendline intercept set at 1:

以及同一图表的半对数版本，其线性近似趋势线截距设置为1：

![[SuperMemo_The true history of spaced repetition_附件/SInc-vs-logR-2.gif]]

Interestingly, stability increase for retrievability of 100% may be less than 1. Some molecular research indicates increased lability of memories at review time. This is one more piece of evidence that repetitive cramming can hurt you not only by costing you extra time.

有趣的是，100% 可检索性时的稳定性增长可能小于 1。一些分子研究表明，在复习时，记忆的易变性会增加。这进一步证明了重复填鸭式学习不仅会浪费额外的时间，还会对你有其他伤害。

##### 稳定性增长对可检索性的依赖性（2018）（Dependence of stability increase on retrievability (2018)）

Despite all the algorithmic differences and artifacts, the dependence of stability increase on retrievability for well-formulated knowledge is almost identical with that derived from data produced 13 years later by Algorithm SM-17.

尽管有这些算法上的差异和人为因素的影响，对于结构良好的知识，（我们在2018年对）稳定度增益对可检索性的依赖性（的结论），与13年后由 SM-17 算法通过数据得出的结论几乎相同。

Recall that in SuperMemo, we use forgetting curves to provide a better estimate of retrievability. This is then used to correct the estimated stability. By combining several sources of information, Algorithm SM-17 can provide more accurate stability estimates. There is still the old artifact of the survival of a memory trace that would linearly contribute to the new stability. This artifact can be weighed out parametrically. However, each time SuperMemo tries to do that, its performance metrics drop.

请记住，在 SuperMemo 中，我们使用遗忘曲线来提供更好的可检索性估值。然后，这被用于校正稳定性估值。通过结合多个信息来源，SM-17 算法可以提供更准确的稳定性估值。仍然存在一个旧的人为因素，即记忆痕迹的残留会线性地影响新的稳定性。可以参数化地权衡掉这个人为因素。然而，每次 SuperMemo 尝试这样做时，其性能指标都会下降。

Despite all the improvements, and much larger data sets (esp. for low R), the dependence of stability increase on retrievability for easy items seems set in stone.

尽管进行了这些改进，并且使用了更大的数据集（尤其是在 R 值较低的条件下），简单项目的稳定性增长对可检索性的依赖性似乎已成定局。

This perfect picture collapses when we add difficult knowledge into the mix. This is partly due to reducing the *long survival* artifact mentioned above. For that reason, new SuperMemos do not rely on this seemingly well-confirmed memory formula:

当我们把困难知识加入进来时，这幅完美的图景就崩溃了。这一定程度上是由于要消除上述提到的“长期残留”人为因素的影响（从而导致了 SuperMemo 的性能下降）。因此，新的 SuperMemo 版本不再依赖这个看似已被充分证实的记忆公式：

![[SuperMemo_The true history of spaced repetition_附件/Stability_increase_as_a_function_of_retrievability.png]]

> ***Figure:** The strength of long-term memory depends on the timing of review. For well-formulated knowledge, long delays in review produce large increase in memory stability. Optimum review should balance that increase with the probability of forgetting. In the presented graph, the relationship between stability increase and the logarithm of retrievability (log(R)) is linear. Log(R) expresses time. Nearly 27,000 repetitions have been used to plot this graph. Observed memory stability before review spanned from 2 days to 110 days. Maximum increase in stability of nearly 10-fold was observed for lowest levels of retrievability. The stability increase matrix was generated with Algorithm SM-17 in SuperMemo 17*
> 
> ***图示**：长期记忆的强度取决于复习的时间安排。对于结构良好的知识，较长的复习延迟会产生较大的记忆稳定性增长。最佳复习应在该增长与遗忘概率之间取得平衡。在所示的图表中，稳定性增长与可检索性对数 (log(R)) 之间的关系是线性的。Log(R) 表示时间。为了绘制该图，使用了近 27,000 次复习的数据。观察到的复习前记忆稳定性从 2 天到 110 天不等。在最低的可检索性水平下，观察到近 10 倍的最大稳定性增长。该稳定性增长矩阵由 SuperMemo 17 中的 SM-17 算法生成。*

#### 记忆稳定性增长公式（Memory stability increase formula）

With the matrix of stability increase at hand, we could look for a symbolic expression of stability increase. The equation that has been found in 2005 will later be referred to as *Eqn. SInc2005*. Note that formulas used in Algorithm SM-17 differ:

有了稳定性增长矩阵，我们可以寻找稳定性增长的符号表达式。2005 年发现的等式在下文中将被称为 *Eqn. SInc2005*。请注意，SM-17 算法中使用的公式有所不同：

Archive warning: Why use literal archives?

下面是引用文档

For constant knowledge difficulty, we applied two-dimensional surface-fitting to obtain the symbolic formula for *SInc*. We have used a modified Levenberg-Marquardt algorithm with a number of possible symbolic function candidates that might accurately describe *SInc* as a function of S and R. The algorithm has been enhanced with a persistent random-restart loop to ensure that the global maxima be found. We have obtained the best results with the following formula <small>(Eqn. SInc2005)</small>:

对于恒定的知识难度，我们采用二维曲面拟合来获得 _SInc_ 的符号公式。我们使用了改进的 Levenberg-Marquardt 算法，以及一系列可能的符号函数候选式，这些候选式可以准确地将 _SInc_ 描述为 S 和 R 的函数。该算法通过一个持久的随机重启循环进行了增强，以确保找到全局最大值。我们通过以下公式获得了最佳结果 <small>(Eqn. SInc2005)</small>：

*SInc*= *a*S<sup><em>-b</em>&nbsp;</sup>×e<sup><em>c</em>R</sup>+*d*

where:

-   *SInc* – increase in memory stability as a result of a successful repetition (quotient of stability S before and after the repetition)
-   R – retrievability of memory at the moment of repetition expressed as the probability of recall in percent
-   S – stability of memory before the repetition expressed as an interval generating R=0.9
-   *a*, *b*, *c*, *d* – parameters that may differ slightly for different data sets
-   e – base of the natural logarithm

其中：

- _SInc_ – 成功复习后记忆稳定性的增长（复习前后稳定性 S 的商）
- R – 复习时记忆的可检索性，用回忆成功的概率（百分比）表示
- S – 复习前记忆的稳定性，用生成 R=0.9 （即每次复习时会议成功率为90%）的（复习）间隔表示
- *a*、*b*、*c*、*d* – 可能因数据集不同而略有不同的参数
- e – 自然对数的底数

The parameters *a*, *b*, *c*, *d* would vary slightly for different data sets, and this might reflect user-knowledge interaction variability (i.e. different sets of learning material presented to different users may result in a different distribution of difficulty as well as with different grading criteria that may all affect the ultimate measurement).For illustration, an average value of *a*, *b*, *c*, *d* taken from several data sets has been found to be: *a=76*, *b=0.023*, *c=-0.031*, *d:=-2*, with *c* varying little from set to set, and with *a* and *d* showing relatively higher variance. See the example: How to use the formula for computing memory stability?

参数 _a_、_b_、_c_、_d_ 会因数据集不同而略有不同，这可能反映了用户与知识交互的多样性（即，呈现给不同用户的不同学习材料集可能导致不同的难度分布，以及不同的评分标准，这些都可能影响最终的测量结果）。为了说明这一点，从几个数据集中获得的 _a_、_b_、_c_、_d_ 的平均值为：*a=76*，*b=0.023*，*c=-0.031*，*d=-2*，其中 *c* 在不同数据集之间的变化很小，而 *a* 和 *d* 显示出相对较高的方差。请参阅示例：如何使用公式计算记忆稳定性？

### 从稳定性增长公式得出的结论（Conclusions derived from stability increase formula）

The above formula for stability increase differs slightly from later findings. For example, it seems to underestimate the decline in stability increase with S (low *b*). However, it can be used to derive a great deal of interesting conclusions.

上述稳定性增长公式与后来的发现略有不同。例如，它似乎低估了稳定性增长幅度随 S （稳定性）的下降（在 *b* 值较低的情况下）。然而，它可以用来推导出许多有趣的结论。

#### 复习价值随时间的线性增长（Linear increase in value of review over time）

Due to the spacing effect the potential for an increase in memory stability keeps growing over time in nearly linear fashion:

由于间隔效应，记忆稳定性增长的潜力随着时间的推移以近乎线性的方式不断增长：

Archive warning: Why use literal archives?

下面是引用文档

The above formula produced *SInc* values that differed on average by 15% from those obtained from data in the form of the *SInc* matrix on homogeneous data sets (i.e. repetition history sets selected for: a single student, single type of knowledge, low difficulty, and a small range of A-Factors).

上述公式产生的 _SInc_ 值，与在同质数据集（即，通过以下条件筛选出的复习历史集：单个学生、单一类型的知识、低难度、且 A-因子取值范围较小）上以 _SInc_ 矩阵形式获得的值相比，平均相差 15%。

As inter-repetition interval increases, despite double exponentiation over time, *SInc* increases along a nearly-linear sigmoid curve (both negative exponentiation operations canceling each other):

随着复习间隔的增加，尽管随着时间的推移进行了双重指数运算，_SInc_ 仍沿近似线性的 S 型曲线增长（两个负指数运算相互抵消）：

![[SuperMemo_The true history of spaced repetition_附件/SInc-vs-time-2.gif]]

> ***Figure:** The graph of changes of SInc in time. This graph was generated for S=240 using Eqn. SInc2005.*
> 
> ***图示：** SInc 随时间变化的图表。该图表是在 S=240 的条件下，使用 Eqn. SInc2005 生成的。*

The nearly linear dependence of *SInc* on time is reflected in SuperMemo by computing the new optimum interval by multiplying O-Factor by the actually used inter-repetition interval, not by the previously computed optimum interval (in SuperMemo, O-Factors are entries of a two-dimensional matrix OF[S,D] that represent *SInc* for R=0.9).

*SInc* 对时间的近乎线性的依赖性，在 SuperMemo 中通过以下方式体现：计算新的最佳间隔时，将 O-因子乘以实际使用的复习间隔，而不是之前计算的最佳间隔（在 SuperMemo 中，O-因子是二维矩阵 OF[S, D] 中的项目，代表 R=0.9 时 *SInc* 的值）。

#### 记忆稳定性的预期增长（Expected increase in memory stability）

Optimization of learning may use various criteria. We may optimize for a specific recall level or for maximization of the increase in memory stability. In both cases, it is helpful to understand the expected level of stability increase.

学习优化可以使用各种标准。我们可以为了达到特定的回忆成功率进行优化，也可以为了最大化记忆稳定性的增长幅度进行优化。在这两种情况下，理解（记忆）稳定性增长幅度的预期水平都是有帮助的。

Let’s define the expected value of the increase in memory stability as:

E(*SInc*)= *SInc*×R

where:

-   R – retrievability
-   *SInc* – increase in stability
-   E(*SInc*) – expected probabilistic increase in stability (i.e. the increase defined by *SInc* and diminished by the possibility forgetting)

我们将记忆稳定性增长的期望值定义为：

E(*SInc*)= *SInc*×R

其中：

- R – 可检索性
- *SInc* – 稳定性增长幅度
- E(*SInc*) – 预期的稳定性增长幅度（即，由 _SInc_ 定义并可能因遗忘可而减少的增长）

The formula for stability increase derived in 2005 produced a major surprise. We used to claim that the best speed of learning can be achieved with the forgetting index of 30-40%. Eqn SInc2005 seemed to indicate that very low retention can bring pretty good memory effects. Due to the scarcity of low-R data back in 2005, those conclusions need to be taken with caution:

2005 年推导出的稳定性增长公式产生了一个巨大的惊喜。我们过去常常声称，将遗忘指数保持在 30-40% 可以实现最佳的学习速度。但 Eqn SInc2005 似乎表明，非常低的（记忆）保留率也能带来相当好的记忆效果。由于 2005 年 R 值较低的数据还很匮乏，这些结论需要谨慎对待：

Archive warning: Why use literal archives?

下面是引用文档

From Eqn SInc2005 we have E(*SInc*)=(*a*S<sup><em>-b</em></sup>×e<sup><em>c</em>R</sup>+*d*)×R. By finding the derivative d *ESInc*/d R, and equating it with zero, we can find retrievability that maximizes the expected increase in stability for various levels of stability:

根据 Eqn SInc2005，我们有 E(*SInc*)=(*a*S<sup><em>-b</em></sup>×e<sup><em>c</em>R</sup>+*d*)×R。通过求导 d *ESInc*/d R，并将其置零（*译注：就是寻找导数为0的点，导数为零的点就是极值点，高中应该都学过吧*），我们可以找到不同稳定性水平下，使预期稳定性增长最大化的可检索性：

![[SuperMemo_The true history of spaced repetition_附件/ESInc-vs-R-1-1.gif]]

> ***Figure:** Expected increase in memory stability* E(SInc) *as a function of retrievability R for stability S derived from Eqn ( SInc2005). Using the terminology known to users of SuperMemo, the maximum expected increase in memory stability for short intervals occurs for the forgetting index equal to 60%! This also means that the maximum forgetting index allowed in SuperMemo (20%) results in the expected increase in stability that is nearly 80% less than the maximum possible (if we were only ready to sacrifice high retention levels).*
> 
> ***图：** 记忆稳定性预期增长幅度 E(SInc) 作为可检索性 R 的函数，其中稳定性 S 由 Eqn(SInc2005) 推导得出。使用 SuperMemo 用户熟悉的术语，短间隔内记忆稳定性预期增长的最大值出现在遗忘指数等于 60% 的情况下！这也意味着，SuperMemo 中允许的最大遗忘指数（20%）对应的（记忆）稳定性预期增长幅度比最大可能值（如果我们只准备牺牲高保留率）低近 80%。*

![[SuperMemo_The true history of spaced repetition_附件/ESInc_as_function_of_R_for_S.jpg]]

> ***Figure:** Expected increase in memory stability E(SInc) as a function of retrievability R and stability S as derived from Eqn SInc2005*
> 
> ***图：** 记忆稳定性预期增长幅度 E(SInc) 作为可检索性 R 和稳定性 S 的函数，由 Eqn SInc2005 推导得出。*

#### 间隔重复中的记忆复杂性（Memory complexity in spaced repetition）

Memory stability in spaced repetition depends on the quality of review which depends on memory complexity. As early as in 1984, I expressed that in my own learning in what later became known as minimum information principle. For effective review, knowledge needs to be simple. It may form a complex structure, but individual memories subject to review should be atomic. In 2005, we found a formula that governs the review of complex memories.

间隔重复中的记忆稳定性取决于复习的质量，而复习的质量取决于记忆的复杂性。早在 1984 年，我就在自己的学习中表达了这一点，后来这被称为最小信息原则。为了有效复习，知识需要简单。它可以形成复杂的结构，但接受复习的单个记忆应该是原子化的。2005 年，我们找到了一个控制复杂记忆复习的公式。

Georgios Zonnios was once an inquisitive teen user of SuperMemo. Today, he is an education innovator and a rich creative contributor to many of my ideas. He noticed:

Georgios Zonnios 曾经是一位好奇的青少年 SuperMemo 用户。如今，他是一位教育创新者，也是我许多想法的丰富创意贡献者。他注意到：

Stability in the formula for stability of complex items is like resistance in an electronic circuit: many parallel resistors allow of leaks in current.

在复杂项目的稳定性公式中，稳定性就像电子电路中的电阻：许多并联电阻会导致电流泄漏。

Incidentally, in the early days of incremental reading, Zonnios independently arrived at the concept of incremental writing, which today may seem like an obvious step in employing the tools of incremental reading in creativity. This article has also been written by means of incremental writing.

顺便说一句，在增量阅读的早期，Zonnios 独立提出了增量写作的概念，如今，将增量阅读工具应用于创造性工作似乎已经是一个显而易见的步骤。本文也是通过增量写作完成的。

This is how memories for complex items have been described and analyzed in 2005:

在2005年，对复杂项目的记忆是这样被分析和描述的：

Archive warning: Why use literal archives?

下面是引用文档

The difficulty in learning is determined by complexity of remembered information. Complex knowledge results in two effects:

-   increased interference with other pieces of information
-   difficulty in uniform stimulation of memory trace sub-components at review time

学习的难度取决于要记忆的信息的复杂性。复杂的知识会产生两个影响：

- 与其他信息片段的干扰增加
- 复习时均匀刺激记忆痕迹子成分的难度增加

Both components of difficulty can be counteracted with the application of appropriate representation of knowledge in the learning process.

通过在学习过程中应用适当的知识表达方法，可以抵消这两个难度成分。

Let us see how complexity of knowledge affects build up of memory stability.

让我们看看知识的复杂性如何影响记忆稳定性的建立。

Imagine we would like to learn the following: *Marie Sklodowska-Curie was a sole winner of the 1911 Nobel Prize for Chemistry.* We can take two approaches: one in which knowledge is kept complex, and one with easy formulations. In a complex variant, a double cloze might have been formulated for the purpose of learning the name of Marie Curie and the year in which she received the Nobel Prize.

假设我们想学习以下内容：“玛丽·斯克沃多夫斯卡-居里是 1911 年诺贝尔化学奖的唯一获奖者。”我们可以采取两种方法：一种是保持知识的复杂性，另一种是使用简单的表述。在复杂表述的方案中，可能会制定一个双重完形填空，以学习玛丽·居里的名字和她获得诺贝尔奖的年份。

> *Q: […] was a sole winner of the […] Nobel Prize for Chemistry*  
> *A: Marie Sklodowska-Curie, 1911*

> *问：[…]是[…]年诺贝尔化学奖的唯一获得者。*
> *答*：玛丽·斯克沃多夫斯卡-居里，1911*

In a simple variant, this double cloze would be split and the Polish maiden name would be made optional and used to create a third cloze:

在一个简单表述的方案中，这个双重完形填空将被拆分，居里夫人的娘家姓将被设为可选，并用于创建第三个完形填空：

（*译注：原文提到的 maiden name，剑桥词典的解释是 A woman's maiden name is the family family name she has before she gets married。即女子改随夫姓之前原本的姓氏*）

> *Q: […] was a sole winner of the 1911 Nobel Prize for Chemistry*  
> *A: Marie (Sklodowska-)Curie*
> 
> *Q: Marie Sklodowska-Curie was a sole winner of the […](year) Nobel Prize for Chemistry*  
> *A: 1911*
> 
> *Q: Marie […]-Curie was a sole winner of the 1911 Nobel Prize for Chemistry*  
> *A: Sklodowska*

> *问：[…]是1911年诺贝尔化学奖的唯一获得者*
> *答：玛丽·（斯克沃多夫斯卡-）居里*
> 
> *问：玛丽·斯克沃多夫斯卡-居里是[…]年诺贝尔化学奖的唯一获得者*
> *答：1911*
> 
> *问：玛丽·[…]-居里是1911年诺贝尔化学奖的唯一获得者*
> *答：斯克沃多夫斯卡*

In addition, in the simple variant, a thorough approach to learning would require formulating yet two cloze deletions, as Marie Curie was also a winner of 1903 Nobel Prize for Physics (as well as other awards):

此外，在简单表达的翻案中，彻底的学习方案还需要制定另外两个完形填空，因为玛丽·居里也是 1903 年诺贝尔物理学奖的获得者（以及其他奖项）：

> *Q: Marie Sklodowska-Curie was a sole winner of the 1911 Nobel Prize for […]*  
> *A: Chemistry*
> 
> *Q: Marie Sklodowska-Curie was a sole winner of the 1911 […]*  
> *A: Nobel Prize (for Chemistry)*

> *问：玛丽·斯克沃多夫斯卡-居里是 1911 年诺贝尔 […] 奖的唯一获得者* 
> *答：化学*
> 
> *问：玛丽·斯克沃多夫斯卡-居里是 1911 年 […] 奖的唯一获得者*
> *答：诺贝尔（化学）*

Let us now consider the original composite double cloze. For the sake of the argument, let’s assume that remembering the year 1911 and the name Curie is equally difficult. The retrievability of the composite memory trace (i.e. the entire double cloze) will be a product of the retrievability for its subtraces. This comes from the general rule that memory traces, in most cases, are largely independent. Although forgetting one trace may increase the probability of forgetting the other, in a vast majority of cases, as proved by experience, separate and different questions pertaining to the same subject can carry an entirely independent learning process, in which recall and forgetting are entirely unpredictable. Let us see how treating probabilities of recall as independent events affects the stability of a composite memory trace:

现在让我们审视最初的复合双重完形填空。为了便于讨论，我们假设记住 1911 年这个年份和记住居里这个名字同样困难。复合记忆痕迹（即整个双重完形填空）的可检索性将是其子痕迹可检索性的乘积。这源于一般规律，即在大多数情况下，记忆痕迹在很大程度上是独立的。尽管遗忘一条痕迹可能会增加遗忘另一条痕迹的概率，但在绝大多数情况下，经验证明，与同一主题相关的不同问题可以进行完全独立的学习过程，其中回忆和遗忘是完全不可预测的。让我们看看将回忆概率视为独立事件如何影响复合记忆痕迹的稳定性：

(9.1) R=R<sub>a</sub>×R<sub>b</sub>

where:

-   R – retrievability of a binary composite memory trace
-   R <sub>a</sub> and R <sub>b</sub> – retrievability of two independent memory trace subcomponents (subtraces): a and b

其中：

- R – 二元复合记忆痕迹的可检索性
- R<sub>a</sub> 和 R<sub>b</sub> – 两个独立记忆痕迹子成分（子痕迹）a 和 b 的可检索性

(9.2) R=exp<sup>-kt/Sa</sup>×exp<sup>-kt/Sb</sup>=exp<sup>-kt/S</sup>

where:

-   t – time
-   k – ln(10/9)
-   S – stability of the composite memory trace
-   S <sub>a</sub> and S <sub>b</sub> – stabilities of memory subtraces a and b

其中：

- t – 时间
- k – ln(10/9)
- S – 复合记忆痕迹的稳定性
- S<sub>a</sub> 和 S<sub>b</sub> – 记忆子痕迹 a 和 b 的稳定性

(9.3) -kt/S=-kt/S<sub>a</sub>-kt/S<sub>b</sub>=-kt(1/S<sub>a</sub>+1/S<sub>b</sub>)

(9.4) S=S<sub>a</sub>×S<sub>b</sub>/(S<sub>a</sub>+S<sub>b</sub>)

We used the Eqn. (9.4) in further analysis of composite memory traces. We expected, that if initially, stability of memory subtraces S<sub>a</sub> and S<sub>b</sub> differed substantially, subsequent repetitions, optimized for maximizing S (i.e. with the criterion R=0.9) might worsen the stability of subcomponents due to sub-optimal timing of review. We showed this not to be the case. Substabilities tend to converge in the learning process!

我们在对复合记忆痕迹的进一步分析中使用了公式 (9.4)。我们预期，如果最初记忆子痕迹 S<sub>a</sub> 和 S<sub>b</sub> 的稳定性差异很大，那么以最大化 S（稳定性）为目标而优化的后续复习（即，以 R=0.9 为标准）可能会由于复习时间不佳而恶化子成分的稳定性。我们证明了事实并非如此。子稳定性在学习过程中趋于收敛！

Stability of complex memories can be derived from substabilities of atomic memories.

复杂记忆的稳定性可以从原子记忆的子稳定性中推导出来。

#### 复合记忆痕迹的子稳定性的收敛（Convergence of sub-stabilities for composite memory traces）

It was easy to simulate the behavior of complex memories in spaced repetition. Their substabilities tend to converge. This leads to inefficient review and a slow buildup of stability. Today we can show that at a certain level of complexity, it is no longer possible to build memory stability for long-term retention. In short, there is no way to remember a book other than just re-reading it endlessly. This is a futile process.

模拟间隔重复中复杂记忆的行为很容易。它们的子稳定性趋于收敛。这会导致低效的复习和缓慢的稳定性建立。今天我们可以证明，到特定的复杂性水平后，建立能够长期维持的记忆稳定性将不再可能。简而言之，除了无休止地重读之外，没有其他方法可以记住一本书。这是一个徒劳的过程。

Archive warning: Why use literal archives?

下面是引用文档

If we generate a double-cloze, we are not really sure if a single repetition generates a uniform activation of both memory circuits responsible for storing the two distinct pieces of knowledge. Let us assume that the first repetition is the only differentiating factor for the two memory traces, and that the rest of the learning process proceeds along the formulas presented above.

如果我们生成一个双重完形填空，我们并不能真正确定一次复习是否会均匀激活负责存储两个不同知识片段的记忆回路。假设第一次复习是区别两个记忆痕迹的唯一因素，并且其余的学习过程按照上述公式进行。

To investigate the behavior of stability of memory subtraces under a rehearsal pattern optimized for composite stability with the criterion R=0.9, let us take the following:

为了研究在“以 R=0.9 为标准，为更高的复合稳定性进行优化”的复习模式下，记忆子痕迹稳定性的行为，我们采用以下方案：

-  S<sub>a</sub>=1
-  S<sub>b</sub>=30
-  S=S<sub>a</sub>×S<sub>b</sub>/(S<sub>a</sub>+S<sub>b</sub>) (from Eqn. 9.4)
-  *SInc*=*a*S<sup><em>-b</em></sup>×e<sup><em>c</em>R</sup>+*d* (from Eqn. SInc2005)
-  composite memory trace is consolidated through rehearsal with R=0.9 so that both subtraces are equally well re-consolidated (i.e. the review of the composite trace is to result in no neglect of subtraces)

-  S<sub>a</sub>=1
-  S<sub>b</sub>=30
-  S=S<sub>a</sub>×S<sub>b</sub>/(S<sub>a</sub>+S<sub>b</sub>)（来自 Eqn. 9.4（公式 9.4））
-  *SInc*=*a*S<sup><em>-b</em></sup>×e<sup><em>c</em>R</sup>+*d*（来自 Eqn. SInc2005）
- 复合记忆痕迹通过以 R=0.9 为目标的复习进行巩固，以便两个子痕迹都被同等良好地重新巩固（即，复合痕迹的复习不应导致对子痕迹的忽视）

As can be seen in the following figure, memory stability for the composite trace will always be less than the stability for individual subtraces; however, the stabilities of subtraces converge.

从下图可以看出，复合痕迹的记忆稳定性将始终低于单个子痕迹的稳定性；然而，子痕迹的稳定性会收敛。

![[SuperMemo_The true history of spaced repetition_附件/Stabil4-2.gif]]

> ***Figure:** Convergence of stability for memory sub-traces rehearsed with the same review pattern optimized for the entire composite memory trace (i.e. review occurs when the composite retrievability reaches 0.9). The horizontal axis represents the number of reviews, while the vertical axis shows the logarithm of stability. Blue and red lines correspond with the stability of two sub-traces which substantially differed in stability after the original learning. The black line corresponds with the composite stability (S=S<sub>a</sub>×S<sub>b</sub>/(S<sub>a</sub>+S<sub>b</sub>)). The disparity between S<sub>a</sub> and S<sub>b</sub> self-corrects if each review results in a uniform activation of the underlying synaptic structure.*
> 
> ***图：** 记忆子痕迹的稳定性收敛情况，两个子痕迹使用相同的复习模式进行复习，复习模式基于整个复合记忆痕迹进行优化（即，当复合可检索性达到 0.9 时进行复习）。横轴表示复习次数，纵轴表示稳定性的对数。蓝色和红色线对应于初次学习后稳定性有明显差异的两个子痕迹的稳定性。黑线对应于复合稳定性（S=S<sub>a</sub>×S<sub>b</sub>/(S<sub>a</sub>+S<sub>b</sub>)）。如果每次复习都导致底层突触结构的均匀激活，则 S<sub>a</sub> 和 S<sub>b</sub> 之间的差异会自我纠正。*

#### 复合稳定性增长（Composite stability increase）

Archive warning: Why use literal archives?

下面是引用文档

Let us now figure out how much *SInc* differs for composite stability S and for subtrace stabilities S <sub>a</sub> and S <sub>b</sub>? If we assume the identical stimulation of memory subtraces, and denote SInc <sub>a</sub> and SInc <sub>b</sub> as *i*, then for repetition number r, we have:

> SInc<sub>a</sub>=SInc<sub>b</sub>= *i*
> 
> S<sub>a</sub>[r]=S<sub>a</sub>[r-1]×*i*  
> S<sub>b</sub>[r]=S<sub>b</sub>[r-1]×*i*
> 
> S[r]=S<sub>a</sub>[r]×S<sub>b</sub>[r]/(S<sub>a</sub>[r]+S<sub>b</sub>[r])
> =S<sub>a</sub>[r-1]×S<sub>b</sub>[r-1]×*i*<sup>2</sup>/(S<sub>a</sub>[r-1]×*i*+S<sub>b</sub>[r-1]×*i*)
> = *i*×(S<sub>a</sub>[r-1]×S<sub>b</sub>[r-1])/(S<sub>a</sub>[r-1]+S<sub>b</sub>[r-1])=*i*×S[r-1]

现在让我们计算一下复合稳定性 S 和子痕迹稳定性 S<sub>a</sub> 和 S<sub>b</sub> 的 _SInc_ 有多大差异？如果我们假设记忆子痕迹的刺激相同，并将 SInc<sub>a</sub> 和 SInc<sub>b</sub> 表示为 _i_，那么对于复习次数 r，我们有：

> SInc<sub>a</sub>=SInc<sub>b</sub>= *i*
> 
> S<sub>a</sub>[r]=S<sub>a</sub>[r-1]×*i*  
> S<sub>b</sub>[r]=S<sub>b</sub>[r-1]×*i*
> 
> S[r]=S<sub>a</sub>[r]×S<sub>b</sub>[r]/(S<sub>a</sub>[r]+S<sub>b</sub>[r])
> =S<sub>a</sub>[r-1]×S<sub>b</sub>[r-1]×*i*<sup>2</sup>/(S<sub>a</sub>[r-1]×*i*+S<sub>b</sub>[r-1]×*i*)
> = *i*×(S<sub>a</sub>[r-1]×S<sub>b</sub>[r-1])/(S<sub>a</sub>[r-1]+S<sub>b</sub>[r-1])=*i*×S[r-1]

In other words:

> (11.1) SInc=*i*=SInc<sub>a</sub>=SInc<sub>b</sub>

换句话说：

> (11.1) SInc=*i*=SInc<sub>a</sub>=SInc<sub>b</sub>

The above demonstrates that with the presented model, the increase in memory stability is independent of the complexity of knowledge assuming equal re-consolidation of memory subtraces.

上述内容表明，在我们所提出的模型中，假设记忆子痕迹的重新巩固程度相同，则记忆稳定性的增长与知识的复杂性无关。

**Composite stability increase is the same as the increase in stability of sub-traces.**

**复合稳定性增长幅度与子痕迹的稳定性增长幅度相同。**

## 2014年：SM-17算法（2014: Algorithm SM-17）

The newest SuperMemo algorithm in its design can be used to summarize its own phylogeny. It can also be used to write the counterfactual history of spaced repetition. If there were no dinosaurs, humans might not have emerged or might look differently. However, the entire dino branch of the evolutionary tree could easily be chopped off, and still keep humans safe on their own mammalian branch.

最新的 SuperMemo 算法，在其设计中，能够总结其自身的演化历程。它也可以被用来撰写间隔重复的“反事实历史”。如果恐龙没有出现，人类可能也不会出现，或者会以不同的形态出现。然而，进化树中整个恐龙分支完全可以被移除，而人类仍然可以在其哺乳动物分支上安全存在。

In a similar fashion, we can show a seemingly deterministic chain of linked events in the emergence of spaced repetition and Algorithm SM-17. This can be used to prove that Biedalak or Murakowski were more important for history of spaced repetition than Ebbinghaus. Anki was more important than Pimsleur. Gary Wolf provided more impact than William James.

类似地，我们可以展示间隔重复和 SM-17 算法发展过程中一系列看似确定的、相互关联的事件。用它们用来证明，在间隔重复的历史中，Biedalak 或 Murakowski 比艾宾浩斯更重要，Anki 比皮姆斯勒更重要，Gary Wolf 的影响力超过了威廉·詹姆斯。

However, the maximum impact of spaced repetition is yet to be seen and confluence of forces may re-arrange those early influences. In particular, with an explosion in legitimate competition, the central role of SuperMemo can only be retained with further innovation (e.g. see neural creativity).

然而，间隔重复的最大影响力尚未显现，各种力量的汇聚可能会重新排列这些早期影响的顺序。特别是，随着合法竞争的爆发，SuperMemo 的中心地位只有通过进一步的创新（例如，参见神经创造力）才能保持。

Here is how I would explain the entire Algorithm SM-17 using the building blocks of history as written for this article:

-   the key to long-term retention is to compute optimum spacing (1985)
-   as spacing depends on memory complexity, we need to begin with classifying items into difficulty categories (1987)
-   we find the optimum review time by plotting the forgetting curve, which indicates a moment when retention drops below an acceptable level (1991)
-   to find optimum time in scarce data, we need to use approximations, and it helps to know that forgetting is exponential (1994)
-   as the speed of forgetting depends on memory stability, the whole algorithm must be designed with two component of memory at its core (1988). The lack of consideration for the model may be the chief mistake made by developers of competitive spaced repetition algorithms, e.g. as in the case of neural network approach (1997)
-   the key power of the two components model is to make it possible to compute the increase in memory stability at review (2005)
-   the algorithm must build the model of memory by collecting repetition data. It must be adaptable to the available information (1989)
-   before data is available, it is helpful to start with a universal memory formula (1990)
-   further minor adjustments and improvements can make a world of difference (1995), e.g. post-lapse interval, absolute difficulty, fast multi-dimensional regression, etc.

以下是基于本文所描述的历史进程，对整个 SM-17 算法的解释：

- 长期记忆的关键在于计算最佳间隔（1985年）。
- 由于间隔取决于记忆的复杂性，我们需要首先将项目分类为难度类别（1987年）。
- 通过绘制遗忘曲线，我们可以找到最佳复习时间，遗忘曲线指明了记忆保持率下降到可接受水平以下的时刻（1991年）。
- 为了在数据匮乏的情况下找到最佳时间，我们需要使用近似值，了解遗忘呈指数规律是有帮助的（1994年）。
- 由于遗忘的速度取决于记忆的稳定性，整个算法必须以记忆的两个组成部分为核心进行设计（1988年）。对该模型的忽视可能是竞争性间隔重复算法开发者犯的主要错误，例如，在神经网络方法中（1997年）。
- 两个组成部分模型的关键优势在于，它可以计算复习时记忆稳定性的增加（2005年）。
- 算法必须通过收集重复数据来构建记忆模型。它必须适应可用的信息（1989年）。
- 在数据可用之前，从一个通用的记忆公式开始是有帮助的（1990年）。
- 进一步的微小调整和改进可能会产生巨大的影响（1995年），例如，遗忘后间隔、绝对难度、快速多维回归等。

And so, step by step, Algorithm SM-17 has emerged at the top of the evolutionary tree in spaced repetition.

因此，SM-17 算法一步一步地在间隔重复的进化树顶端脱颖而出。

## 间隔重复的指数级传播（Exponential adoption of spaced repetition）

### SM-2算法的缓慢起步（Slow start of Algorithm SM-2）

Algorithm SM-2 was first used in learning on Dec 13, 1987 and with minor tweaks survived to this day in a number of applications. SuperMemo abandoned the algorithm in 1989, however, it keeps popping up in new applications with a frequency that must be approaching a few new developments each month. I lost count long ago. Some of the mutations contradict the principles of SuperMemo and still take on its label. Most often, the violations include intervals measured in minutes, or halving intervals at fail grade (Leitner style). Those mutations also lead to some fake news about SuperMemo. Note that fake news was one of the greatest incentives for writing this article.

SM-2 算法于1987年12月13日首次应用于学习，经过微小的调整，至今仍被许多应用程序采纳。SuperMemo 在1989年放弃了该算法，但它仍然以惊人的频率出现在新的应用程序中，估计现在每月都还有几个新的开发项目。我早就数不清了。其中一些变种与 SuperMemo 的原则相悖，却仍然打着它的旗号。最常见的违规行为包括以分钟为单位计算间隔，或在不及格时将间隔减半（Leitner 风格）。这些变种也导致了一些关于 SuperMemo 的虚假新闻。请注意，对虚假新闻的澄清是撰写本文的最大动机之一。

（*译注：关于原文所提到的“Leither style”，其出处是莱特纳记忆系统（Leitner System），也这是一种基于间隔重复的记忆方法，具体做法为将信息分成不同的卡片，将每张卡片安排到不同的盒子里，每个盒子都代表了一定的记忆难度和重复间隔。每次学习时，只需要从盒子一开始学习，随着记忆的巩固和加深，卡片逐渐地被移到下一个盒子里，直到最后一个盒子，被遗忘的卡片会被放回第一个盒子，和上面 Wozniak 教授自己的研究结论比起来，这个重复间隔显然缩短的过于激进了。*）

When Duolingo speaks in their paper of *hand-picked* parameters in reference to SuperMemo, it must be a result of relying on some older texts, perhaps second-hand texts, perhaps texts written in reference to Algorithm SM-2. After all, SuperMemo was pretty adaptable as of 1989 and Algorithm SM-17 is the most adaptable specimen in existence.

当 Duolingo 在其论文中提及 SuperMemo 的“手工挑选”参数时，一定是参考了一些较早的文本，甚至可能是二手文本，也可能是提及 SM-2 算法的文本。毕竟，SuperMemo 从1989年起就有了很强的适应性，而 SM-17 算法是现存最具适应性的样本。

Some of the blame for misinformation is mine as I stopped caring about peer review, and let the information wild on the web with insufficient mythbusting effort.

部分错误信息的责任在我，因为我停止关注同行评审，让信息在网络上肆意传播，而没有进行足够的辟谣工作。

The first applications to use Algorithm SM-2 were non-commercial offshoots of SuperMemo for Atari in the 1980s. Later, minor clones of SuperMemo (e.g. for handheld computers) opted for variants of Algorithm SM-2 with various own innovations, of which many provided painful lessons on the impact of disrespect of memory in the name of cramming.

最早使用 SM-2 算法的应用程序是那些20世纪80年代雅达利 SuperMemo 的非商业衍生品。后来，SuperMemo 的一些小型克隆版本（例如，用于掌上电脑的版本）选择了 SM-2 算法的变体，并加入了各种自己的创新，相当一部分最终在“只顾让人死记硬背，对记忆毫无尊重会有多坏的影响”上，提供了痛苦的教训。

By 2001, SuperMemo World moved ahead by five major generations of the algorithm. All major software lines, incl. on-line SuperMemo and SuperMemo for Windows adopted the data driven variants of the algorithm. *supermemo.net* became one of the pioneering e-learning platforms (today evolving into *supermemo.com* ). SuperMemo for Windows pioneered self-learning solutions such as incremental reading or neural creativity. In the meantime, Algorithm SM-2 became an easy first-choice option for other developers.

到2001年，SuperMemo World 在算法上又向前推进了五个大版本。所有主要的软件产品线，包括在线 SuperMemo 和 Windows上的 SuperMemo，都采用了数据驱动的算法变体。*supermemo.net* 成为了最早的在线学习平台之一（如今发展成了*supermemo.com*）。Windows 版 SuperMemo 率先推出了增量阅读和神经创造力等自学解决方案。与此同时，SM-2 算法也成为了其他开发人员首选的轻松方案。

### 1998年：发布与加速（1998: publishing and acceleration）

On May 10, 1998, Algorithm SM-2 was opened to the public and published on the web here.

1998年5月10日，SM-2算法被公开，并在此处发布于网络（*译注：“此处”指 SuperMemo 的在线网站，本文最初也是在上面发布，然后被译者拿来翻译*）。

Mnemosyne was first to pick the tool as the offshoot of neural network MemAid created in 2003. As of 2006, Mnemosyne keeps collecting repetition history data running a mutation of Algorithm SM-2. As a free multi-platform application, Mnemosyne quickly reached a large base of users, e.g. on Linux, or those users who have Latex requirements.

Mnemosyne 是第一个选择该工具的，它是2003年创建的神经网络 MemAid 的衍生产品。截至2006年，Mnemosyne 一直在运行着 SM-2 算法的一个变种，借此收集重复历史数据。作为一个免费的多平台应用程序，Mnemosyne 迅速获得了庞大的用户群，例如在 Linux 系统上，或者那些有 LaTeX 需求的用户。

Anki was born on Oct 6, 2006. It was based on Algorithm SM-2 and for nearly a decade provided the widest reach for the algorithm. It is still going strong. Anki introduced a great deal of innovations into their algorithm but refused to advance beyond its basic principles (see: criticism of SM3+).

Anki 诞生于2006年10月6日。它基于 SM-2 算法，并在近十年内为该算法提供了最广泛的传播。它至今仍然发展强劲。Anki 在其算法中引入了大量创新，但拒绝超越其基本原则（参见：对 SM3+ 的批评）。

In 2007, when we met Gary Wolf, SuperMemo looked like a sad deserted island that begged a question: if it is so good, why others don’t try to copy the algorithm. Anki and Mnemosyne were little known at that time. Wolf’s article in Wired in 2008 caused a nice rush for education software developers to implement a form of spaced repetition. Algorithm SM-2 seems like a low fruit to pick and its expansion accelerated. Many users of SuperMemo claim they would never find the program without Wolf’s article in Wired. Krzysztof Biedalak likes to joke though that Wolf’s article was indeed a breakthrough. However, not for SuperMemo. It simply opened the floodgates for the competition to rush in into the field of spaced repetition.

2007年，当我们遇到 Gary Wolf 时，SuperMemo看起来像一个凄凉的荒岛，不禁让人发问：如果它如此优秀，为什么其他人不尝试复制这个算法？当时的 Anki 和 Mnemosyne 名声不显。2008年，Wolf 在《连线》杂志上发表的文章引发了教育软件开发人员（在软件中）使用某种形式的间隔重复的热潮。SM-2 算法似乎是一个容易摘取的低垂果实，它的扩展速度也因此加快了。许多 SuperMemo 用户声称，如果没有 Wolf 在《连线》杂志上的文章，他们永远不会找到这个程序。Krzysztof Biedalak 喜欢开玩笑说，Wolf 的文章确实是一个突破。但不是对 SuperMemo 而言。它只是打开了闸门，让竞争对手涌入了间隔重复领域。

### 2008年：爆发（2008: explosion）

Quizlet was written in 2005 and released in 2007. It was initially a typical cramming tool, however, by 2015, backed by venture capital, Quizlet announced a higher emphasis on long-term retention, which resulted in adopting a variant of Algorithm SM-2. By 2017, they decided to use machine learning to deploy a new algorithm that would capitalize on billions of repetition records collected. The short stint for SuperMemo at Quizlet must have given a mutation of Algorithm SM-2 an exposure to the largest user base ever. At the time, Quizlet reported reaching every second high school student in the US.

Quizlet 于2005年被编写，并于2007年发布。最初，它是一个典型的填鸭式学习工具。然而，到2015年，在风险资本的支持下，Quizlet 宣布会更加重视长期记忆，这导致他们采用了 SM-2 算法的一个变种。到2017年，他们决定使用机器学习来部署一种新的算法，以利用他们收集的数十亿条重复记录。Quizlet 短暂使用了 SuperMemo，这使得 SM-2 算法的一个变种得以接触到有史以来最大的用户群。当时，Quizlet 报告称，他们覆盖了美国一半的高中生。

The new approach taken by Quizlet is based on a strong foundation, and can lead to a very strong tool, however, this is very disappointing to hear the motivation behind the move towards better algorithms: ” *Cramming is a reality for many students, and we want to help them make the best of their study time however they spend it*“. Algorithm SM-17 provides for more freedom to students: (1) to advance learning when in need, or (2) to delay low priority material. However, we always discourage cramming as a bad practice. It is schools that need to adapt to human brain, not the other way around. This stubborn stance on learning efficiency hurts SuperMemo, but it will never change.

Quizlet 的新方法建立在坚实的基础上，可能会产生非常强大的工具。然而，他们转向更好算法的动机令人非常失望：“*填鸭式学习是许多学生（不得不面对）的现实，我们希望帮助他们充分利用学习时间，无论他们如何使用这些时间*”。SM-17 算法为学生提供了更大的自由度：（1）在需要时推进学习，或（2）延迟低优先级材料。然而，我们始终不鼓励填鸭式学习这种不良做法。应该由学校来适应人脑，而不是人脑去适应学校。这种对学习效率的顽固立场让 SuperMemo 承受了损失，但它永远不会改变。

That move away from a simple review schedule by Quizlet in 2017 is probably the move past the peak of popularity for the old venerable algorithm. New competitors will need to go for intelligent tools, or perhaps for licensing Algorithm SM-17. The news is good.

Quizlet 在2017年放弃了简单复习计划，这可能标志着这款古老而受人尊敬的算法的流行度将从顶峰开始滑落。新的竞争者将需要转向智能工具，或者请求 SM-17 算法的授权。这是个好消息。

### 有多少人使用间隔重复？（How many people use spaced repetition?）

In mid-1991, one of my classmates tried to cheer me up. He predicted we will be successful and we will manage to sell 10-20 copies of SuperMemo. I was more optimistic. In 1993, I predicted 1 million users by 1996. In 1994, Enter, Poland, mentioned similar optimism of Marczello Georgiew:

> In questionnaires received at SuperMemo World, when asked what they like most in the program, users of SuperMemo overwhelmingly indicate its effectiveness. The software may be OK, but what really counts is results in learning. How about dislikes? Users are not pleased with this or that, most often with the fact that, even in Poland, SuperMemo is always released first in English. But there is no particular turn-off that takes precedence. Definitely, nobody questions the fact that with SuperMemo one can learn faster and never to worry about forgetting. Taking this rosy picture into heart, one might wonder why has SuperMemo not yet sold in millions of copies worldwide. Marczello Georgiew, Marketing Director at SuperMemo World proposed to recall the problems Graham Bell experienced when trying to introduce his funny machine for talking over a wire or how pessimistic the predictions of industry futurologists were about the expansion of the air-polluting mechanical horse. Then he adds confidently: ***It took Wozniak 10 years to turn necessity into invention, give us half this time, and we will turn his invention into a global necessity**.*

1991年中期，我的一位同学试图让我振作起来。他预言我们会成功，并能卖出10-20份 SuperMemo。我则更为乐观。1993年，我预计到1996年我们将有100万用户。1994年，波兰的《Enter》杂志提到了 Marczello Georgiew 也有类似的乐观态度：

> 在 SuperMemo World 收到的问卷调查中，当被问及他们最喜欢该程序的哪方面时，SuperMemo 的用户绝大多数都表示是它的有效性。软件本身只是还可以，但真正重要的是学习效果。不喜欢什么呢？用户有各种各样的不满意，最常见的是，即使在波兰，SuperMemo 也总是先发布英文版。但没有特别令人反感的问题占据主导地位。毫无疑问，没有人质疑使用 SuperMemo 可以学得更快，并且永远不用担心遗忘。憧憬着这幅美好的景象，人们可能会想，为什么 SuperMemo 在全球的销量还没有达到数百万份。SuperMemo World 的营销总监 Marczello Georgiew 建议我们回顾一下格雷厄姆·贝尔在推广他的有线通话“搞笑机器”时遇到的问题，或者行业预言者们对机械马的普及将带来的空气污染问题做出的悲观预测。然后他自信地补充道：****沃兹尼亚克花了10年时间将需求转化为发明，给我们一半的时间，我们将把他的发明转化为全球必需品***。

In my 1 million users prediction, I was off by 3 years, and had to make a distinction between short-timers and active users. The proportion of active users of spaced repetition kept dropping with wider adoption. In 2007, we estimated the reach of SuperMemo to be 5 million, of which most were freeware and partwork users. Of those 5 million, only 0.4-4.0% were active users. This might have been as few as 20,000 students.

我预测的100万用户，比我预计的晚来了3年，并且这还是短期用户和活跃用户的总和。随着间隔重复的普及，活跃用户的比例不断下降。2007年，我们估计 SuperMemo 的覆盖范围为500万，其中大部分是免费软件和分期付款用户。在这500万用户中，只有0.4-4.0%是活跃用户。其中可能只有2万名是学生。

In 2009, Gwern Branwen estimated the population of active users to be around 100,000, which seems to agree with my numbers. This does not sound too optimistic for two decades of hard work at SuperMemo World.

2009年，Gwern Branwen 估计活跃用户约为10万人，这似乎与我的数据相符。但对于 SuperMemo World 二十年的辛勤工作来说，这听起来并不太乐观。

Let’s then have a closer look at the reach of spaced repetition today. My estimates below met with a great deal of skepticism. I agree that they are based on a great deal of guesswork. However, once you are on an exponential curve of growth, even large estimate errors make little difference. You can overestimate by 200% and still catch up quickly in no time.

那么，让我们仔细看看今天间隔重复的普及程度。我下面的估计遇到了很多怀疑。我承认，这些估计很大程度上是基于猜测。然而，一旦你处于指数增长曲线上，即使是很大的估计误差也几乎没有影响。你可以高估200%，但（现实）仍然能够在短时间内迅速赶上。

This is why I do not hesitate to say that the exponential growth in the adoption of spaced repetition streaks towards the big B: one billion users. Amazon’s Kindle has added spaced repetition to its Flashcard option in Vocabulary Builder. Even users of SuperMemo who use Kindle may know nothing of the fact. Flashcards with books is the general idea that was to bring SuperMemo to NASDAQ back in 1996 if we succeeded in persuading venture capital that the idea made sense.

这就是为什么我毫不犹豫地说，间隔重复普及的指数增长正朝着一个巨大的“B”前进：十亿用户。亚马逊的 Kindle 在其“词汇构建器”的“抽认卡”选项中添加了间隔重复功能。但即使是使用 Kindle 的 SuperMemo 用户也可能对此毫无察觉。将抽认卡与书籍结合起来的想法，本来可以在1996年将 SuperMemo 带到纳斯达克，只要我们成功地说服风险投资家这个想法是可行的。

However, to hit a billion users we need another breakthrough. The first obvious candidate that comes to mind is Facebook, which might wire spaced repetition into the cacophony of social interaction, and make free learning transparent, i.e. where users learn without ever showing intent.

然而，要达到十亿用户，我们需要另一个突破。最容易想到的方案是与 Facebook 结合，它可以将间隔重复融入社交互动的嘈杂环境中，并使免费学习变得透明，即让用户在没有明确意图的情况下也能进行学习。

If you think Facebook and spaced repetition are incompatible worlds, consider the world of advertising. These days we all hate advertising. No matter how well it is targeted. However, the pestering party can maximize the memory effect and minimize the annoyance (i.e. retrievability) by employing spaced repetition. Even the most captivating TV advert will get on your nerves by the third exposure. Spaced review could ensure that retrievability is low and retention high.

如果你认为 Facebook 和间隔重复是两个不相容的领域，那么请想想广告。如今，我们都讨厌广告。无论它的目标定位多么精准。然而，通过采用间隔重复，扰人的一方可以最大限度地提高记忆效果，并最大限度地减少（受众的）烦扰（即，可检索性）。即使是最引人入胜的电视广告，在第三次播放时也会让你感到厌烦。间隔重复可以保持可检索性较低，而记忆保持率较高。

Last but not least, spaced review may be taken on by the bad guys. The makers of fake news and worse. A publicity charlatan might pull strings behind the back of a world leader. He may shake the world in spaces. This may expose the whole world to spaced repetition to be sure we all remember.

不得不提的是，间隔重复同样可能会被坏人利用。像是假新闻的制造者，甚至更糟的人。一个公关骗子可能会在世界领导人的幕后操纵。他可能会遵循间隔发布震撼信息。进而让全世界都暴露在间隔重复中，以确保我们都记住（他想让我们记住的信息）。

The top of the pyramid is so bad that I will not even list it. I don’t want to give bad guys any ideas.

金字塔的顶端是如此糟糕，我甚至不会列出来。我不想给坏人任何灵感。

My estimates below include a couple of points that are pretty certain. The first user in 1985, second in 1987, one million by 2000, and my laborious estimate of 5 million in 2007. Today, Duolingo claims 200,000 users. Quizlet claims even more. The growth is still showing few sign of saturation.

我下面的估计包括几个非常确定的点。1985年的第一个用户，1987年的第二个用户，2000年的100万用户，以及我费力估计的2007年的500万用户。今天，Duolingo 声称有20万用户。Quizlet 声称的则还要更多。但增长仍然没有显示出饱和的迹象。

![[SuperMemo_The true history of spaced repetition_附件/800px-Adoption_of_spaced_repetition_1985-2018.png]]

> ***Figure:** We expected spaced repetition to show signs of saturation long ago. However, through transmutation, it will inevitably hit a billion users at some point. Once it becomes integrated with human digital life, it will affect nearly everyone. If my estimate is right, the speed of adoption, aided by the web, is still ahead of the telephone, car, and the radio. We never thought it was possible to compete with Pokemons or Angry Birds though. The exponential regression formula in the graph is: Reach=exp((year-1984)*0.63). The red line determined by that formula crosses 1 billion just about now*
> 
> ***图示：** 我们早就预料到间隔重复会显示出饱和的迹象。然而，通过转变，它将不可避免地在某个时候达到十亿用户。一旦它与人类的数字生活融合，它将影响几乎所有人。如果我的估计是正确的，虽说是在网络的帮助下，但它的普及速度超过了电话、汽车和收音机。不过我们还是没指望他能比得上宝可梦或者愤怒的小鸟。图中的指数回归公式为：普及量=exp((年份-1984)×0.63)。由该公式确定的红线现在正好穿过10亿。*

Today, with almost no barrier of entry, there are many students who try and drop out after weeks or even days of use. The proportion of active users may be very low. A billion users with negligible learning is still little learning. The next step in the job is to produce a cultural paradigm shift that will add value to efficient long-term learning. We need to begin with a change to the system of schooling and to adopt the principles of free learning.

如今，由于几乎没有准入门槛，许多学生在使用数周甚至数天后就尝试放弃。活跃用户的比例可能非常低。即使有十亿用户，但多数人的学习效果微不足道，最后仍然是很少的学习。下一步的工作是产生一种文化范式转变，为高效的长期学习增加价值认同。我们需要从改变学校教育体系，并采用自由学习的原则开始。

Once spaced repetition hits a billion users, cultural paradigm shift will be necessary to convert usership to actual benefits in long-term quality learning

一旦间隔重复的用户达到十亿，就必须进行文化范式转变，才能将用户数量转化为长期高质量学习的实际效益。

The road ahead is still very long.

前路漫漫，道阻且长。

## 记忆研究史摘要（Summary of memory research）

### 间隔重复研究中的问题（Problem with spaced repetition research）

History of research on spaced repetition has been plagued by the following factors:

-   guesses and heuristics used in place of mathematical optimization
-   poor interaction between theory and practice with science focused on simple experiments and practice focused on simple tools
-   terminological inconsistency that leads to cycles of forgetting and re-discovery!

间隔重复研究的历史受到以下因素的困扰：

- 使用猜测和启发式方法代替数学优化。
- 理论与实践之间缺乏良好的互动，科学侧重于简单的实验，而实践侧重于简单的工具。
- 术语上的不一致导致了成果被反复遗忘和重新发现！

The above agrees with my ranking of *factors of failure* . Until the arrival of personal computing and the web, it was hard to escape the vicious cycle.

以上内容与我对“*失败因素*”的排名一致。在个人电脑和互联网出现之前，很难摆脱这个恶性循环。

### 间隔重复的直觉（Spaced repetition intuitions）

When we asked teenagers a set of questions about how their memory works, a large proportion could come with pretty good guesses about repetition spacing without ever making any measurements. In particular, they often correctly guess that the first optimum inter-repetition interval might be 1-7 days long and that successive intervals will increase. Moreover, many could guess that the second interval might be a month long and that successive intervals might double. In other words, **spaced repetition is a common intuition**.

当我们询问青少年关于他们记忆是如何运作的一系列问题时，很大一部分人即使从未进行过任何测量，也能对重复间隔的设置给出相当好的猜测。特别是，他们通常能够正确地猜到，第一次最佳的重复间隔可能在 1-7 天左右，并且后续的间隔会逐渐增加。此外，许多人还能猜到第二次间隔可能是一个月，而后续的间隔可能会翻倍。换句话说，**间隔重复是一种常见的直觉**。

### 早期的记忆研究（Early memory research）

In 1885, Hermann Ebbinghaus made a major contribution to the science of memory. He experimented on himself and came up with the first outline of the forgetting curve. He was also aware of the spacing effect. He never worked on spaced repetition. I do not credit Hermann for an inspiration in my work over spaced repetition as I simply had no idea who Hermann was and what he accomplished. I designed my own measurement that led to spaced repetition. In an unrelated and forgotten exercise, I also produced my own forgetting curve that might have influenced my thinking. Hermann’s curve was much steeper and might have actually discouraged further work (see: Error of Ebbinghaus forgetting curve). Our Adam Mickiewicz University library was well stocked up with “ancient” pre-WW2 German literature, however, I knew no German. Mine was an ignorant solo effort. I read about Ebbinghaus later, and mentioned his forgetting curve in my Master’s Thesis.

1885年，赫尔曼·艾宾浩斯（Hermann Ebbinghaus）对记忆科学做出了重大贡献。他以自己为实验对象，首次勾勒出了遗忘曲线的轮廓。他也意识到了间隔效应，但他从未研究过间隔重复。我并不认为赫尔曼对我的间隔重复研究有任何启发，因为我当时根本不知道赫尔曼是谁以及他取得了什么成就。我设计了自己的测量方法，从而导出了间隔重复。在一个不相关且被遗忘的（早年）练习中，我也得出了自己的遗忘曲线，这可能影响了我的思考。赫尔曼的曲线陡峭得多，甚至可能阻碍了进一步的研究（参见：艾宾浩斯遗忘曲线的错误）。我们亚当·密茨凯维奇大学的图书馆里收藏了大量“古老”的二战前德国文献，然而，我一点德语都不懂。我的研究完全是无知且自力更生的努力。后来，我才读到关于艾宾浩斯的内容，并在我的硕士论文中提到了他的遗忘曲线。

By 1901, in writings of William James, the superiority of spaced review seemed clear and it seemed like a matter of time before it permeates the learning theory with optimization of spacing taken as the next obvious step. It was not to be. For another 8 decades.

到了1901年，在威廉·詹姆斯（William James）的著作中，间隔复习的优越性似乎已经很明显，并且它渗透到学习理论中似乎只是时间问题，对间隔的优化是显而易见下一步骤。然而，这并没有实现。80年就这样白白过去。

In his popular book of 1932, C.A. Mace has suggested a simple spaced repetition schedule: 1 day, 2 days, 4 days, 8 days, etc. Good guess! Mace’s effort was forgotten though because spaced repetition “on paper” before the era of the Internet must have hardly been appealing. For a good start, Mace would have to shine with a good example. I bet that was not easy. Herr Hitler dominated the news at that time.

1932年，C.A. 梅斯在他广受欢迎的著作中，提出了一种简单的间隔重复计划：1 天、2 天、4 天、8 天，以此类推。这是一个很好的猜测！然而，梅斯的努力却被遗忘了，因为在互联网时代之前，“纸上”的间隔重复肯定没有什么吸引力。为了取得好的开端，梅斯需要用一个好的案例来证明。我敢肯定那并不容易。当时，希特勒的新闻占据了主导地位。

### 1960年代：文艺复兴（1960s: The Renaissance）

In 1966, Herbert Simon had a peek at Jost’s Law derived around 1897 from Ebbinghaus’s work. Simon noticed that exponential nature of forgetting necessitates the existence of a memory property that today we call memory stability. Simon wrote a short paper and moved on to hundreds of other projects he was busy with. His text was largely forgotten.

1966年，赫伯特·西蒙（Herbert Simon）略微关注了乔斯特定律，该定律大约于1897年根据艾宾浩斯的研究推导而来。西蒙注意到遗忘的指数性质必然指向一种记忆特性的存在，我们今天称之为记忆稳定性。但西蒙写了一篇短文后，就投入到他正在进行的数百个其他项目中去了。他的文章很大程度上被遗忘了。

At roughly the same time, Robert Bjork had a great deal of innovative ideas in reference to learning and memory. As it often happens, he was ahead of his time. Teachers hardly ever listen to psychologists. Students do not even know their names. If Bjork was a programmer, we might have had the first popular application of spaced repetition a decade earlier. I think he would just not let a great idea off the hook. It was Bjork who seems to have been first to clearly separate retrieval strength and storage strength in a model analogous to our two component model of memory.

大约在同一时期，罗伯特·比约克（Robert Bjork）在学习和记忆方面有很多创新性的想法。正如经常发生的那样，他走在了时代的前面。老师们几乎从不听心理学家的话。学生们甚至不知道他们的名字。如果比约克是一名程序员，我们可能早在十年前就有了第一个流行的间隔重复应用程序。我认为他不会轻易放弃一个伟大的想法。似乎是比约克最早在一个与我们的记忆二元模型类似的模型中，清晰地区分了提取强度和存储强度。

In 1967, Paul Pimsleur could clearly see that spaced repetition could be a great tool for learning word-pairs in language learning. Like SuperMemo, he struggled with terminology and used the term “graduated-interval recall”. In our “serrated forgetting curve” challenge, Pimsleur came closest with the earliest known serrated curves graph as in the picture:

1967年，保罗·皮姆斯勒（Paul Pimsleur）清楚地认识到，间隔重复可以应用在语言学习中，成为学习词对的伟大工具。像 SuperMemo 一样，他也经历术语上的挣扎，并使用了“分级间隔回忆”这个术语。在我们的“锯齿状遗忘曲线”挑战中，皮姆斯勒最接近地提出了最早的已知锯齿状曲线图，如下图所示：

![[SuperMemo_The true history of spaced repetition_附件/Pimsleur_serrated_curves-1.jpg]]

Perhaps we will discover earlier sketches of the idea, however, for technical reasons, the older the print, the less rich it is in graphs, which we today generate en masse in Excel.

也许我们会发现更早的关于这个想法的草图，然而，由于技术原因，印刷品越古老，其包含图表就越少，但今天我们已经可以用 Excel 大量生成这些图表。

Pimsleur’s intervals extended into periods of hours, minutes and even seconds. It was a reflection of an intuition, not measurement. He extended his reasoning from declarative knowledge that can easily be measured (e.g. word pairs) to procedural knowledge and audio-pattern recognition, as in learning pronunciation.

皮姆斯勒的间隔研究深入到小时、分钟甚至秒。这反映的是一种直觉，而不是测量。他将他的推理从容易测量的陈述性知识（例如词对）扩展到程序性知识和音频识别，例如学习发音的过程。

SuperMemo solves this problem by separating word-pair learning from pronunciation, spelling, recognition, synonyms, and the like. As a result, e.g. in Advanced English, we never need to reduce intervals beyond user’s standard startup stability, which rarely drops down below a day.

SuperMemo 通过将词对学习与发音、拼写、识别、同义词等分开来解决这个问题。就结果来看，例如，在高级英语中，我们从未需要将间隔缩短到用户的“标准初始稳定性”以下，而这种稳定性很少低于一天。

For practical reason and due to the role of sleep, SuperMemo never uses intervals shorter than 1 day. Sleep is also the main reason why the algorithm uses 1-day resolution in the length of intervals. SuperMemo makes it possible to review multiple times in a day, but this is part of a subset review that, on occasion, may appear useful (e.g. when cramming for an exam). 

出于实际原因以及睡眠的作用，SuperMemo 从不使用短于一天的间隔。睡眠也是算法在间隔长度上使用一天作为最小单位的主要原因。SuperMemo 允许一天内多次复习，但这属于一次子复习，只是偶尔可能有用（例如，在考试前突击复习时）。

Pimsleur’s interval recommendations were different than those of Mace or SuperMemo on paper ( Algorithm SM-0). They were not a result of a measurement, but a result of a speculation, which ranged from solid to poor. Pimsleur thought of ensuring recall of 60%, which is very low by SuperMemo standards. He bet on startup stability of 5 seconds, while SuperMemo uses 1-15 days, which is just fine for 90% recall of well-formulated knowledge.

皮姆斯勒的间隔设置建议，与梅斯或纸面版 SuperMemo（算法 SM-0）的建议不同。它们不是测量的结果，而是推测的结果，其质量稂莠不齐。皮姆斯勒认为要确保60%的回忆成功率，这在 SuperMemo 的标准看来非常低。他盲猜（作为初次复习间隔的）记忆的初始稳定性是5秒左右，而 SuperMemo 选择1-15天，在知识被良好组织的前提下，这已经足够达到90%的回忆成功率了。

Pimsleur’s base of interval exponentiation ( E-Factor) was 5, which should be 1.4-2.5 in most cases. As a result, Pimsleur’s spacing differs dramatically from SuperMemo’s, and should not be used as a benchmark in algorithmic metric. In his original paper (1967), Pimsleur proposed intervals of 5 sec., 25 sec., 2 min., 10 min., 1 hour, 5 hours, 1 day, 5 days, 25 days, 4 months, and 2 years. The differences came mostly from the practise based on materials of different character (equivalent to high complexity in SuperMemo). The use of seconds, minutes and hours is tantamount to cramming and is strongly discouraged in SuperMemo. Instead, optimization of knowledge representation is advised.

皮姆斯勒的间隔指数（E-Factor）基数为 5，而这个值在大多数情况下应该在1.4-2.5之间。总的来讲，皮姆斯勒关于间隔的结论与 SuperMemo 差异很大，不应作为衡量算法的基准。在他最初的论文（1967年）中，皮姆斯勒提出了5秒、25秒、2分钟、10分钟、1小时、5小时、1天、5天、25天、4个月和2年的间隔。这些差异主要源于基于不同性质（学习）材料（相当于 SuperMemo 中的高复杂度学习材料）的实践。使用秒、分钟和小时等间隔等同于突击学习，在 SuperMemo 中是强烈不鼓励的。相反，优化知识表达方案才是我们推荐的做法。

In 1969, Alfred Maksymowicz wrote “Read and think”. You will not find his book in your library. It was written in Polish and for a narrow circle of students of technical universities. It mentioned spaced repetition, forgetting curves, and even how the forgetting index might determine the optimum interval. Maksymowicz proposed the first optimum interval to be 3 days. As many efforts before and after, this good advice remained largely ignored. Students rush to pass an exam and then forget. Cram and dump is a principle by which the pressure of schooling destroys the prospects of good long-term learning.

1969年，阿尔弗雷德·马克西莫维奇（Alfred Maksymowicz）写了一本名为《阅读与思考》的书。在您的图书馆里可能找不到这本书，因为它最初是用波兰语写成的，主要面向一小部分技术大学的学生。书中提到了间隔重复、遗忘曲线，甚至讨论了遗忘指数如何决定最佳复习间隔。马克西莫维奇建议的第一个最佳复习间隔是3天。然而，就像许多在他前后被提出的建议一样，这个有益的建议很大程度上被忽视了。学生们急于通过考试，考过后就忘记了知识。这种“突击学习后遗忘”的模式，正是学校教育压力扼杀良好长期学习前景的原因所在。

I know of Maksymowicz’s book only because I studied at a technical university in Poland, and I was pretty loud of my own spaced repetition method. I can only imagine that there have been dozens other similar texts where intuitions were formulated as a good advice that then remained ignored by the masses. Without the coincidence of time and space, future texts on spaced repetition might never notice Maksymowicz ever existed.

我之所以知道马克西莫维奇的书，是因为我曾在波兰的一所技术大学学习，并且对自己的间隔重复方法颇为高调。我只能想象，可能还有数十本类似的书籍，其中一些直觉性的想法被提炼成有益的建议，但最终却被大众所忽视。如果没有时间和空间的巧合，未来关于间隔重复的著作可能永远不会注意到马克西莫维奇的存在。

Maksymowicz might have been inspired by Pimsleur, Mace, his own intuition, or other potential texts of which I have no knowledge. Maksymowicz gives credence to the words of Szafraniec, skeptical of SuperMemo: “all has occurred before”.

马克西莫维奇的灵感可能来自于皮姆斯勒（Pimsleur）、梅斯（Mace）、他自己的直觉，或其他我不知道的潜在文献。马克西莫维奇认同一位 SuperMemo 的质疑者——斯扎弗拉涅茨（Szafraniec）的观点：“一切都曾发生过”。（*译注：个人感觉这里侧重指“所有好点子都已经被想到过了”*）

### 1972年：莱特纳（卡片）盒（1972: Leitner box）

The greatest practical and algorithmic success in the area of spaced review before SuperMemo can be attributed to Sebastian Leitner. In 1972, he proposed the **Leitner box system** . In a Leitner system, flashcards are prioritized and dumped to boxes corresponding with different stability levels. The Leitner system has one huge advantage over the theoretical advice dished prior to his proposition: it was practical. It was a system anyone could use with little introduction. Even SuperMemo on paper (1985) seems complex in comparison.

SuperMemo 出现之前，在间隔复习领域，在实践和算法两方面取得最大成功的，可能当属塞巴斯蒂安·莱特纳（Sebastian Leitner）。1972年，他提出了**莱特纳卡片盒系统**（**Leitner box system**）。在莱特纳系统中，助记卡（flashcard）会根据不同的记忆稳定性水平被依序处理并重新分类。莱特纳系统相比他之前提出的理论性建议，有一个巨大的优势：它非常实用。这是一个任何人都可以轻松使用，几乎不需要任何介绍的系统。即使是1985年以纸质形式出现的 SuperMemo，与之相比也显得复杂。

![[SuperMemo_The true history of spaced repetition_附件/Leitner_system.png]]

> ***Figure:** An incorrect mutation of the Leitner system where failed answers are moved back by one box only (source: Wikipedia). This variant was in use in Duolingo for a while*
> 
> ***图：** 莱特纳系统的一种不正确的变体，其中回答错误的卡片只退回一个卡片盒（来源：维基百科）。这种变体曾在 Duolingo 上使用过一段时间。*

**The Leitner box is not a spaced repetition tool**. It is a prioritization tool. There is no concept of an interval, let alone optimum interval. The name *box* comes from the original *implementation* in the form of physical flashcard boxes with not association to passing time. When the Leitner box is used regularly on a small-sized collection of flashcards, it simulates the behavior of spaced repetition. If intervals are too short, it leads to cramming. If they get too long, it leads to sub-optimum outcomes. However, in SuperMemo, low priority material may also be postponed cyclically and yield very long intervals which reduce expected stability increase, but carry a larger stability increase for items that survive longer intervals. 

**莱特纳卡片盒并非一个间隔重复工具**。它是一个优先级排序工具。其中并没有间隔的概念，更不用说最佳间隔了。名称中的“盒”（box）源于系统最初以助记卡盒形式的实现，与时间的流逝无关。莱特纳盒被用来定期处理少量助记卡时，它会模拟间隔重复的行为。如果复习间隔过短，则会导致填鸭学习。如果间隔过长，则达不到最优的学习效果。然而，在 SuperMemo 中，低优先级的材料也可能被周期性地推迟复习，从而产生非常长的间隔，这会降低记忆稳定性提升的预期值，但对于能够撑过更长间隔的项目，则会带来更大的稳定性提升。

In the 1990s and early in the new millennium, the Leitner system was used in many successful flashcard applications. As they kept tinkering and improving the review procedures, these apps might have actually evolved into a full-blown spaced repetition system. Their application declined though due to the popularity of SuperMemo’s Algorithm SM-2 that turned out to be easy to implement and vastly superior.

在20世纪90年代和新千年初期，莱特纳系统被广泛应用于许多成功的助记卡应用中。随着这些应用不断改进复习流程，它们可能实际上已经演变成了成熟的间隔重复系统。然而，由于 SuperMemo 的 SM-2 算法易于实现且性能远超前者，这些应用的使用逐渐减少。

Newer software mutations of the Leitner box system may attach intervals to priority boxes, e.g. 16 days for Box #5, but this approach has flaws tantamount to cramming: (1) failure still leads to the regression of intervals, while it should lead to resumed learning, (2) five repetitions in the first month does not compare well to well-formulated knowledge that may reduce the cost of learning in SuperMemo in the first month alone by 60-80%, and (3) more boxes would be needed. We have seen intervals well beyond maximum human lifespan in SuperMemo. The needs for lifetime applications are 200 thousand percent higher. This is the difference between a *permastore* interval and 16 days. 11 extra boxes would be needed to cover the lifetime at E-factor of 2.

莱特纳卡片盒系统较新的软件变体可能会为卡片盒按优先级设定间隔，例如，给5号卡片盒设定16天的间隔，但这种方法存在和填鸭式学习类似的缺陷：(1) 即使答错，也只是将间隔缩短，而正确的做法应该是重新开始学习；(2) 第一个月内就需要进行五次复习，与经过精心设计的知识体系相比，效果相差甚远，后者在 SuperMemo 中仅第一个月就可能将学习成本降低60-80%；(3) 需要更多的卡片盒。我们在 SuperMemo 中见过远超人类寿命的复习间隔。对于需要终生使用的知识，其（稳定性）需求（比莱特纳盒能提供的（16天））要高出20万倍。这就是“永久存储”间隔和16天之间的区别。如果假设 E 因子为2，则需要额外增加11个卡片盒才能覆盖终生的学习需求。

Today, one of the most popular systems for learning languages is Duolingo. For a long while, it used the Leitner system. Today they employ their own new algorithm based on retrievability predictions. However, they still used the Leitner system as a benchmark. To make matters worse, their benchmark used the reverse transfer of flashcard in priority boxes (where the post-lapse stability is overestimated). Normalized Leitner might be used as a benchmark, however, simple normalization equivalent to using E-factor of 2, may produce different results than the choice of E-factor 1.6.

如今，最受欢迎的语言学习系统之一是 Duolingo。很长一段时间以来，它都使用了莱特纳系统。如今，他们采用了基于可检索性预测的全新算法。然而，他们仍然将莱特纳系统用作基准。更糟糕的是，他们在基准中使用了卡片盒中助记卡的逆向转移（在这种情况下，遗忘后的记忆稳定性被高估了）。归一化的莱特纳系统或许可以作为基准，然而，简单的归一化（相当于使用E因子为2）可能产生与选择E因子1.6不同的结果。

（*译注：“卡片盒中助记卡的逆向转移”，指的是复习时发现助记卡上的内容已经被遗忘后，将助记卡放入上一级的卡片盒（例如，从每16天复习一次的卡片盒到每8天复习一次的卡片盒），Wozniak 教授已经通过前文说明了，根据他的研究成果，正确的做法应该是从头开始重新记忆（重新学习后，从当前的卡片盒放回（已经学了但）还没复习过的卡片盒）*）

In the future, all algorithms should switch to a universal metric proposed by SuperMemo, and Algorithm SM-2 might become a useful metric benchmark that can be implemented in parallel with proprietary solutions. I hope users will demand clarity, statistics, metrics, and full openness in that respect.

未来，所有算法都应该转向 SuperMemo 提出的通用指标，而 SM-2 算法可能成为一个有用的公共标准，可以与专有解决方案并行实现。在这方面，我希望用户不要放松对结果清晰度、统计数据、衡量标准以及完全的开放性的要求。

In the 1970s, Tony Buzan would focus on structured knowledge with his mind-mapping innovations. Mind maps and SuperMemo would, paradoxically, stand in conflict due to a lack of a good unifying theory. In short, we need good models to understand the world, and we need the spaced review to retain the components of the model in the long term. Buzan also had his own ideas how the review should be spaced. When he first met SuperMemo in the early 1990s, he instantly agreed with the concept, however, he always preferred to focus on knowledge structure rather than a mere review.

在20世纪70年代，托尼·布赞（Tony Buzan）专注于通过他的思维导图创新来构建结构化的知识。然而，由于缺乏一个良好的统一理论，思维导图和 SuperMemo 却形成了一种矛盾的对立。简而言之，我们需要好的模型来理解世界，并且我们也需要间隔复习来长期记忆模型中的各个组成部分。布赞也有他自己关于应该如何安排复习间隔的想法。当他在20世纪90年代初首次接触 SuperMemo 时，他立刻认同了这个理念，然而，他总是更倾向于关注知识结构本身，而不是仅仅是复习。

### 1980年代：SuperMemo（1980s: SuperMemo）

My own work entered the picture in 1982 when I really got fed up with a never-ending process of forgetting. I wanted to learn biochemistry and physiology. I would read books, make notes and it would all be for nothing due to the process of forgetting. Even the most important facts could slip the memory at the most unfortunate moment (e.g. exam). I decided to employ active recall. Instead of just making notes, I would make notes as questions and answers. I could cover answers and respond using active recall. This would dramatically improve learning. This is how it is done in SuperMemo to this day. This new approach had a lovely impact on boosting my love of learning.

我的个人研究在1982年开始崭露头角，当时我实在受够了永无止境的遗忘过程。我渴望学习生物化学和生理学。我阅读书籍，做笔记，但最终一切都因为遗忘而付诸东流。即使是最重要的知识，也可能在最不合时宜的时刻（例如考试时）从记忆中溜走。我决定采用主动回忆的方法。我不再仅仅做笔记，而是将笔记做成问答的形式。我可以遮盖答案，然后通过主动回忆来回答问题。这极大地提高了我的学习效果。SuperMemo 至今仍然采用这种方法。这种新方法对我的学习兴趣产生了积极而美妙的影响。

By 1984, I was fluent enough with my active recall approach to know that complex questions don’t work. If you pack too much stuff into the answer, e.g. make a long list of it, you will keep forgetting. This would be futile learning. I later called that quest for simplicity ” minimum information principle“. Today, this principle is one of the first mentioned among 20 rules of knowledge formulation.

到了1984年，我已经熟练掌握了我的主动回忆方法，并意识到复杂的问题是行不通的。如果你在答案中塞入太多内容，例如列出长长的清单，你就会不断地遗忘。这将是徒劳的学习。我后来将这种对简洁性的追求称为“最小信息原则”。如今，这一原则已成为知识构建的20条规则中首先被提及的原则之一。

The real breakthrough came in 1985, i.e. exactly 100 years after the publication of Ebbinghaus’ dissertation on memory. I wanted to check how the spacing of review affects recall. I needed to figure out the length of optimum intervals between repetitions. Obviously, those intervals exist. I only needed to measure them. The experiment is described here. The experiment was simple, rough, lazy, and hurried. Instead of taking a patient few years to find out all details, after 6 months I formulated the first SuperMemo algorithm. You can call it the first case of somewhat scientific spaced repetition. My research was based on one person, and one type of learning material, but it was universal enough to have many faithful users years later.

真正的突破发生在1985年，也就是在艾宾浩斯关于记忆的论文发表整整100年后。我想要研究复习的间隔对记忆的影响。我需要找出重复之间间隔的最佳时长。很明显，最佳间隔是存在的，我只需要找到它们。实验过程在这里有描述。这个实验简单、粗略、随意且匆忙。我没有耐心花费几年时间来找出所有细节，而是在6个月后就制定了第一个 SuperMemo 算法。你可以称之为第一个具有一定科学性的间隔重复案例。我的研究基于一个人和一种学习材料，但它足够通用，以至于多年后拥有了许多忠实用户。

On Jul 31, 1985, I started learning biochemistry using the new method. This is the birthday of computational spaced repetition. The computer program SuperMemo for DOS came in 1987, and the name SuperMemo in 1988.

1985年7月31日，我开始使用这种新方法学习生物化学。这一天是计算间隔重复的诞生日。用于 DOS 系统的计算机程序 SuperMemo 于1987年问世，而“SuperMemo”这个名称则在1988年才被确定。

In the 1980s, Jaap Murre’s Memory Chain Model was one of the early models of memory that might have led to a solid spaced repetition algorithm. It even had its own early application, Captain Mnemo, that might have competed with SuperMemo for priority in the field. Captain Mnemo and OptLearn are examples of why, in academic environments, great theories are often not followed by practical implementations that could gain wider appeal.

在20世纪80年代，雅普·穆尔（Jaap Murre）的记忆链模型是早期记忆模型之一，它可能曾经为一个可靠的间隔重复算法奠定了基础。它甚至拥有自己的早期应用——Captain Mnemo，该应用可能曾与 SuperMemo 在这一领域争夺领先地位。Captain Mnemo 和 OptLearn 都可作为典型，表明为什么在学术环境中，伟大的理论往往无法获得广泛的应用实践。

In 1991, SuperMemo World was formed and its beginnings are described here. By 1999, we started using the term “spaced repetition” instead of the *“SuperMemo method”*. For recent developments at SuperMemo World see here.

1991年，SuperMemo World 成立，其发展历程在此有所描述。到1999年，我们开始使用“间隔重复”这个术语，取代了“SuperMemo方法”。关于 SuperMemo World 的最新进展，请参见此处。

## 失败与成功的剖析（The anatomy of failure and success）

### 研究失败的公式（Formula for research failure）

Some intuitions about spaced repetition are pretty common. This gives rise to a major question: why has not spaced repetition been investigated earlier and why didn’t it permeate into the practice of learning? Intuitions are not enough, a good experimental design is also vital. This section explains why others were close but failed. How Ebbinghaus or Spitzer might have brought spaced repetition to life 90-130 years earlier. There must be something wrong with the immediacy of gratification in peer review and battle for grants. Why is there so much buzz in the field of drugging kids for school, while diseases that take a heavy death toll in less developed countries get little interest?

关于间隔重复的一些直觉相当普遍。这引出了一个主要的问题：为什么间隔重复没有更早地被研究，为什么它没有渗透到学习实践中？仅仅有直觉是不够的，一个良好的实验设计也至关重要。本节解释了为什么其他人曾接近成功但最终失败的原因。艾宾浩斯（Ebbinghaus）和斯皮策（Spitzer）是如何有机会在90到130年前就将间隔重复带入现实的。同行评审和争取资助的即时回报机制一定存在一些问题。为什么给孩子们用药以适应学校的问题会受到如此多的关注，而那些在欠发达国家造成巨大死亡人数的疾病却很少受到重视？

In this chapter, I try to figure out why spaced repetition was so late to come. Here is my take prioritized by the impact factor:

-   computers make a dramatic difference in learning efficiency in spaced repetition, early formulations would not be viral enough even in the era of the Internet
-   web perpetuates knowledge and crystallizes its essence (e.g. at Wikipedia)
-   intuitions do not ensure good experimental design. Myself, Ebbinghaus, Spitzer, and others, produced designs that would add more noise and complexity to the issue
-   human culture is in a perpetual flow. We massively forget and re-discover old findings. This is as true of individuals as it is of cultures. Science is also subject to fads, fashions and forgetting. Only now, spaced repetition has reached the *“impact density”* needed to become *“common knowledge”*. See: Discontinuity in the research on spacing effect
-   self-interest and self-learning are best drivers of applicability. Science permeates lives via practical applications. SuperMemo was the first practical application of spaced repetition that could reach thousands and then millions of users
-   there used to be a great deal of confusion between short and long-term memory, between spacing in lists, and spacing in a single day, and even between procedural and declarative learning
-   expanding, contracting or equally spaced schedule can all be made superior given appropriate timing
-   experimenters tend to use heterogeneous material (poems, lists, nonsense syllables, pages of questions, groups of students, etc.)
-   experiments where passive review is used instead of active recall do not benefit from the testing effect
-   experiments where intervals are measured in *intervening items* are based on different memory mechanisms and should not even be labelled as *spaced repetition*. To this day, a lot of confusion in research is caused by mixing up the measures of intervals without a clear separation of terminology
-   short-span of research projects makes spaced repetition investigations hardly possible
-   focus on classroom applications has confused the outcomes. Schools are not a good place for learning. Research that optimizes for school environment is of little relevance in free learning
-   ages old distinction between *learning* and *retention* confuses the thinking about optimal education. The distinction comes from schooling in which we learn first and then pray to forget little
-   terminology keeps mutating and this makes hard for new generations of researchers to capitalize on prior work. Even our own 1994 paper uses the term *repetition spacing*. For the list of terminological mutations see this Glossary entry. Web, wisdom of the crowds, and wikis (like this one) are likely to remedy the problem of terminology

在本章中，我试图弄清楚为什么间隔重复出现得如此之晚。以下是我的观点，已经根据影响大小进行了优先排序：

- 计算机在间隔重复的学习效率方面带来了显著的提升，早期的理论即使在互联网时代也不具备足够的传播性。
- 网络传播知识并使其本质得以凝练（例如在维基百科上）。
- 直觉并不能保证良好的实验设计。我自己、艾宾浩斯、斯皮策等人设计的实验都增加了问题的复杂性和所受的干扰。
- 人类文化处于永恒的流动之中。我们大规模地遗忘并重新发现旧的成果。对于个体和文化而言都是如此。科学也受到时尚潮流和遗忘的影响。直到现在，间隔重复才达到了成为“常识”所需的“影响密度”。参见：间隔效应研究中的不连续性。
-  自主兴趣和自主学习是应用性的最佳驱动力。科学通过实际应用渗透到人们的生活中。SuperMemo 是第一个能够触及数千乃至数百万用户的间隔重复实用应用。
- 过去，人们在短期记忆和长期记忆，列表中的间隔和一天内的间隔，甚至程序性学习和陈述性学习之间存在着很大的混淆。
-  只要与适当的时机配合，无论是扩展式的、收缩式的还是等距的复习安排都可以达到优越的效果。
- 实验者倾向于使用异质（研究）材料（诗歌、列表、无意义音节、记满问题的纸张、学生群体等）。
- 使用被动复习而非主动回忆的实验无法从测试效应中获益。（*译注：测试效应（testing effect），指的是主动回忆记住的内容（比如回答试卷上的问题）有助于更好的形成长期记忆，这就是为什么花费相同学习时间的前提下，需要接受考试的学生往往比不用考试的学生学习效果更好，测试效应也因此得名*）
- 以“间隔项目”为间隔单位的实验基于不同的记忆机制，甚至不应被标记为“间隔重复”。直到今天，研究中许多混乱都源于混淆间隔的测量方法，而缺乏明确的术语区分。（*译注：这里的“以间隔项目为间隔单位”是相对“以时间为间隔单位”而言的，即以两次复习之间还学习了多少其他项目（而不是隔了多少时间）作为衡量间隔长度的标准，两种研究不可一概而论。*）
- 研究项目的短周期使得间隔重复的研究难以进行。
- 侧重于课堂应用混淆了结果。学校并非理想的学习场所。为学校环境优化的研究跟自由学习几乎没有相关性。
- 长期以来，“学习”和“记忆”之间的区别混淆了人们对最佳教育的思考。这种区别源于学校教育，在学校教育中，我们先是学习，然后为了忘得少一点而祈祷。
- 术语不断演变，这使得新一代研究人员难以利用前人的工作。即使我们自己在1994年的论文也使用了“重复间隔”这个术语。关于术语演变的列表，请参见此词汇表条目。网络、集体智慧和维基百科（如本篇）很可能能够解决术语问题。

In 2006, Will Thalheimer produced an excellent research review of spaced repetition research. It was based on over 100 research articles. However, in the summary Thalheimer cast doubt about the value of progressive spacing. This shows that even dozens of papers won’t help if the experimental design is based on incorrect models.

2006年，威尔·塔尔海默（Will Thalheimer）撰写了一篇关于间隔重复研究的出色综述，该综述基于100多篇研究文章。然而，在总结中，塔尔海默对渐进式间隔的价值表示怀疑。这表明，如果实验设计基于不正确的模型，即使有数十篇论文，也无济于事。

In spaced repetition, it is not enough for review to be expanding. The review needs to be optimally expanding

在间隔重复中，复习间隔仅仅扩大是不够的，复习间隔需要是最佳的扩大。

### 失败的实验（Failed experimentation）

I will list three cases of experiments that were bound to fail or to confuse:

-   **Herman Ebbinghaus** (1885) was motivated by the science of memory. His intuitions were excellent, however, in the name of purity, he focused on nonsensical syllables. Inadvertently, he contributed to complexity of memory and interference, which he aimed to avoid. His forgetting curve is ruthless and discouraging. Had Ebbinghaus learned meaningful material of interest, he might have had extended the scope of his experiment. We all know from school that cramming nonsense is a form of mental torture. Had Ebbinghaus opted for practical applications, like myself, we might have had a paper variant of spaced repetition born a neat 100 years before the fact. Naturally, without computers, without the web, his ideas might still fall into the pit of silence for a century, as much as it has actually happened to the concept of the spacing effect.
-   **Herbert Spitzer** (1939) was motivated by improving classroom performance. He opted for the worst case of heterogeneity. While I struggled with pages of mixed difficulty material, and Ebbinghaus struggled with meaningless material, Spitzer compounded those effects by the heterogeneity of minds. Instead of pages of questions, Spitzer had groups of pupils exposed to pages of reading materials. In those noisy conditions, it is hard to see the regularities of exponential forgetting and spaced repetition. Even if Spitzer’s results were overwhelmingly positive, I doubt the bureaucracy of the education system would make a good use of the procedure. Education is driven by standardized testing, grades, and certificates. It is hardly ever driven by science and the actual impact of the learning procedure on learning outcomes. It is a factory system. Spitzer’s efforts were as doomed as those groundbreaking ideas of Benezet spawned a decade earlier (1929)
-   **Wozniak** (1985). My own misleading experiment on spaced repetition started on Jan 31, 1985, and might have ruined my efforts had it sufficiently confused my mind. Luckily, before the results came in, I designed a better experiment and was never impacted by the confusion.

我将列举三个注定失败或令人困惑的实验案例：

- **赫尔曼·艾宾浩斯**（1885年）受到记忆科学的启发。他的直觉非常出色，然而，为了追求纯粹性，他专注于无意义的音节。无意中，他反而增加了记忆的复杂性和干扰，而这正是他试图避免的。他的遗忘曲线是残酷且令人沮丧的。如果艾宾浩斯学习的是他感兴趣的有意义的材料，他可能已经扩展了他的实验范围。我们从学校都知道，死记硬背毫无意义的内容是一种精神折磨。如果艾宾浩斯像我一样选择了实际应用，我们可能早在一百年前就诞生了间隔重复的纸质版本。当然，在没有计算机和互联网的情况下，他的想法可能仍然会沉寂一个世纪，就像间隔效应的概念实际上所经历的那样。
- **赫伯特·斯皮策**（1939年）的动机是提高课堂表现。他选择了最糟糕的异质性材料。我在处理难度不一的混合材料时感到吃力，艾宾浩斯在处理无意义的材料时感到困难，而斯皮策则通过学生思维的异质性加剧了这些影响。斯皮策没有使用问题页，而是让学生群体接触阅读材料。在这种嘈杂的环境下，很难看到指数遗忘和间隔重复的规律。即使斯皮策的结果压倒性地积极，我怀疑教育系统的官僚机构也没法很好地利用这种方法。教育是由标准化测试、分数和证书驱动的。它很少由科学和学习程序对学习成果的实际影响驱动。这是一个工厂式的系统。斯皮策的努力注定会失败，就像贝内泽特十年前（1929年）提出的那些开创性想法一样。
- **沃兹尼亚克**（1985年）。我本人关于间隔重复的误导性实验始于1985年1月31日，如果它充分混淆了我的思维，可能会毁掉先前的努力。幸运的是，在结果出来之前，我设计了一个更好的实验，逃脱了这种困惑的影响。

### 艾宾浩斯的实验（1885年）（Ebbinghaus experiments (1885)）

#### 误解（The myth）

A popular myth says that Ebbinghaus invented spaced repetition back in 1885. That myth was born from our own SuperMemo documentation. When we compiled the history of SuperMemo for the web in 1997, we added a few names with contribution to memory research. As explained here, it was important to keep SuperMemo grounded in science. My own contribution has always been minimized because of the negligible weight of my name. As Ebbinghaus came at the top of the list for chronological reasons, it soon gave birth to the idea that he was the father of spaced repetition. Even our own materials evolved in that direction by mistake by careless editing. Today, the web is swamped with Ebbinghaus and the serrated set of forgetting curves. If you Google for the forgetting curves, you will see this:

一个广为流传的说法是，艾宾浩斯早在1885年就发明了间隔重复。这个误解源于我们 SuperMemo 自己的文档。1997年，当我们在网上整理 SuperMemo 的历史时，我们添加了一些对记忆研究有贡献的名字。正如这里所解释的，将 SuperMemo 建立在科学基础上非常重要。由于我个人名字的影响力微乎其微，我的贡献一直被最小化。由于时间顺序，艾宾浩斯被排在最前面，因此很快就产生了他是间隔重复之父的想法。甚至我们自己的材料也由于粗心的编辑而错误地朝着这个方向发展。如今，网络上充斥着关于艾宾浩斯和锯齿状遗忘曲线的说法。如果你在谷歌上搜索遗忘曲线，你会看到这样的结果：

![[SuperMemo_The true history of spaced repetition_附件/Google_search_for_forgetting_curves-1.jpg]]

> ***Figure:** Google search for ” forgetting curve” (November 2017). The “serrated set” of forgetting curves dominates the search. Many of the pictures are labelled by wrong attribution with the name of Hermann Ebbinghaus. The more fit origin of the picture is presented in Two components of memory*
> 
> **图示：** 谷歌搜索“遗忘曲线”（2017年11月）。“锯齿状”的遗忘曲线占据了搜索结果的主导地位。许多图片都被错误地标注为赫尔曼·艾宾浩斯的名字。这张图片更合适的来源在《记忆的两个组成部分》中有所呈现。

These are the same serrated curves that I depicted in Optimization of learning (1990):

这些正是我在《学习优化》（1990年）中描绘的相同的锯齿状曲线：

![[SuperMemo_The true history of spaced repetition_附件/Hypothetical_mechanism_of_optimal_learning-1.jpg]]

For more on the myth see our blog: Did Ebbinghaus invent spaced repetition?

欲了解更多关于这个误解的信息，请参见我们的博客：艾宾浩斯是否发明了间隔重复？

#### 事实（The fact）

We should rather be amazed with the fact that Ebbinghaus did not come up with spaced repetition. He was very close. He was touching all the right buttons.

我们更应该对艾宾浩斯没有提出间隔重复的事实感到惊讶。他当时已经非常接近了，他触及了所有正确的关键点。

This is what he wrote about the spacing effect:

> For the relearning of a 12-syllable series **at a definite time**, accordingly, **38 repetitions, distributed in a certain way over the three preceding days, had just as favorable an effect as 68 repetitions made on the day just previous**. Even if one makes very great concessions to the uncertainty of numbers based on so few researches, the difference is large enough to be significant. It makes the assumption probable that *with any considerable number of repetitions* a suitable distribution of them over a space of time is decidedly more advantageous than the massing of them at a single time.

以下是他关于间隔效应的论述：

> 因此，在**确定的时间**复习一系列总计12个的音节，**将复习在（测试前）三天内按某种时间分布进行38次重复，与在（测试）前一天进行68次重复的效果一样好**。即使我们考虑到研究数量过少，对数据的不确定性做出很大让步，这种差异也足够大，足够具有显著意义。这使得以下假设很有可能成立：_对于任何相当数量的重复_，将它们在一段时间内进行适当的分布，肯定比在同一时间集中进行更有利。

Why did Ebbinghaus not take the next seemingly obvious step to see how the forgetting curve changes upon review? For one, he did not test forgetting, but the saving on re-learning. His tests were a review. With my approach it is easy to want to achieve a set level of retention. It is conceptually less intuitive to ask for a set reduction in the cost of re-learning.

为什么艾宾浩斯没有采取下一个看似显而易见的步骤，去观察复习后遗忘曲线的变化呢？首先，他没有测试遗忘，而是测试了重新学习时节约的成本。他的测试是复习。采用我的方法，要达到一定的记忆保持水平（并且以此为衡量标准）是很容易的。而（艾宾浩斯）想要让重新学习的成本按固定比例减少，在概念上没那么直观。

However, a solution to overcoming that conceptual obstacle would be to persist with learning. Creativity thrives on the investment of time and thinking in varying contexts. To me, the answer to the Ebbinghaus puzzle is very simple. Like a good scientist, Ebbinghaus was theory-perfectionist. He chose to memorize nonsense syllables to minimize interference from his prior knowledge. Unfortunately, this had a few bad side effects:

-   his lists were hard to learn and his forgetting curve was very steep. It makes for a very discouraging picture for any student who cares about remembering in the long term
-   his lists gave him no pleasure in learning. This is the exact opposite of what I experienced in 1985. Every item in my paper collection was a little step forward in advancing my knowledge to a new level. Once I plotted my first forgetting curve, I wanted to know what happens after the next review
-   Ebbinghaus has focused on the time or effort needed for re-learning, while I always was primarily interested in retention with little interest in how much time or effort is needed to bring the recall back to 100%

然而，克服这个概念障碍的解决方案在于坚持学习。在不同情境下持续投入时间和思考，创造力就会蓬勃发展。对我来说，艾宾浩斯之谜的答案非常简单。作为一个优秀的科学家，艾宾浩斯是一个理论完美主义者。他选择记忆无意义的音节，以最大限度地减少先前知识的干扰。不幸的是，这带来了一些不良的副作用：

- 他的列表很难学习，而且他的遗忘曲线非常陡峭。这对于任何关心长期记忆的学生来说，都是一个非常令人沮丧的画面。
- 他的列表没有给他带来学习的乐趣。这与我在1985年的经历完全相反。我纸质收藏中的每一个项目都是我将知识提升到新水平的一小步。一旦我绘制了我的第一条遗忘曲线，我就想知道下一次复习后会发生什么。
- 艾宾浩斯专注于重新学习所需的时间或努力，而我的兴趣则主要在记忆保持上，反而不太关心需要多少时间和努力才能使回忆成功率恢复到100%。

I will then venture a claim that in all his heroic memorization efforts, Hermann Ebbinghaus got fed up with learning nonsense. This would break the most persistent student. My better luck came from the burning need for getting good results in learning. This resulted in self-perpetuation of the effort. This is helpful in overcoming creative obstacles.

因此，我大胆地断言，在他所有英勇的记忆努力中，赫尔曼·艾宾浩斯最终厌倦了学习毫无意义的东西。这足以击垮最执着的学生。我之所以运气更好，是因为对取得良好学习成果的强烈渴望。这导致了努力的自我延续。并且有助于克服创造性的障碍。

Interestingly, in 2015, Jaap Murre reproduced the original Ebbinghaus experiment with meticulousness worth Ebbinghaus himself (even digging into original manuscripts). Murre was prudent enough not to subject himself to the mental strain of nonsense syllables, which actually might have introduced some bias. He took the best subject available: a 22-year-old student who was rewarded with co-authorship of the publication. Incidentally, Murre seems to have been able to capture the circadian effect of learning in that his curve shows a minor bump after the period of 24 hours.

有趣的是，2015年，雅普·穆尔（Jaap Murre）以艾宾浩斯本人般的细致程度重现了最初的艾宾浩斯实验（他甚至深入研究了原始手稿）。穆尔足够谨慎，没有让自己承受记忆无意义音节的精神压力，这实际上可能引入了一些偏差。他选择了最好的受试者：一名22岁的学生，并因此获得了该成果的共同署名权。顺便提一下，穆尔似乎能够捕捉到学习的昼夜节律效应，因为他的曲线在24小时后出现了一个小小的波动。

#### 重新学习的节约（Saving on re-learning）

There is a huge difference between retrievability and “savings in re-learning”. Depending on the timing, no retrieval may mean that the fact has “just been forgotten, and easily re-relearned” or “forgotten for good”. Saving on re-learning may be non-zero on materials with zero retrievability. In simple terms, lack of access to memories does not imply zero stability. In that sense, Ebbinghaus curve is not even a good expression of exponential forgetting. There will be a different saving on re-learning for difficult material and for easy material.

可检索性与“重新学习的节约”之间存在巨大差异。根据（复习）时机，无法检索可能意味着“刚刚被遗忘，很容易重新学习”，也可能意味着“永远被遗忘了”。对于完全无法检索的材料，重新学习（相比初次学习）节约的成本也可能并非为零。简单来说，无法获取记忆并不意味着稳定性为零。从这个意义上讲，艾宾浩斯曲线甚至不是指数遗忘的良好表达。对于困难材料和简单材料，重新学习节约的成本会有所不同。

#### 遗忘曲线 (1984年)（Forgetting curve (1984)）

While writing the chapter about forgetting curves, I thought that my own notion of the forgetting curve was erroneous at the beginning. However, while digging into my archives, by accident, I discovered that I had also plotted a forgetting curve for the retention of English vocabulary in 1984, just a few months before designing SuperMemo on paper:

在撰写关于遗忘曲线的章节时，我认为自己最初对遗忘曲线的理解是错误的。然而，在翻阅我自己的档案时，我偶然发现，早在1984年，也就是在设计纸质版 SuperMemo 之前的几个月，我也绘制了一张英语词汇记忆保留率的遗忘曲线：

![[SuperMemo_The true history of spaced repetition_附件/Forgetting_curve_for_retention_1984.jpg]]

> ***Figure:** My very first forgetting curve for the retention of English vocabulary plotted back in 1984, i.e. a few months before designing SuperMemo on paper. This graph was not part of the experiment. It was simply a cumulative assessment of the results of intermittent learning of English vocabulary. The graph was soon forgotten. It was re-discovered 34 years later. After memorization, 49 pages of ~40 word pairs of English were reviewed at different intervals and the number of recall errors was recorded. After rejecting outliers and averaging, the curve appears to be far less steep that the curve obtained by Ebbinghaus (1885), in which he used nonsense syllables and a different measure of forgetting: saving on re-learning*
> 
> ***图：** 我在1984年绘制的第一个英语词汇记忆保留率的遗忘曲线，就在设计纸质版 SuperMemo 之前的几个月。这张图表并非实验的一部分，它仅仅是对间断学习英语词汇结果的累积评估。这张图表很快就被遗忘了，直到34年后才被重新发现。每页约40个英语词对，总计49页的词汇，在记忆之后按不同间隔进行了复习，并记录了回忆错误的数量。在剔除异常值并取平均值后，该曲线看起来比艾宾浩斯（1885年）获得的曲线平缓得多，艾宾浩斯使用了无意义的音节和不同的遗忘衡量标准：重新学习的（成本）节约。*

I forgot about the fact of plotting that curve. I presume, once I had SuperMemo, that curve no longer seemed important or relevant. I was not focused on the “science of memory”. I just wanted to get good results in learning. Apparently, I did not think that plotting a forgetting curve was a big deal. I nearly missed that figure in 2018 too as it was labelled in small print: *average speed of forgetting for the first memorization*.

我甚至忘记了自己绘制过那条曲线。我推测，一旦拥有了 SuperMemo，那条曲线（在当时的我眼里）似乎就不再重要或相关了。我当时并没有专注于“记忆科学”，我只是想在学习中取得好的结果。显然，我并不认为绘制遗忘曲线是什么了不起的事情。2018年，我也差点错过了这张图，因为它只用小字标注着：“第一次记忆的平均遗忘速度”。

The result came from 49 pages of 40-word pairs each, i.e. 1960 words (compare: 13 years of school in a month). I did all my learning for learning’s sake, not for the experiment. There was no experiment actually. All I needed was to collect the numbers from my actual learning effort and plot the curve. The simplicity of the calculation might also explain why I forgot the exercise so easily.

结果来自每页约40个英语词对，共49页的词汇，总计1960个单词（等同于在一个月内完成13年的学校教育）。我所有的学习都是为了学习本身，而不是为了实验。实际上，根本没有实验。我所需要的只是从我实际的学习过程中收集数据并绘制曲线。计算很简单，这可能也解释了我为什么如此容易地忘记了这项练习。

I wrote about simple intuitions before the 1985 experiment. In the light of this 1984 curve, it might seem that the intuitions may have been derived from that little experiment. What today seems obvious might not be that obvious without the crutch of that little calculation. However, I can guess that by Feb 1985, I have already forgotten my curve because I did not skip Stage A in the spaced repetition experiment. My forgetting curve agreed with the experiment and the first review interval should be 1 day indeed.

我在1985年实验之前就写过关于简单直觉的内容。鉴于1984年的这条曲线，这些直觉可能就源于那个小小的实验。今天看起来显而易见的事情，如果没有那一点计算的支撑，可能也并非那么明显。然而，我猜测到1985年2月，我已经忘记了我的曲线，因为我在间隔重复实验中没有跳过阶段 A。我的遗忘曲线与实验结果一致，第一个复习间隔确实应该是1天。

The erroneous notion of sigmoidal curves must have been born later. Today, I seem to recall remotely that I originally thought that the sigmoidal nature kicks in only after the first review. I might never know how my thought process worked at that time. All I cared was the efficiency of SuperMemo. In the excitement of the discovery of SuperMemo, I forgot my curve for the entire 34 years. Today, that little graph matters only to illustrate how easily we can discover, forget, stray, re-discover, and then re-discover the original discovery. Memory is fallible. God bless spaced repetition.

关于 S 形曲线的错误概念一定是在后来产生的。今天，我似乎模糊地记得，我最初认为 S 形特征只有在第一次复习之后才会出现。我可能永远无法知道当时我的思维过程是如何运作的。我只关心 SuperMemo 的效率。在发现 SuperMemo 的兴奋中，我把我的曲线完全遗忘了整整34年。今天，那张小小的图表只为了说明我们多么容易发现、遗忘、偏离、重新发现，然后再重新发现最初的发现。记忆是不可靠的。感谢上帝赐予间隔重复。

![[SuperMemo_The true history of spaced repetition_附件/Forgetting_curve_Wozniak_1984.jpg]]

> ***Figure:** The very first forgetting curve for the retention of English vocabulary plotted back in 1984 (a few months before designing SuperMemo on paper). This graph was not part of an experiment. It was simply a cumulative assessment of the results of intermittent learning of English vocabulary. The graph was forgotten and re-discovered 34 years later. After memorization, 49 pages of ~40 word pairs of English were reviewed at different intervals and the number of recall errors was recorded. White circles correspond with recall derived from the average number of errors per page after a given interval. Logarithmic regression in orange provides the best fit. Power regression in red follows closely. This could be expected from heterogeneous material (pages of words). This is also very similar to the results obtained by Ebbinghaus (1885), except the curve is far less steep as befits meaningful material. As expected, exponential regression in white provides the weakest fit*
> 
> ***图：** 我在1984年绘制的第一个英语词汇记忆保留率的遗忘曲线，就在设计纸质版 SuperMemo 之前的几个月。这张图表并非实验的一部分，它仅仅是对间断学习英语词汇结果的累积评估。这张图表很快就被遗忘了，直到34年后才被重新发现。每页约40个英语词对，总计49页的词汇，在记忆之后按不同间隔进行了复习，并记录了回忆错误的数量。白色圆圈对应于在给定间隔后根据每页平均错误数得出的回忆结果。橙色的对数回归提供了最佳拟合。红色的幂回归紧随其后。由于使用了异质（学习）材料（词汇页），这样的结果是可以预见的。这与艾宾浩斯（1885年）获得的结果也非常相似，只是由于这次用的是有意义的材料，曲线的陡峭程度要小得多。同样正如预期的那样，白色的指数回归提供了最差的拟合。*

### 斯皮策的实验 (1939年)（Spitzer experiment (1939)）

In 1939, Herbert F. Spitzer investigated various testing schedules on 3605 sixth-grade pupils in 9 Iowa cities. This was the entire population of 91 schools. The kids read a 6-page text and their knowledge was later tested with 25 specific questions.

1939年，赫伯特·F·斯皮策（Herbert F. Spitzer）在爱荷华州9个城市的3605名六年级学生中研究了各种不同的测试日程。这涵盖了91所学校的全部学生。孩子们阅读了一篇6页的课文，然后（研究者）通过25个具体问题对其知识进行测试。

Spitzer designed different testing schedules, however, the design clearly did not aim at optimum spacing, and his research summary did not make any recommendation in that respect.

斯皮策设计了不同的测试日程，然而，该设计显然并非旨在实现最佳间隔，而且他的研究总结在这方面也没有提出任何建议。

![[SuperMemo_The true history of spaced repetition_附件/Spitzer_1939_Diagram_of_Procedure.jpg]]

> ***Figure:** Diagram of procedure. Spitzer (1939).*
> 
> ***图：** 斯皮策的实验流程图（1939年）。*

Only the first two groups of students used an expanding schedule. These were the groups that came top on tests, however, Spitzer attributed this to the testing effect as these were the only two groups with 3 tests, i.e. the middle test was interpreted as a “testing intervention” (rather than repetition).

只有前两个学生群体使用了（测试间隔时间）递增的日程安排。这些群体在测试中取得了最好的成绩，然而，斯皮策将此归因于测试效应，因为仅有这两个群体（总计）接受了3次测试，即（两次测试）中间的测试被解释为一种“测试干预”（而不是重复）。

![[SuperMemo_The true history of spaced repetition_附件/Spitzer_1939_Curves_of_Retention.jpg]]

> ***Figure** Spitzer (1939). Curves of retention*
> 
> ***图示：** 斯皮策的记忆保留率曲线（1939年）。*

In his recommendations, Spitzer focused on the power of the testing effect, of what I call “active recall” in reference to my flashcards of 1982. What I like about his paper is the recommendation that testing be used for students to correct their own knowledge, provide feedback, and thus give them a sense of their progress. This stands in contrast to modern testing that is more often used as a whip to push kids to do more learning.

在他的建议中，斯皮策专注于测试效应的力量，这在我1982年的助记卡中被称为“主动回忆”。我喜欢他的论文的地方在于，他建议使用考试来帮助学生纠正自己的知识，提供反馈，从而让他们感受到自己的进步。这与现代考试形成了鲜明对比，现代考试更常被用作鞭策手段，以强迫孩子进行更多学习。

Spitzer’s diagram of intervals reminds me of my own self-administered test that failed to produce convincing results. In this case, intervals are clearly clocked by school life, not by demands of memory.

斯皮策的间隔图让我想起了我自己的自主测试，那些测试未能产生令人信服的结果。在这种情况下，间隔显然是按照学校生活来安排的，而不是根据记忆的需求。

In his research, Spitzer exhibited ruthless Gatesian approach to testing and learning, typical of early school innovators that often did more damage than good by being too thorough! Educators who do not employ the learn drive in the process, are doomed to fail even if they employ the best tools for boosting memory!

在他的研究中，斯皮策展现了残酷的盖茨式的学习和测试方法，这在早期的教学创新者中很典型，他们往往因为掌控过于深入，而让结果弊大于利！那些在过程中不运用学习驱动力的教育者，即使使用了最好的记忆增强工具，也注定会失败！

I cannot but remark on the issue of ethical considerations. While we slaughter millions of animals in the name of science, we might perhaps fail to notice that this research, with all the best intent at heart, used the labor of 3000+ involuntary participants. What is great for memory research does not need to be great for individual learning. In the era of Google, I found the test texts used by Spitzer pretty offputting. Despite the fact that a great deal of effort was put into the selection of the subject matter and wording, I would consider coercive reading a violation of my freedom. Those materials might be much better than your school average, but schooling will always be about mass production and less about creative freedom.

我忍不住要从伦理角度发表评论。虽然我们为了科学的名义屠宰了数百万动物，但我们可能没有注意到，这项研究，尽管其出发点是好的，却使用了3000多名非自愿参与者的劳动。对记忆研究有益的东西，不一定对个体学习有益。在谷歌时代，我发现斯皮策使用的测试文本相当令人反感。尽管在主题选择和措辞方面付出了大量努力，但我会认为强制阅读是对我自由的侵犯。这些材料可能比你学校的平均水平要好得多，但学校教育永远是为了（有助于）大规模的生产，而非创造性的自由。

（*译注：译者并不完全认同 Wozniak 教授的看法，创造性自由肯定得有，但是大规模生产保障了人民的衣食住行，物质上的丰富才能带来思想上的解放，这时已经在历史实践中证明过的，当然，目前（2025年）的全世界教育体系都还有巨大的改进空间，这点笔者完全认同。*）

Reading about a biology of banana plants might be palatable to a gardener or a biologist, which I claim to be. However, why would kids need to read about bananas if their current interest was the Great Depression, the Dust Bowl, Nazi Germany, or baseball?

阅读关于香蕉种植的文章，对于园丁或生物学家来说可能很有意思，而我自认为是这两者之一。然而，如果孩子们目前对大萧条、沙尘暴、纳粹德国或棒球更感兴趣，他们为什么需要阅读关于香蕉的东西呢？

（*译注：不管吃香蕉还是吃大米，人总得先吃饱才有力气研究这些玩意啊……*）

School is the time when we stop learning and start cramming. It is the time when we lose the love of learning. Adding spaced repetition to this coercive mix could only make things worse.

上学只会让我们停止学习，开始死记硬背。只会让我们我们失去对学习的热爱。在这种强制性的环境中加入间隔重复只会让情况变得更糟。

### 沃兹尼亚克的实验 (1985年)（Wozniak experiment (1985)）

Before I managed to compute optimal intervals for reviewing pages with English vocabulary, I designed an experiment which might have put me on wrong tracks. The experiment was to show the value of the progressive increase in review intervals. Instead, it showed that equally spaced review might be superior.

在我设法计算出复习英语词汇页的最佳间隔之前，我设计了一个实验，这个实验差点让我走上了错误的道路。该实验旨在展示“逐渐增加复习间隔”（这一策略）的价值。然而，结果却表明等距复习可能更优越。

Experiments in science should not be considered “failed” just because they come with unexpected results. However, in this case, unexpected results came from bad design, and might have resulted in confusion that would inhibit further progress. To this day researchers speak of “mixed results” in spaced repetition due to wrong design or even simple terminological confusion.

科学实验不应仅仅因为结果出乎意料就被认为是“失败”的。然而，在这一案例中，意想不到的结果源于糟糕的设计，并且可能导致困惑，从而阻碍进一步的发展。时至今日，研究人员仍然会谈论在间隔重复中，由于错误的设计，甚至简单的术语混淆而造成的“混合结果”。

Fortunately, my intuitions about memory in 1985 were too solid, and it was pretty obvious that with rapid acceleration in the expanding length of intervals, forgetting might overwhelm consolidation. My progressive schedule was simply not optimum. I would have certainly designed a better follow-up. Most of all, I wanted to continue learning with success. I doubt I would have given up without a good solution.

幸运的是，我在1985年关于记忆的直觉非常坚定，而且很明显，随着间隔长度的快速增加，遗忘可能会压倒巩固。我的渐进式安排显然只是还没达到最优状态。我肯定会设计一个更好的后续实验。最重要的是，我希望能够继续成功地学习。我怀疑即使没有找到一个好的解决方案，我也不会轻言放弃。

The experiment shows that it is not enough to have a good guess about what optimum intervals are. The intervals actually need to be computed.

这个实验表明，仅仅对最佳复习间隔有一个好的猜测是不够的，我们需要对间隔进行实际计算。

Archive warning: Why use literal archives?

下面是引用文档

<small>This text is part of: ”&nbsp;<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">Optimization of learning</a>&nbsp;</em>” by&nbsp;<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)</small>

<small>下面的段落是以下文章的一部分：“<em><a href="http://supermemo.guru/wiki/Optimization_of_learning" rel="noreferrer noopener" target="_blank">学习优化</a>&nbsp;</em>”由<a href="http://supermemo.guru/wiki/Piotr_Wozniak" rel="noreferrer noopener" target="_blank">Piotr Wozniak</a>&nbsp;(1990)撰写</small>

At the beginning of 1985, I designed two experiments which consequently revolutionized my learning methodology and led to the formulation of the SuperMemo method.

1985年初，我设计了两个实验，这两个实验随后彻底改变了我的学习方法，并促成了 SuperMemo 方法的形成。

The first experiment can be a good illustration of how a misconceived idea can yield valuable conclusions (the second is described here). It is a common intuition that with successive repetitions, knowledge should gradually become more durable and require less frequent review. Thus repetitions separated by increasing intervals should be more effective than those whose intervals are always the same. This belief proved to be false. Let us see an experiment which demonstrates the fact:

第一个实验可以很好地说明一个因误解而诞生的想法是如何产生有价值的结论的（第二个实验在这里也有描述）。一个常见的直觉是，随着重复次数的增加，知识应该逐渐变得更加持久，并且只需更低的复习频率即可维持。因此，间隔逐渐增加的重复应该比那些间隔始终相同的重复更有效。然而，这种信念被证明是错误的。让我们来看一个证明这一事实的实验：

**Experiment on the influence of various repetition spacing patterns on the effect of repetitions on knowledge retention (Jan 31, 1985 – Aug 2, 1986)**

4.  The memorized knowledge consisted of 195 items divided into three equal groups: A, B and C.
5.  Each of the items had the following form:*Question:* English irregular verb*Answer:* simple present, simple past and past participle forms of the verb in question
6.  All items of a particular group were memorized in one session by repeating them until all were known (group A – Jan 31, B – Feb 2, C – Feb 3).
7.  Two final control dates were established: Dec 6-7, 1985 and Aug 1-2, 1986 on which the level of retention in all groups was measured at the same time (for each item the accuracy of recall was measured in a four grade scale).
8.  Before the control dates, all of the groups A, B and C underwent 6 independent repetitions in the following intervals (expressed in days):

| Repetition number | Group A (equal spacing over a longer time) | Group B (spacing based on increasing intervals) | Group C (equal spacing in 30 days) |
| ----------------- | ------------------------------------------ | ----------------------------------------------- | ---------------------------------- |
| 1                 | 18 days                                    | 1 day                                           | 5 days                             |
| 2                 | 18 days                                    | 5 days                                          | 5 days                             |
| 3                 | 18 days                                    | 9 days                                          | 5 days                             |
| 4                 | 18 days                                    | 24 days                                         | 5 days                             |
| 5                 | 18 days                                    | 44 days                                         | 5 days                             |
| 6                 | 18 days                                    | 70 days                                         | 5 days                             |

**关于不同重复间隔模式对知识保留效果影响的实验 (1985年1月31日 – 1986年8月2日)**

4. 所记忆的知识由195个项目组成，分为A、B和C三个相等的小组。
5. 每个项目都具由以下形式组成：*问题：* 英语不规则动词 *答案：* 所提动词的现在时、过去时和过去分词形式。
6. 特定小组的所有项目都会在一次复习中，通过不停重复进行记忆，直到全部掌握（A组 – 1月31日，B组 – 2月2日，C组 – 2月3日）。
7. 建立了两个最终的对照日期：1985年12月6日至7日和1986年8月1日至2日，在这些日期同时测量所有组的保留率水平（对于所有项目，回忆的准确性都以四级评分标准进行衡量）。
8. 在对照日期之前，A、B、C 三组内容都进行了6次独立的重复，间隔如下（以天为单位）：

| 重复次数 | A 组（复习间隔时长相等，总计时间更长） | B 组（复习间隔时长递增） | C 组（复习间隔时长相等，总计30天） |
| ---- | -------------------- | ------------- | ------------------- |
| 1    | 18天                  | 1天            | 5天                  |
| 2    | 18天                  | 5天            | 5天                  |
| 3    | 18天                  | 9天            | 5天                  |
| 4    | 18天                  | 24天           | 5天                  |
| 5    | 18天                  | 44天           | 5天                  |
| 6    | 18天                  | 70天           | 5天                  |

The intent of the experiment was to prove that increasing intervals are the best for memory consolidation (group B) as opposed to intervals that are evenly distributed (group A) or concentrated in time (group C). The results of the experiment are shown in Fig. 3.1:

实验的目的是证明，与均匀分布的间隔（A组）或时间上集中的间隔（C组）相比，间隔逐渐增加（B组）对记忆巩固的效果最好。实验结果如图3.1所示：

![[SuperMemo_The true history of spaced repetition_附件/Condensed_vs_Distributed_vs_Progressive_schedule.jpg]]

The results of the second control are not present on the graph because of the prosaic fact that studying at the University of Technology [started in October 1985] required perfect knowledge of irregular verbs, therefore another measurement was pointless.As it can be seen in Fig.3.1 above, the experiment yielded unexpected results proving that increasing inter-repetition intervals need not be better than constant-length intervals. Fortunately, long before the results of the experiment were known, I suspected that there must exist optimum inter-repetition intervals. The principle of using such intervals in the process of learning will be later be referred to as the optimum repetition spacing principle.

由于一个很实际的原因，第二次对照的结果没有出现在图表中：[1985年10月开始]在理工大学学习需要对不规则动词有完美的掌握，因此再进行一次测量毫无意义（*译注：这里作者的意思应该是，本来用于记忆测试的材料由于学校的要求已经被提前熟练掌握了，已经背熟的材料就没法再用来做记忆实验了*）。正如上图3.1所示，实验得出了意想不到的结果，证明逐步增加的重复间隔不一定比固定长度的重复间隔更好。幸运的是，早在实验结果出来之前，我就怀疑一定存在最佳的重复间隔。在学习过程中使用这种间隔的原则后来被称为最佳重复间隔原则。

While writing History of spaced repetition, I found the original graphs in my archive. It is pretty obvious that *massed practice* is not a good approach:

在撰写《间隔重复的历史》时，我在我的档案中找到了原始图表。很明显，**集中练习**不是一个好方法：

### 为什么间隔重复的想法最终取得了成功？（Why spaced repetition idea succeeded in the end?）

Spaced repetition is intuitive. After some reflection, it is even obvious. Why didn’t we come up with solutions earlier? SuperMemo on paper would be feasible as soon as mankind came up with paper. However, in ancient times, the volume of vital knowledge was small enough for the brain to easily cope with the deployment of natural learning methods. By working in the field, the farmer quickly gains all necessary expertise that helps him excel for as long as health permits.

间隔重复是符合直觉的。如果再加上一些思考，它甚至可以说是显而易见。为什么我们没有更早地提出解决方案呢？只要人类发明了纸张，纸质版的 SuperMemo 就变得可行了。然而，在古代，重要知识的体量很小，大脑很容易就能通过自然学习的方法记住。通过在田间劳作，农民很快就能获得所有必要的专业知识，只要健康允许，这些知识就足够帮助他良好地工作了。

Things started changing with the arrival of print in the 15th century. Knowledge started proliferating and it also gained means of efficient perpetuation. Newton at plague years might be an interesting example of an individual who would theoretically benefit from spaced repetition. However, Newton’s book collection was limited and the problems to think about and solve were so numerous that it is easy to imagine he would never be bothered with his failing memory. All he needed was to make notes.

倒了15世纪，随着印刷术的出现，情况开始发生变化。知识开始激增，并且也获得了有效传播的手段。伦敦大瘟疫时期的牛顿可能是一个有趣的例子，理论上他会从间隔重复中受益。然而，牛顿的书籍收藏有限，需要思考和解决的问题又如此之多，他很可能从未被自己记忆力衰退的问题困扰。只要做做笔记就够了。

Over the next two centuries, the stores of available knowledge kept increasing and human natural appetite for remembering might have been increasing at the same time. Research by Ebbinghaus in the 1880s is an example of a continual interest in the workings of memory. However, even today, most of the scientists are rarely bothered by their forgetting. Making notes and Google can satisfy most of the needs for most of them. When Vannevar Bush conceived memex device in the 1930s, he saw it as a memory augmentation. However, even if memex was to be seen as a distant cousin of incremental reading or neural creativity, all its knowledge, like in Google, lived predominantly outside of the human brain. My quest reminds me that of V. Bush except I want to see all that knowledge make a direct imprint on human creativity (see: neural creativity).

在接下来的两个世纪里，可获取的知识储备不断增加，人类对记忆的天然渴望也在同时增加。艾宾浩斯在1880年代的研究是人们对记忆运作持续感兴趣的一个典型案例。然而，即使在今天，大多数科学家也很少为他们的遗忘而烦恼。做笔记和使用谷歌就能满足他们大部分的需求。当万尼瓦尔·布什（Vannevar Bush）在20世纪30年代构思 memex 设备时，他将其视为一种记忆增强手段。然而，即使将 memex 看作是增量阅读或神经创造力的远亲，其所有知识，就像在谷歌中一样，主要存在于人脑之外。我觉得自己的探索与 V. Bush 有诸多相似之处，但我和它的不同之处在于，我希望看到所有这些知识对人类创造力产生直接的影响（见：神经创造力）。

Why was I particularly bothered by forgetting? There are many kids out there who like to show off at school. When my brother showed me how to differentiate needles of a spruce and a fir, in my 3rd-grade biology class, I was eager to show that I know more than your average kid. That eagerness was quickly suppressed by schooling, but some traces survived. When we started learning chemistry in Grade 7, I was proud to be able to recall complex names like adenosine triphosphate or deoxyribonucleic acid. I was even looking up difficult chemistry names to memorize and impress. I memorized the details of the anatomy of a jawless fish. Again I tried to impress at school, but no one was interested.

为什么我特别在意遗忘呢？有很多孩子在学校喜欢炫耀。当我哥哥教会我如何区分云杉和冷杉的针叶之后，在三年级的生物课上，我就渴望展示我比普通孩子知道得更多。这种渴望很快就被学校教育压抑了，但一些痕迹幸存了下来。当我们七年级开始学习化学时，我为能够回忆起像三磷酸腺苷或脱氧核糖核酸这样复杂的名称而感到自豪。我甚至会查阅难记的化学名称来记忆并给别人留下深刻印象。在我记住了无颌鱼的解剖细节之后，我又一次试图在学校里给人留下深刻印象，但没有人感兴趣。

When I got deeper into zoology in Grade 5, some kind of OCD for information started showing up. I wanted to know all animals in the Poznan zoo, their habitat, and even their taxonomy and Latin names. I got fantastic books with photographs of all animals and knowing them seemed like an interesting endeavour.

当我到了五年级，更深入地学习动物学时，某种对信息的强迫症开始显现出来。我想知道波兹南动物园里所有的动物，它们的栖息地，甚至它们的分类学和拉丁学名。我买了一些很棒的书，里面有所有动物的照片，了解它们似乎是一件很有趣的事情。

In 1974, I became interested in boxing, football, and sports in general. I used to visit the waste paper store in our school and search for sports journals. My colleague Robert asked me to collect pictures with naked ladies. I complied. My puberty was late and I was not interested. When the stack of photos spilled at home, I explained it to my mom ” *not for me!*“. She nodded compassionately with a smirk. In the meantime, I would use an iron to remove wrinkles from my recycled sports journal collection. I would stack them up neatly and archive by date. The stack filled up several shelves in bookcases in my room. That obsessive neatness would make for a disturbing picture for any parent, however, my mom was tolerant. I was free to follow my passions even if they seemed preposterous. I have no doubt that freedom is one of the vital ingredients of healthy development. Don’t many kids show similar symptoms in obsessions with stamp collecting, postcards and football cards?

1974年，我对拳击、足球和其他各种体育运动产生了兴趣。我经常去我们学校的废品回收站寻找体育杂志。我的同学罗伯特让我顺带帮忙收集裸体女士的照片。我照做了。我的青春期来得比较晚，当时我对此并不感兴趣。当照片在家中散落一地时，我向妈妈解释说：“*不是我自己要的！*”她同情地点了点头，脸上带着一丝微笑。与此同时，我会用熨斗熨平我回收的体育杂志，以去除褶皱。我会把它们整齐地叠起来，并按日期归档。这些杂志堆满了房间里书架上的几个隔板。这种强迫性的整洁对于任何父母来说都可能是一个令人不安的景象，然而，我的母亲却很宽容。我可以自由地追求我的爱好，即使它们看起来荒唐可笑。我毫不怀疑，自由是健康发展的重要组成部分。很多孩子在收集邮票、明信片和足球卡方面不也表现出类似的痴迷症状吗？

Some early drive in the direction of incremental reading showed some time between ages 10 and 12. I started making notes about horses by following links in a paper encyclopedia. It was fun to start with one entry, and hope to write a booklet about horses by just following the links. In Grade 1 of high school (aged 12), I did a similar exercise with an encyclopedia of mammals. There was some inner need to codify all information about certain subjects in biology. I decided to write an encyclopedia-sized book about the living world. I used a typewriter at mom’s work and my own rich illustrations to write the history of evolution. I never finished. The futility of that exercise should be obvious. It never bothered my mind. The effort was enjoyable and addictive.

大约在10岁到12岁之间，我开始对增量阅读表现出一些早期的兴趣。我开始通过翻阅纸质百科全书中的链接来做关于马的笔记。从一个条目开始，跟随链接不断跳转，最后汇总出一本关于马的小册子，这很有趣。高中一年级（12岁时），我用一本哺乳动物百科全书做了类似的练习。我内心似乎有一种渴望，要将关于某些生物学主题的所有信息汇总并编码。我决定写一本和百科全书一样大的关于生命世界的书。我用妈妈工作单位的打字机和自己丰富的插图来撰写进化史。我从未完成。这项练习的徒劳应该很明显。但这从未困扰过我。这个过程既令人愉快且沉醉。

I showed a similar informavorous nature when I started learning zoology, chemistry, biology, and later biochemistry during summer vacations 1977-1979 (aged 13-15). This was a definite start of my growing need for remembering. I would produce calligraphically written and meticulously illustrated books with my newly acquired knowledge. However, after a longer while that knowledge tended to evaporate. That futility started bothering me slowly. What’s the point of writing books if soon they turn into the same dead material like all other books on the shelf?

1977年至1979年暑假期间（13-15岁），当我开始学习动物学、化学、生物学，后来是生物化学时，也表现出类似的对信息的强烈渴望。这确实是我日益增长的记忆需求的开始。我会用书法写字，并配上精心绘制的插图，来制作记录我新获得知识的书籍。然而，过了一段时间后，这些知识往往会消失。这种徒劳感开始慢慢地困扰我。如果我写的书很快就会变成书架上所有其他书籍一样的死物，那么写书有什么意义呢？

Around the year 1981-1982 (aged 19-20), I started writing down my knowledge in the form of questions and answers for active recall tests. I knew that this was the only way to preserve things in memory for longer. Needless to say, after a while, the chaotic review did not provide full satisfaction either. At that stage, I was clearly very hungry for knowledge. I wanted to remember. Simple intuitions led to simple experiments and then to a simple SuperMemo for DOS. I was driven by practical applications that combined research with the pleasure of learning.

大约在1981-1982年（19-20岁），我开始以问答的形式记录我的知识，用于主动回忆测试。我知道这是将知识在记忆中保存得更长远的唯一方法。毋庸置疑，过了一段时间后，这种混乱的复习也未能完全令人满意。在那时，我显然对知识非常渴望。我想记住。简单的直觉导致了简单的实验，然后是简单的 DOS 版 SuperMemo。我被实践所驱动，学习乐趣与研究在其中得以结合。

As of that point, my path has become deterministic. I loved learning too much to give up SuperMemo in difficult times. My love of learning was easily suppressed at school or when I was involved in running a business. However, once I decided to work from home (1997), the positive feedback loop has set in between learning, love of learning, and the progress of SuperMemo. As this also happens to be the way to earn a living, that loop is for ever. Only bad health or death can break this cycle. That part of the formula for progress is easy to figure out.

从那时起，我的道路就变得确定了。我太热爱学习了，以至于在困难时期也不会放弃 SuperMemo。被迫上学或参与生意经营时，我对学习的热爱很容易被压抑。然而，一旦我决定在家工作（1997年），学习、对学习的热爱以及 SuperMemo 的进步之间就形成了正反馈循环。由于这恰好也是谋生的方式，这个循环将永远持续下去。只有健康问题和死亡才能打破这个循环。这部分进步的原因很容易理解。

What could parents do to facilitate similar passions in kids? I think two ingredients come into play: inspiration and freedom. While inspiration is helpful, freedom is essential. These days, inspiration can be found all around. YouTube plays a huge role where humans don’t live up to the mark. All around the world, it is the freedom ingredient that is missing most. Kids are enslaved by schooling. They are also enslaved by authoritarian parenting. I was told many times that some of my crazy behaviors are a side effect of growing up without a father. This might be true. However, to compensate, I had three parents. Mom and two older siblings: inspiring brother and a childless sister who channeled all her love into the little brat of me. I venture a claim that I came to this world with a reasonable endowment, not much above the average. I often lingered at the bottom of the class. Rarely would I come to the lead. I have dozens of examples when I converted meager skills or a bit of talent into excellence in a narrow area of creative pursuits. Freedom and rage to master were always the key ingredients. When I bread dozens of animals or collected dead body parts, my family might ask ” *why is the kid not going to church instead?*“. My mom would shield me from those influences and concerns. I could do things my own way.

父母可以做些什么来促进孩子们产生类似的热情呢？我认为有两个要素起作用：灵感和自由。虽然灵感也有帮助，但自由才是必不可少的。如今，灵感随处可见。YouTube 发挥着巨大的作用，在很多方面弥补了人类的不足。放眼世界，最缺乏的就是自由这一要素。孩子们被学校教育所束缚，也被专制的父母所束缚。我曾多次被告知，我的一些古怪行为是成长过程中没有父亲的副作用。这可能是真的。然而，为了弥补这一点，我有三个父母。妈妈和两个年长的手足：一个充满激情的哥哥和一个没有孩子的姐姐，她把所有的爱都倾注在我这个小坏蛋身上。我敢说，我来到这个世界时，天赋不算突出，略高于平均水平而已。我经常在班级里给人垫底，很少能名列前茅。我有很多成功案例，将微薄的技能，或一点点天赋，转化为在某个细分的创造性领域里的卓越成就。自由和渴望掌握始终是关键要素。当我繁殖了几十只动物或收集尸体的时候，我的亲戚们可能会问：“_这孩子为什么不去教堂呢？_”但我妈妈总是保护我免受那些影响和关注。我可以按照自己的方式做事。

My development was then primarily boosted by the impact of freedom. Freedom helps the learn drive thrive, and the learn drive has self-amplifying powers. This led me to obsessions that make it possible to boast today of fathering spaced repetition. Passions and obsessions should be cherished. Instead, we tend to exterminate them in the name of robotization of development. We set benchmarks and ask kids to jump through the hoops. As if being led by the hand through college has ever contributed to anyone’s independent thinking. This decorticating process needs to stop! The future belongs to free learning.

我的发展主要得益于自由的影响。自由有助于学习驱动力蓬勃发展，而学习驱动力本身具有自我增强的力量。这使我获得了（对事业的）专注，进而使我取得了能够自豪地宣称自己是“间隔重复之父”的成就。激情和痴迷应该被珍视。相反，我们往往以标准化发展的名义消灭它们。我们设定基准，要求孩子们跳过重重障碍。仿佛被手把手地带入大学就能培养出任何人的独立思考能力。这种剥皮的过程需要停止！未来属于自由学习。

As for spaced repetition, the appetite for solving the problem of forgetting increased substantially with the arrival of personal computers. In the early 1990s, I heard it with increasing frequency from users of SuperMemo that they thought of a similar solution for themselves but decided to look around for a specific software application first.

至于间隔重复，随着个人电脑的出现，解决遗忘问题的渴望大大增加。在20世纪90年代初，我越来越频繁地从 SuperMemo 的用户那里听到，他们也曾想到类似的解决方案，但首先决定在市场上寻找特定的软件应用。

It is the demands of school that cause most frustrations in students today, however, schools are not a good place for creative thinking. Students do flock to spaced repetition mostly because it is served on a silver platter. It is ready to consume. Very few contemplate their own solutions.

如今，学校的要求是造成大多数学生挫败感的主要原因，然而，学校并不是培养创造性思维的好地方。学生们之所以涌向间隔重复，主要是因为它唾手可得，可以直接使用。很少有人会思考他们自己的解决方案。

In addition to personal freedoms, some of the good fortunes that gave a good start to SuperMemo were: (1) free university in communist Poland, (2) family sponsorship in purchasing an outrageously expensive PC, (3) lenient schools that did not impose much on my free time, etc.

除了个人自由之外，一些为 SuperMemo 奠定良好基础的机缘包括：（1）共产主义波兰的免费大学教育，（2）家人赞助购买一台极其昂贵的个人电脑，（3）宽松的学校教育，没有对我的自由时间施加太多限制，等等。

You will not see many 22-24 year olds tinkering with their own science at the cost of the state or their family. There is nothing wrong with young adults living with their parents if they pursue creative goals.

22-24岁的年轻人为了自己的科学研究而花费国家或家庭的钱财并不常见。但如果年轻人为了追求创造性的目标而与父母同住，这并没有什么问题。

Spaced repetition was born at the confluence of good forces: free learning in a communist system, the transition from communism to the market economy, and the arrival of personal computing. That was boosted by freedom at home and a dose of healthy obsession with learning. The main ingredient of that equation is freedom. Freedom is replicable. All it needs is to be granted.

间隔重复诞生于多种有利因素的交汇点：共产主义制度下的免费教育，从共产主义向市场经济的过渡，以及个人电脑的出现。这些因素又在家庭提供的自由和对学习的健康痴迷的推动下得到了发展。这次成功的首要因素是自由。自由是人人都能获得的。它所需要的只是被给予。

### SuperMemo 的第一个十年：与怀疑作斗争（First decade of SuperMemo: Battling skepticism）

Skepticism surrounded the early days of SuperMemo in Poland. This was expressed pretty accurately in the Polish computer journal *Enter* in 1994 (see full article):

> **SuperMemo might work but it cannot be that good**  
> 
> If one is convinced of the validity of what has been said about SuperMemo, will he or she be already convinced that the program is a perfect cure for the ailing memory? Can it really capitalize on the properties of the nervous system and let learning proceed a dozen times faster than in standard circumstances? 
> 
> After all there have been generations of students trying to figure out better methods of learning, and a breakthrough comparable with SuperMemo seems highly unlikely even to quite an open-minded observer. Wozniak discounts the low-probability argument as the viable source of skepticism, and says that he has more than once traced down evidence that SuperMemo-like approaches to learning have already been tried before with lesser or greater degree of success.
> 
> Moreover, it is worth noticing that SuperMemo might not see the light were it not implemented as a computer program which can easily be transferred between individuals. In other words, it could have fallen into oblivion as the previous attempts to put order in the process of learning. 
> 
> One must remember that the skeletal algorithm of SuperMemo has been formulated in 1985, and only 1987 saw its very slow expansion in selected scientific circles in Poznan. Another turning- point to be kept in view is that SuperMemo World would not have been formed in 1991 were it not for the inspiring meeting of minds between Wozniak and his colleague from the university, Krzysztof Biedalak, currently SuperMemo World’s Vice-President.
> 
> Both top-students at the university, Wozniak intended to study neuroscience in the US, Biedalak wanted to do the same in the field of artificial intelligence. Only by coincidence, they were both thrown into the world of entrepreneurial science. All this shows that despite the fact that the principles of SuperMemo are extremely simple and might have been invented several dozen times independently in several dozen countries of the planet, SuperMemo is not just a run-of-the-mill. The distinctive merit of SuperMemo World was to put the idea in practice, invest a great deal of man-hours in the development of the software, and focus on marketing the idea to the potential customer. Otherwise, SuperMemo would have forever remained limited to the small circle of its early enthusiasts.

在波兰，SuperMemo 在发展早期受到了大量怀疑。这种怀疑在1994年的波兰计算机杂志《Enter》上得到了相当准确的表达（见全文）：

> **SuperMemo可能有效，但它不可能那么好**
> 
> 如果一个人相信了关于 SuperMemo 所说的一切，他或她是否已经相信这个程序是治疗记忆力衰退的完美良药？它真的能够利用神经系统的特性，使学习速度比标准情况下快十几倍吗？
> 
> 毕竟，几代学生一直在努力寻找更好的学习方法，即使对相当开明的观察者来说，SuperMemo 这个级别的突破似乎也没有发生的可能。沃兹尼亚克不觉得“低概率”是质疑的可靠论据，并表示他不止一次地追溯到证据，表明类似 SuperMemo 的学习方法之前已经有人尝试过，只是成功程度或多或少。
> 
> 此外，值得注意的是，如果 SuperMemo 没有以可以轻松在个人之间传输的计算机程序的形式实现，它可能就不会问世。换句话说，它可能像之前试图整理学习过程的尝试一样，被遗忘在历史的长河中。
> 
> 人们必须记住，SuperMemo 的骨干算法是在1985年制定的，直到1987年，它才在波兹南的特定科学圈子里缓慢扩展。另一个需要关注的转折点是，如果没有沃兹尼亚克与他的大学同学、现任 SuperMemo World 副总裁克里斯托夫·比达拉克之间富有启发性的思想交流，SuperMemo World 就不会在1991年成立。
> 
>  同为大学里的顶尖学生，沃兹尼亚克原本打算在美国学习神经科学，而比达拉克则想在人工智能领域做同样的事情。只是由于巧合，他们都被卷入了科学产业界。所有这一切都表明，尽管 SuperMemo 的原理极其简单，并且可能在全球几十个国家被独立发明过几十次，但 SuperMemo 不仅仅是一个普通的软件。SuperMemo World 的独特功绩在于将这个想法付诸实践，在软件开发上投入了大量人力，并专注于向潜在客户推广这个想法。否则，SuperMemo 将永远局限于其早期爱好者的小圈子之中。

### 前景是光明的（The future is bright）

I mentioned that the progress of spaced repetition has been bogged down by guesswork, weak practical toolset, and terminological confusion. Today, all those factors fall by the roadside. New web applications come into force, they combine big data, and practical needs of users. They all use the same terminology: forgetting curve, spacing effect, and spaced repetition. The future of learning looks brighter than ever.

我提到过，间隔重复的进展曾因猜测、缺乏实用工具和术语混淆而停滞不前。如今，所有这些因素都已成为过去。新的网络应用应运而生，它们结合了大数据和用户的实际需求。它们都使用相同的术语：遗忘曲线、间隔效应和间隔重复。学习的未来比以往任何时候都更加光明。
